<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Andes Neural Network Library User Manual: Convolution Functions</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Andes Neural Network Library User Manual
   &#160;<span id="projectnumber">version3.1</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('group__Convolution.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">Convolution Functions</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga43ac72a8511cbaf132ae0edc1fdb6276"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga43ac72a8511cbaf132ae0edc1fdb6276">riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:ga43ac72a8511cbaf132ae0edc1fdb6276"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga76dd8cc6a11522305e9ec5ddb968877e"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga76dd8cc6a11522305e9ec5ddb968877e">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:ga76dd8cc6a11522305e9ec5ddb968877e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga0114bf25be0e886cfc5082157ce217dd"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga0114bf25be0e886cfc5082157ce217dd">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</td></tr>
<tr class="separator:ga0114bf25be0e886cfc5082157ce217dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6349568d6ce5be71ab37670fab334cf9"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga6349568d6ce5be71ab37670fab334cf9">riscv_nn_conv_HWC_s8_s8_s8_sft_bias</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:ga6349568d6ce5be71ab37670fab334cf9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga75095bb9dbfe0344ca04324ac11493bb"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga75095bb9dbfe0344ca04324ac11493bb">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:ga75095bb9dbfe0344ca04324ac11493bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga37169c70f07977dec222eaa63f82a7b1"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga37169c70f07977dec222eaa63f82a7b1">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:ga37169c70f07977dec222eaa63f82a7b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaff8aeef6b452c567ed13804449576f11"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gaff8aeef6b452c567ed13804449576f11">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:gaff8aeef6b452c567ed13804449576f11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gafb242463d8fe330aae86ed20c35a62db"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gafb242463d8fe330aae86ed20c35a62db">riscv_nn_conv_HWC_s16_s16_s16_sft_bias</a> (const q15_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q15_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q15_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:gafb242463d8fe330aae86ed20c35a62db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gabfb034c6133f003ed595846e8e9ecfa4"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gabfb034c6133f003ed595846e8e9ecfa4">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast</a> (const q15_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q15_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q15_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:gabfb034c6133f003ed595846e8e9ecfa4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga23816c40e33fa7fa6e00ad6a8353f08b"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga23816c40e33fa7fa6e00ad6a8353f08b">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any</a> (const q15_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q15_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q15_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:ga23816c40e33fa7fa6e00ad6a8353f08b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab4c2811e5fde9441edd373a492d8cc72"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gab4c2811e5fde9441edd373a492d8cc72">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:gab4c2811e5fde9441edd373a492d8cc72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga01c17cfd9b6bc224bb2329fa9ac7668e"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga01c17cfd9b6bc224bb2329fa9ac7668e">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:ga01c17cfd9b6bc224bb2329fa9ac7668e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad252997444bbf90fb0d75fd643236dec"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gad252997444bbf90fb0d75fd643236dec">riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gad252997444bbf90fb0d75fd643236dec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga40987111c7ab7c94dd9f68ed119e6d05"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga40987111c7ab7c94dd9f68ed119e6d05">riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga40987111c7ab7c94dd9f68ed119e6d05"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga96c008665236c846c00df6299a72cc1b"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga96c008665236c846c00df6299a72cc1b">riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga96c008665236c846c00df6299a72cc1b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga23a073443e036485d6b3524bfc941bee"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga23a073443e036485d6b3524bfc941bee">riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga23a073443e036485d6b3524bfc941bee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab69db7b1e98ecc488fa4aa0bf9630a85"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gab69db7b1e98ecc488fa4aa0bf9630a85">riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gab69db7b1e98ecc488fa4aa0bf9630a85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5e529c27c08af1ed053438245eb5cc9d"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga5e529c27c08af1ed053438245eb5cc9d">riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga5e529c27c08af1ed053438245eb5cc9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga0e13e129f41385887ee1ba8df2383e2c"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga0e13e129f41385887ee1ba8df2383e2c">riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga0e13e129f41385887ee1ba8df2383e2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga3c3b33cfb0f8ee3ba9301ddf05a97ffd"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga3c3b33cfb0f8ee3ba9301ddf05a97ffd">riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga3c3b33cfb0f8ee3ba9301ddf05a97ffd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga07cedbba4cf6034908aefe869ffa4e39"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga07cedbba4cf6034908aefe869ffa4e39">riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga07cedbba4cf6034908aefe869ffa4e39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5cde8f79718970978adc52ff43398289"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga5cde8f79718970978adc52ff43398289">riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga5cde8f79718970978adc52ff43398289"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac8e1e977a81798b73c1ebc53e86a8408"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gac8e1e977a81798b73c1ebc53e86a8408">riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</td></tr>
<tr class="separator:gac8e1e977a81798b73c1ebc53e86a8408"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga24a8bace2b22cc8247209349e7d65502"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga24a8bace2b22cc8247209349e7d65502">riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</td></tr>
<tr class="separator:ga24a8bace2b22cc8247209349e7d65502"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac5b8b0207570a248406b35dc8823f2eb"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gac5b8b0207570a248406b35dc8823f2eb">riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</td></tr>
<tr class="separator:gac5b8b0207570a248406b35dc8823f2eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2e60005d04c89095aea96cad35413298"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga2e60005d04c89095aea96cad35413298">riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</td></tr>
<tr class="separator:ga2e60005d04c89095aea96cad35413298"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga71c0c612eeab3986ec8e9c229b8eb7b1"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga71c0c612eeab3986ec8e9c229b8eb7b1">riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</td></tr>
<tr class="separator:ga71c0c612eeab3986ec8e9c229b8eb7b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa35a08ed9baa6f405785f98347baad39"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gaa35a08ed9baa6f405785f98347baad39">riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</td></tr>
<tr class="separator:gaa35a08ed9baa6f405785f98347baad39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6a77b642dbfda80d5057d2ac519e8f1d"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga6a77b642dbfda80d5057d2ac519e8f1d">riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</td></tr>
<tr class="separator:ga6a77b642dbfda80d5057d2ac519e8f1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga019b31cf5bf4da54260753cba7986570"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga019b31cf5bf4da54260753cba7986570">riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</td></tr>
<tr class="separator:ga019b31cf5bf4da54260753cba7986570"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga223021d62e9b74b81cfd12fbc0a3e4dd"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga223021d62e9b74b81cfd12fbc0a3e4dd">riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</td></tr>
<tr class="separator:ga223021d62e9b74b81cfd12fbc0a3e4dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaca924f232cad9c7597204e787769c7f2"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gaca924f232cad9c7597204e787769c7f2">riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</td></tr>
<tr class="separator:gaca924f232cad9c7597204e787769c7f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gadb59521cfa72fcc7604fe34ee5facac8"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gadb59521cfa72fcc7604fe34ee5facac8">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gadb59521cfa72fcc7604fe34ee5facac8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gacd83d34d0b2cbb2a5b212363f918fb7c"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gacd83d34d0b2cbb2a5b212363f918fb7c">riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gacd83d34d0b2cbb2a5b212363f918fb7c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae7d4bde0dd1670efb9be84ec31d0d401"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gae7d4bde0dd1670efb9be84ec31d0d401">riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gae7d4bde0dd1670efb9be84ec31d0d401"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga721c3ff634c7a82c91e7f91f180b864c"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga721c3ff634c7a82c91e7f91f180b864c">riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga721c3ff634c7a82c91e7f91f180b864c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf232464c89d1773e32226f0949b8ca4d"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gaf232464c89d1773e32226f0949b8ca4d">riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gaf232464c89d1773e32226f0949b8ca4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5a001b97a602ab3cb09d64d24fa5ef80"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga5a001b97a602ab3cb09d64d24fa5ef80">riscv_nn_conv_HWC_s8_s8_s8_sym_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga5a001b97a602ab3cb09d64d24fa5ef80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga113c37953e5dbc27a6594eb643746eb5"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga113c37953e5dbc27a6594eb643746eb5">riscv_nn_conv_HWC_s8_s16_s8_sym_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga113c37953e5dbc27a6594eb643746eb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaab8918049659ff71be17a01a71828719"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gaab8918049659ff71be17a01a71828719">riscv_nn_conv_HWC_u8_u8_s8_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gaab8918049659ff71be17a01a71828719"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga112d486cdd354e98016cff06531d624c"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga112d486cdd354e98016cff06531d624c">riscv_nn_conv_HWC_u8_s8_s8_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga112d486cdd354e98016cff06531d624c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5fed7a99e6edabfb3b6e5d3a32ef62a9"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga5fed7a99e6edabfb3b6e5d3a32ef62a9">riscv_nn_conv_HWC_u8_s16_s8_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga5fed7a99e6edabfb3b6e5d3a32ef62a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab2d240e2eaf8955ecdd068ca7e165c32"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gab2d240e2eaf8955ecdd068ca7e165c32">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gab2d240e2eaf8955ecdd068ca7e165c32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga773a8061d757774699eff805abe74f1b"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga773a8061d757774699eff805abe74f1b">riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga773a8061d757774699eff805abe74f1b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga67871dd0a0e07e4292aeda95e5078fe1"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga67871dd0a0e07e4292aeda95e5078fe1">riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga67871dd0a0e07e4292aeda95e5078fe1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga81320a6752c371e4e03d457e8e40735c"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga81320a6752c371e4e03d457e8e40735c">riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga81320a6752c371e4e03d457e8e40735c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae3baf00c26cede2998df630c678330a1"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gae3baf00c26cede2998df630c678330a1">riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gae3baf00c26cede2998df630c678330a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga32e70af5e9fbc59ffcf7381fabdb9919"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga32e70af5e9fbc59ffcf7381fabdb9919">riscv_nn_conv_HWC_s8_s8_s8_sym_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga32e70af5e9fbc59ffcf7381fabdb9919"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gacdebd8d5148982ab7b1c262a91a92177"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gacdebd8d5148982ab7b1c262a91a92177">riscv_nn_conv_HWC_s8_s16_s8_sym_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gacdebd8d5148982ab7b1c262a91a92177"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga68fe37d8345759045d25428cc42040f7"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga68fe37d8345759045d25428cc42040f7">riscv_nn_conv_HWC_u8_u8_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga68fe37d8345759045d25428cc42040f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae49893d793c8ac6df418196cadeb7f20"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gae49893d793c8ac6df418196cadeb7f20">riscv_nn_conv_HWC_u8_s8_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gae49893d793c8ac6df418196cadeb7f20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga00a4706b0801befa624884122611fc06"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga00a4706b0801befa624884122611fc06">riscv_nn_conv_HWC_u8_s16_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga00a4706b0801befa624884122611fc06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae2d92a546656e55108924ba27ca26276"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gae2d92a546656e55108924ba27ca26276">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gae2d92a546656e55108924ba27ca26276"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga9eaee4cef18b08f40d833d7a6b5d8830"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga9eaee4cef18b08f40d833d7a6b5d8830">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga9eaee4cef18b08f40d833d7a6b5d8830"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4e57a7085deecb6060a540f1394af81a"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga4e57a7085deecb6060a540f1394af81a">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga4e57a7085deecb6060a540f1394af81a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gabc8b0d617a86ed037d0685a3a103f686"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gabc8b0d617a86ed037d0685a3a103f686">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gabc8b0d617a86ed037d0685a3a103f686"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1b28ebc386e404573ddc2a4ed121f6aa"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga1b28ebc386e404573ddc2a4ed121f6aa">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga1b28ebc386e404573ddc2a4ed121f6aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga00f8f34bd15dd5c58ca4dc862eb9542d"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga00f8f34bd15dd5c58ca4dc862eb9542d">riscv_nn_conv_dw_HWC_s8_s8_s8_sym</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga00f8f34bd15dd5c58ca4dc862eb9542d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga73d114c22b760478a000822022cfdf33"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga73d114c22b760478a000822022cfdf33">riscv_nn_conv_dw_HWC_s8_s16_s8_sym</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga73d114c22b760478a000822022cfdf33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga7af8b80dcc72efb34b1833f72c4f6a54"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga7af8b80dcc72efb34b1833f72c4f6a54">riscv_nn_conv_dw_HWC_u8_u8_s8_sym</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga7af8b80dcc72efb34b1833f72c4f6a54"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4cebb309d779013f326006c1beb12426"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga4cebb309d779013f326006c1beb12426">riscv_nn_conv_dw_HWC_u8_s8_s8_sym</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga4cebb309d779013f326006c1beb12426"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac461f22b2b1d925cd215ea8c21c00726"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gac461f22b2b1d925cd215ea8c21c00726">riscv_nn_conv_dw_HWC_u8_s16_s8_sym</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gac461f22b2b1d925cd215ea8c21c00726"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae6a6617bfa51e56bf1336de65f45d724"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gae6a6617bfa51e56bf1336de65f45d724">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gae6a6617bfa51e56bf1336de65f45d724"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1152e7c4a8672901ec7ddbe0a56af52d"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga1152e7c4a8672901ec7ddbe0a56af52d">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga1152e7c4a8672901ec7ddbe0a56af52d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga0131e9e63030415546c06e738f0f9f45"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga0131e9e63030415546c06e738f0f9f45">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga0131e9e63030415546c06e738f0f9f45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4afbb543d24c35eb8666bc892cc4ee45"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga4afbb543d24c35eb8666bc892cc4ee45">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga4afbb543d24c35eb8666bc892cc4ee45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga44ffadb407dc90da074d84ad332abb5f"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga44ffadb407dc90da074d84ad332abb5f">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga44ffadb407dc90da074d84ad332abb5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf23fa04ad83ead1ff955114c40c19ee4"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gaf23fa04ad83ead1ff955114c40c19ee4">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gaf23fa04ad83ead1ff955114c40c19ee4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gabc238b7d8fa8cf4c14a6249e4fd08bc6"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gabc238b7d8fa8cf4c14a6249e4fd08bc6">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gabc238b7d8fa8cf4c14a6249e4fd08bc6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2876b85637e219ca6ab2692254446912"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga2876b85637e219ca6ab2692254446912">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga2876b85637e219ca6ab2692254446912"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad04e7f4d6ff4f633dc17c39cdaae13af"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gad04e7f4d6ff4f633dc17c39cdaae13af">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gad04e7f4d6ff4f633dc17c39cdaae13af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5abc7465c684db4237884784221b3e3f"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga5abc7465c684db4237884784221b3e3f">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga5abc7465c684db4237884784221b3e3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga21a900727b07cf4b5f64ef37cb3616b2"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga21a900727b07cf4b5f64ef37cb3616b2">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf, q7_t *tmp_buf)</td></tr>
<tr class="separator:ga21a900727b07cf4b5f64ef37cb3616b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaffe21e2c04c4b6206e7cb3a6b7454624"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gaffe21e2c04c4b6206e7cb3a6b7454624">riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *bias, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *tmp_buf)</td></tr>
<tr class="separator:gaffe21e2c04c4b6206e7cb3a6b7454624"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga13a646cc7f2d1eff194ceb09219aaad6"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga13a646cc7f2d1eff194ceb09219aaad6">riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</a> (const uint16_t in_tensor_ch)</td></tr>
<tr class="separator:ga13a646cc7f2d1eff194ceb09219aaad6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4c3bf56f976e682acbe89995e0b86b2e"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga4c3bf56f976e682acbe89995e0b86b2e">riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t pad_x, const uint16_t stride_x, const int32_t *bias, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga4c3bf56f976e682acbe89995e0b86b2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad37e8489144806520a267f5549bdee84"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gad37e8489144806520a267f5549bdee84">riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</a> (const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y)</td></tr>
<tr class="separator:gad37e8489144806520a267f5549bdee84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5e3a64ba631b8c441e39ef43f0c5fd1a"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga5e3a64ba631b8c441e39ef43f0c5fd1a">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *bias, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga5e3a64ba631b8c441e39ef43f0c5fd1a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gade20f23c0dd7a95b881e5264eb2bc948"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gade20f23c0dd7a95b881e5264eb2bc948">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</a> (const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y)</td></tr>
<tr class="separator:gade20f23c0dd7a95b881e5264eb2bc948"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4da9f20943c47ba73ed488479184af8b"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga4da9f20943c47ba73ed488479184af8b">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *bias, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t dilation_x, const int32_t dilation_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga4da9f20943c47ba73ed488479184af8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaac59b1a72098f4dde21117f04ff1784f"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gaac59b1a72098f4dde21117f04ff1784f">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated_get_buffer_size</a> (const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y)</td></tr>
<tr class="separator:gaac59b1a72098f4dde21117f04ff1784f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab716338311449b90be0e572b197f1c15"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gab716338311449b90be0e572b197f1c15">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any</a> (const q15_t *in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const q7_t *ker_weight, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int64_t *bias, q15_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_ch, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t dilation_x, const int32_t dilation_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gab716338311449b90be0e572b197f1c15"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6646acdf91fb6a02cddc71c7cacf1e2f"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga6646acdf91fb6a02cddc71c7cacf1e2f">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</a> (const int32_t in_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y)</td></tr>
<tr class="separator:ga6646acdf91fb6a02cddc71c7cacf1e2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga9495e92d12a80c19899c6534ac23a242"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga9495e92d12a80c19899c6534ac23a242">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any</a> (const q15_t *in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const q7_t *ker_weight, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int64_t *bias, q15_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_ch, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga9495e92d12a80c19899c6534ac23a242"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae778b1228c3f07fa8e440456bcd1acf3"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gae778b1228c3f07fa8e440456bcd1acf3">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any_get_buffer_size</a> (const int32_t in_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y)</td></tr>
<tr class="separator:gae778b1228c3f07fa8e440456bcd1acf3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga0e6d3305f85fa68a83acf15ed5b091e4"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga0e6d3305f85fa68a83acf15ed5b091e4">riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *bias, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga0e6d3305f85fa68a83acf15ed5b091e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae9e421731a7d68af393b49699bb4997a"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gae9e421731a7d68af393b49699bb4997a">riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym_get_buffer_size</a> (const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y)</td></tr>
<tr class="separator:gae9e421731a7d68af393b49699bb4997a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga46a7ec8b73c8c88c4c18e81200c6424b"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga46a7ec8b73c8c88c4c18e81200c6424b">riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym</a> (const q15_t *in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const q7_t *ker_weight, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int64_t *bias, q15_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_ch, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t dilation_x, const int32_t dilation_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:ga46a7ec8b73c8c88c4c18e81200c6424b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaeb04f0eadb58e81adcf264820ea9056a"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gaeb04f0eadb58e81adcf264820ea9056a">riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym_get_buffer_size</a> (const int32_t in_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t dilation_x, const int32_t dilation_y)</td></tr>
<tr class="separator:gaeb04f0eadb58e81adcf264820ea9056a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga3178f7c5258c3f0ed069ad34989a9756"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga3178f7c5258c3f0ed069ad34989a9756">riscv_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any</a> (const int8_t *in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int8_t *ker_weight, const int32_t out_tensor_ch, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int32_t *bias, int8_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t dilation_x, const int32_t dilation_y, int16_t *tmp_buf)</td></tr>
<tr class="separator:ga3178f7c5258c3f0ed069ad34989a9756"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa324a39d61b24176834dc04882e972fe"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gaa324a39d61b24176834dc04882e972fe">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ch_mult, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *bias, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t dilation_x, const uint16_t dilation_y, q15_t *tmp_buf)</td></tr>
<tr class="separator:gaa324a39d61b24176834dc04882e972fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae58a1f52f9db32cf3d549e338459df52"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gae58a1f52f9db32cf3d549e338459df52">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *bias, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t dilation_x, const uint16_t dilation_y, q15_t *in_tmp_buf)</td></tr>
<tr class="separator:gae58a1f52f9db32cf3d549e338459df52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2b66cb29b91f373cae715f5e8a6b0d41"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga2b66cb29b91f373cae715f5e8a6b0d41">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</a> (const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y)</td></tr>
<tr class="separator:ga2b66cb29b91f373cae715f5e8a6b0d41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga70c6a08d04a5cdeffa121992f017a5c8"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga70c6a08d04a5cdeffa121992f017a5c8">riscv_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any</a> (const uint8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint8_t *ker_weight, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const int16_t ch_mult, const int16_t pad_x, const int16_t pad_y, const int16_t stride_x, const int16_t stride_y, const int16_t dilation_x, const int16_t dilation_y, const int32_t *bias, const int32_t in_offset, const int32_t ker_offset, const int32_t out_offset, uint8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t act_min, const int32_t act_max, const int32_t out_shift, const int32_t out_scale)</td></tr>
<tr class="separator:ga70c6a08d04a5cdeffa121992f017a5c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga901b8737e18570edc8b862241d48fbb5"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga901b8737e18570edc8b862241d48fbb5">riscv_nn_conv_dw_HWC_s16_s16_s8_asym_bias_any</a> (const int16_t *in_tensor, const uint16_t in_tensor_batch, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const int8_t *ker_weight, const uint16_t ch_mult, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *bias, int16_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t dilation_x, const uint16_t dilation_y, int16_t *tmp_buf)</td></tr>
<tr class="separator:ga901b8737e18570edc8b862241d48fbb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga41775a9f700b666336a779f1469e264b"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#ga41775a9f700b666336a779f1469e264b">riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ch_mult, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *bias, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t dilation_x, const uint16_t dilation_y, q15_t *tmp_buf)</td></tr>
<tr class="separator:ga41775a9f700b666336a779f1469e264b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab354e5c6b7fd27de531a81c1f6cb67ae"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Convolution.html#gab354e5c6b7fd27de531a81c1f6cb67ae">riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym_get_buffer_size</a> (const uint16_t in_tensor_ch, const uint16_t ch_mult, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x)</td></tr>
<tr class="separator:gab354e5c6b7fd27de531a81c1f6cb67ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<ul>
<li>Algorithm flow of convolution functions with shift-based quantization <div class="image">
<img src="shift-based_convolution_algorithm_flowchart.jpg" alt="" width="600px"/>
<div class="caption">
Figure 4. Algorithm flowchart of convolution functions with shift-based quantization</div></div>
</li>
<li>Algorithm flow of convolution functions with symmetric quantization <div class="image">
<img src="symmetric_convolution_algorithm_flowchart.jpg" alt="" width="600px"/>
<div class="caption">
Figure 5. Algorithm flowchart of convolution functions with symmetric quantization</div></div>
</li>
<li>Algorithm flow for convolution functions with asymmetric quantization <div class="image">
<img src="asymmetric_convolution_algorithm_flowchart.jpg" alt="" width="600px"/>
<div class="caption">
Figure 6. Algorithm flowchart of convolution functions with asymmetric quantization</div></div>
 </li>
</ul>
<h2 class="groupheader">Function Documentation</h2>
<a id="ga43ac72a8511cbaf132ae0edc1fdb6276"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga43ac72a8511cbaf132ae0edc1fdb6276">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
</ul>
</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 160x120x20 input tensor with a 1x1 kernel and generate a</span></div>
<div class="line"><span class="comment">//160x120x8 output tensor. Let both dimensions padding be 0 and their</span></div>
<div class="line"><span class="comment">//stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_X 160</span></div>
<div class="line"><span class="preprocessor">#define IN_Y 120</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 8</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_X 1</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_Y 1</span></div>
<div class="line"><span class="preprocessor">#define PAD_X 0</span></div>
<div class="line"><span class="preprocessor">#define PAD_Y 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_X 1</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_Y 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6       //Scale up the bias by 2^6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 9        //Scale down the output tensor by 1/2^9</span></div>
<div class="line"><span class="preprocessor">#define OUT_X 160</span></div>
<div class="line"><span class="preprocessor">#define OUT_Y 120</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_X * IN_Y] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};</div>
<div class="line">q7_t bias[OUT_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[2 * IN_CH * KER_DIM_X * KER_DIM_Y] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_X * OUT_Y];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#ga43ac72a8511cbaf132ae0edc1fdb6276">riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any</a>(in_data, IN_X, IN_Y ,</div>
<div class="line">    IN_CH, weight, OUT_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X,</div>
<div class="line">    STRIDE_Y, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_X, OUT_Y,</div>
<div class="line">    in_tmp_buf, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="ga76dd8cc6a11522305e9ec5ddb968877e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga76dd8cc6a11522305e9ec5ddb968877e">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs signed 8-bit integer convolution for RGB images with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-vector enabled and its size must be "out_tensor_ch * (3 * ker_dim *
                                 ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 28x28x3 input tensor with a 5x5 kernel and generate a 24x24x20</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 28</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 24</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[3 * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q7_t weight[3 * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q7_t bias[OUT_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[2 * 3 * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#ga76dd8cc6a11522305e9ec5ddb968877e">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias</a>(in_data, IN_DIM, weight, OUT_CH,</div>
<div class="line">    KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_DIM,</div>
<div class="line">    in_tmp_buf, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="ga0114bf25be0e886cfc5082157ce217dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga0114bf25be0e886cfc5082157ce217dd">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>wt_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast signed 8-bit integer convolution for RGB images with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 28x28x3 input tensor with a 5x5 kernel and generate a 24x24x20</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 28</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 24</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[3 * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q7_t weight[3 * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q7_t bias[OUT_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[2 * (3 * KER_DIM * KER_DIM + 1)] = {0};</div>
<div class="line">q15_t wt_tmp_buf[OUT_CH * (3 * KER_DIM * KER_DIM + 1)];</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#ga0114bf25be0e886cfc5082157ce217dd">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast</a>(in_data, IN_DIM, weight,</div>
<div class="line">    OUT_CH, KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data,</div>
<div class="line">    OUT_DIM, in_tmp_buf, wt_tmp_buf);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="ga6349568d6ce5be71ab37670fab334cf9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6349568d6ce5be71ab37670fab334cf9">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_sft_bias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs signed 8-bit integer convolution with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 28x28x1 input tensor with a 5x5 kernel and generate a 24x24x20</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 28</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 1</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 24</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q7_t bias[OUT_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[2 * IN_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#ga6349568d6ce5be71ab37670fab334cf9">riscv_nn_conv_HWC_s8_s8_s8_sft_bias</a>(in_data, IN_DIM, IN_CH, weight, OUT_CH,</div>
<div class="line">    KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_DIM,</div>
<div class="line">    in_tmp_buf, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="ga75095bb9dbfe0344ca04324ac11493bb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga75095bb9dbfe0344ca04324ac11493bb">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs signed 8-bit integer convolution in any x and y dimensions with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 160x120x3 input tensor with a 3x5 kernel and generate a 80x59x5</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 1 and their stride be 2.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_X 160</span></div>
<div class="line"><span class="preprocessor">#define IN_Y 120</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 3</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 5</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_X 3</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_Y 5</span></div>
<div class="line"><span class="preprocessor">#define PAD_X 1</span></div>
<div class="line"><span class="preprocessor">#define PAD_Y 1</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_X 2</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_Y 2</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 9</span></div>
<div class="line"><span class="preprocessor">#define OUT_X 40</span></div>
<div class="line"><span class="preprocessor">#define OUT_Y 30</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_X * IN_Y] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};</div>
<div class="line">q7_t bias[OUT_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[2 * IN_CH * KER_DIM_X * KER_DIM_Y] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_X * OUT_Y];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#ga75095bb9dbfe0344ca04324ac11493bb">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any</a>(in_data, IN_X, IN_Y , IN_CH, weight,</div>
<div class="line">    OUT_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X, STRIDE_Y, bias,</div>
<div class="line">    BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_X, OUT_Y, in_tmp_buf, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="ga37169c70f07977dec222eaa63f82a7b1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga37169c70f07977dec222eaa63f82a7b1">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast signed 8-bit integer convolution with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 12x12x20 input tensor with a 5x5 kernel and generate a 8x8x50</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 12</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 20</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 50</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 8</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q7_t bias[OUT_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[2 * IN_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#ga37169c70f07977dec222eaa63f82a7b1">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast</a>(in_data, IN_DIM, IN_CH, weight,</div>
<div class="line">    OUT_CH, KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data,</div>
<div class="line">    OUT_DIM, in_tmp_buf, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gaff8aeef6b452c567ed13804449576f11"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaff8aeef6b452c567ed13804449576f11">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast signed 8-bit integer convolution in any x and y dimensions with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 160x120x20 input tensor with a 3x5 kernel and generate a</span></div>
<div class="line"><span class="comment">//80x59x8 output tensor. Let both dimensions padding be 1 and their stride</span></div>
<div class="line"><span class="comment">//be 2.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_X 160</span></div>
<div class="line"><span class="preprocessor">#define IN_Y 120</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 8</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_X 3</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_Y 5</span></div>
<div class="line"><span class="preprocessor">#define PAD_X 1</span></div>
<div class="line"><span class="preprocessor">#define PAD_Y 1</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_X 2</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_Y 2</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 9</span></div>
<div class="line"><span class="preprocessor">#define OUT_X 80</span></div>
<div class="line"><span class="preprocessor">#define OUT_Y 59</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_X * IN_Y] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};</div>
<div class="line">q7_t bias[OUT_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[2 * IN_CH * KER_DIM_X * KER_DIM_Y] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_Y * OUT_X];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#gaff8aeef6b452c567ed13804449576f11">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any</a>(in_data, IN_W, IN_Y , IN_CH,</div>
<div class="line">    weight, OUT_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X, STRIDE_Y,</div>
<div class="line">    bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_X, OUT_Y, in_tmp_buf,</div>
<div class="line">    NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gafb242463d8fe330aae86ed20c35a62db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gafb242463d8fe330aae86ed20c35a62db">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s16_s16_s16_sft_bias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s16_s16_s16_sft_bias </td>
          <td>(</td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs signed 16-bit integer convolution with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "in_tensor_ch * ker_dim * ker_dim". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 28x28x1 input tensor with a 5x5 kernel and generate a 24x24x20</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 28</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 1</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 24</span></div>
<div class="line"> </div>
<div class="line">q15_t input_data[IN_CH * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q15_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q15_t bias[OUT_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[IN_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q15_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#gafb242463d8fe330aae86ed20c35a62db">riscv_nn_conv_HWC_s16_s16_s16_sft_bias</a>(input_data, IN_DIM, IN_CH, weight,</div>
<div class="line">    OUT_CH, KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data,</div>
<div class="line">    OUT_DIM, in_tmp_buf, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gabfb034c6133f003ed595846e8e9ecfa4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gabfb034c6133f003ed595846e8e9ecfa4">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast signed 16-bit integer convolution with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch, out_tensor_ch and out_tensor_dim are multiples of 2.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 28x28x4 input tensor with a 5x5 kernel and generate a 24x24x8</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 28</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 4</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 8</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 24</span></div>
<div class="line"> </div>
<div class="line">q15_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q15_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q15_t bias[OUT_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[IN_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q15_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#gabfb034c6133f003ed595846e8e9ecfa4">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast</a>(in_data, IN_DIM, IN_CH, weight,</div>
<div class="line">    OUT_CH, KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data,</div>
<div class="line">    OUT_DIM, in_tmp_buf, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="ga23816c40e33fa7fa6e00ad6a8353f08b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga23816c40e33fa7fa6e00ad6a8353f08b">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast signed 16-bit integer convolution in any x and y dimensions with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that both in_tensor_ch and out_tensor_ch are multiples of 2.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 160x120x20 input tensor with a 3x5 kernel and generate a</span></div>
<div class="line"><span class="comment">//80x59x8 output tensor. Let both dimensions padding be 1 and their stride</span></div>
<div class="line"><span class="comment">//be 2.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_X 160</span></div>
<div class="line"><span class="preprocessor">#define IN_Y 120</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 8</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_X 3</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_Y 5</span></div>
<div class="line"><span class="preprocessor">#define PAD_X 1</span></div>
<div class="line"><span class="preprocessor">#define PAD_Y 1</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_X 2</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_Y 2</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 9</span></div>
<div class="line"><span class="preprocessor">#define OUT_X 80</span></div>
<div class="line"><span class="preprocessor">#define OUT_Y 59</span></div>
<div class="line"> </div>
<div class="line">q15_t in_data[IN_CH * IN_X * IN_Y] = {...};</div>
<div class="line">q15_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};</div>
<div class="line">q15_t bias[OUT_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[2 * IN_CH * KER_DIM_X  * KER_DIM_Y] = {0};</div>
<div class="line">q15_t out_data[OUT_CH * OUT_X * OUT_Y];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#ga23816c40e33fa7fa6e00ad6a8353f08b">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any</a>(in_data, IN_X, IN_Y , IN_CH,</div>
<div class="line">    weight, OUT_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X, STRIDE_Y,</div>
<div class="line">    bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_X, OUT_Y, in_tmp_buf,</div>
<div class="line">    NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gab4c2811e5fde9441edd373a492d8cc72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab4c2811e5fde9441edd373a492d8cc72">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs signed 8-bit integer depthwise convolution with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 11x11x28 input tensor with a 3x3 kernel and generate a 9x9x48</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 11</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 28</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 48</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 3</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 7</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 9</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM * KER_DIM * IN_CH] = {...};</div>
<div class="line">q7_t bias[IN_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[2 * OUT_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#gab4c2811e5fde9441edd373a492d8cc72">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias</a>(in_data, IN_DIM, IN_CH, weight,</div>
<div class="line">    OUT_CH, KER_DIM, PAD, STRIDE, bias, 0, OUT_RSHIFT, out_data, OUT_DIM,</div>
<div class="line">    in_tmp_buf, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="ga01c17cfd9b6bc224bb2329fa9ac7668e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga01c17cfd9b6bc224bb2329fa9ac7668e">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_lshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs signed 8-bit integer depthwise convolution in any x and y dimensions with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Perform a depth-wise convolution for a 79x59x12 input tensor with a 3x3</span></div>
<div class="line"><span class="comment">//kernel and generate a 77x57x12 output tensor. Let both dimensions padding</span></div>
<div class="line"><span class="comment">//be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM_X 79</span></div>
<div class="line"><span class="preprocessor">#define IN_DIM_Y 59</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 12</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 12</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 3</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_SHIFT 0</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 7</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM_X 77</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM_Y 57</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_DIM_X * IN_DIM_Y] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM * KER_DIM * IN_CH] = {...};</div>
<div class="line">q7_t bias[IN_CH] = {...};</div>
<div class="line">q15_t in_tmp_buf[2 * OUT_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM_X * OUT_DIM_Y];</div>
<div class="line"> </div>
<div class="line"><a class="code" href="group__Convolution.html#ga01c17cfd9b6bc224bb2329fa9ac7668e">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any</a>(in_data, IN_DIM_X, IN_DIM_Y,</div>
<div class="line">    IN_CH, weight, OUT_CH, KER_DIM, KER_DIM, PAD, PAD, STRIDE, STRIDE, bias,</div>
<div class="line">    BIAS_SHIFT, OUT_RSHIFT, out_data, OUT_DIM_X, OUT_DIM_Y, in_tmp_buf,</div>
<div class="line">    NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gad252997444bbf90fb0d75fd643236dec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad252997444bbf90fb0d75fd643236dec">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga40987111c7ab7c94dd9f68ed119e6d05"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga40987111c7ab7c94dd9f68ed119e6d05">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga96c008665236c846c00df6299a72cc1b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga96c008665236c846c00df6299a72cc1b">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga23a073443e036485d6b3524bfc941bee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga23a073443e036485d6b3524bfc941bee">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="gab69db7b1e98ecc488fa4aa0bf9630a85"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab69db7b1e98ecc488fa4aa0bf9630a85">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga5e529c27c08af1ed053438245eb5cc9d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5e529c27c08af1ed053438245eb5cc9d">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to 2 * in_tensor_ch * ker_dim_x * ker_dim_y. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga0e13e129f41385887ee1ba8df2383e2c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga0e13e129f41385887ee1ba8df2383e2c">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to 2 * in_tensor_ch * ker_dim_x * ker_dim_y. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga3c3b33cfb0f8ee3ba9301ddf05a97ffd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3c3b33cfb0f8ee3ba9301ddf05a97ffd">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga07cedbba4cf6034908aefe869ffa4e39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga07cedbba4cf6034908aefe869ffa4e39">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to 2 * in_tensor_ch * ker_dim_x * ker_dim_y. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga5cde8f79718970978adc52ff43398289"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5cde8f79718970978adc52ff43398289">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="gac8e1e977a81798b73c1ebc53e86a8408"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac8e1e977a81798b73c1ebc53e86a8408">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>wt_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution on RGB images for signed 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga24a8bace2b22cc8247209349e7d65502"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga24a8bace2b22cc8247209349e7d65502">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>wt_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution on RGB images for signed 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gac5b8b0207570a248406b35dc8823f2eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac5b8b0207570a248406b35dc8823f2eb">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>wt_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution on RGB images for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga2e60005d04c89095aea96cad35413298"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2e60005d04c89095aea96cad35413298">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>wt_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution on RGB images for unsigned 8-bit integer inputs and signed 8-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga71c0c612eeab3986ec8e9c229b8eb7b1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga71c0c612eeab3986ec8e9c229b8eb7b1">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>wt_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution on RGB images for unsigned 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaa35a08ed9baa6f405785f98347baad39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa35a08ed9baa6f405785f98347baad39">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>wt_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution on RGB images for signed 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga6a77b642dbfda80d5057d2ac519e8f1d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6a77b642dbfda80d5057d2ac519e8f1d">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>wt_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution on RGB images for signed 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga019b31cf5bf4da54260753cba7986570"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga019b31cf5bf4da54260753cba7986570">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>wt_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution on RGB images for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga223021d62e9b74b81cfd12fbc0a3e4dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga223021d62e9b74b81cfd12fbc0a3e4dd">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>wt_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution on RGB images for unsigned 8-bit integer inputs and signed 8-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaca924f232cad9c7597204e787769c7f2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaca924f232cad9c7597204e787769c7f2">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>wt_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution on RGB images for unsigned 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gadb59521cfa72fcc7604fe34ee5facac8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gadb59521cfa72fcc7604fe34ee5facac8">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for signed 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gacd83d34d0b2cbb2a5b212363f918fb7c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gacd83d34d0b2cbb2a5b212363f918fb7c">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gae7d4bde0dd1670efb9be84ec31d0d401"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae7d4bde0dd1670efb9be84ec31d0d401">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga721c3ff634c7a82c91e7f91f180b864c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga721c3ff634c7a82c91e7f91f180b864c">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaf232464c89d1773e32226f0949b8ca4d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf232464c89d1773e32226f0949b8ca4d">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga5a001b97a602ab3cb09d64d24fa5ef80"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5a001b97a602ab3cb09d64d24fa5ef80">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for signed 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga113c37953e5dbc27a6594eb643746eb5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga113c37953e5dbc27a6594eb643746eb5">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s16_s8_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s16_s8_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaab8918049659ff71be17a01a71828719"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaab8918049659ff71be17a01a71828719">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_u8_s8_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_u8_s8_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga112d486cdd354e98016cff06531d624c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga112d486cdd354e98016cff06531d624c">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s8_s8_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s8_s8_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga5fed7a99e6edabfb3b6e5d3a32ef62a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5fed7a99e6edabfb3b6e5d3a32ef62a9">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s16_s8_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s16_s8_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gab2d240e2eaf8955ecdd068ca7e165c32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab2d240e2eaf8955ecdd068ca7e165c32">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga773a8061d757774699eff805abe74f1b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga773a8061d757774699eff805abe74f1b">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga67871dd0a0e07e4292aeda95e5078fe1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga67871dd0a0e07e4292aeda95e5078fe1">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga81320a6752c371e4e03d457e8e40735c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga81320a6752c371e4e03d457e8e40735c">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gae3baf00c26cede2998df630c678330a1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae3baf00c26cede2998df630c678330a1">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga32e70af5e9fbc59ffcf7381fabdb9919"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga32e70af5e9fbc59ffcf7381fabdb9919">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gacdebd8d5148982ab7b1c262a91a92177"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gacdebd8d5148982ab7b1c262a91a92177">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s16_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s16_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga68fe37d8345759045d25428cc42040f7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga68fe37d8345759045d25428cc42040f7">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_u8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_u8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gae49893d793c8ac6df418196cadeb7f20"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae49893d793c8ac6df418196cadeb7f20">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga00a4706b0801befa624884122611fc06"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga00a4706b0801befa624884122611fc06">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_u8_s16_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_u8_s16_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gae2d92a546656e55108924ba27ca26276"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae2d92a546656e55108924ba27ca26276">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for signed 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga9eaee4cef18b08f40d833d7a6b5d8830"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga9eaee4cef18b08f40d833d7a6b5d8830">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga4e57a7085deecb6060a540f1394af81a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4e57a7085deecb6060a540f1394af81a">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gabc8b0d617a86ed037d0685a3a103f686"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gabc8b0d617a86ed037d0685a3a103f686">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga1b28ebc386e404573ddc2a4ed121f6aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1b28ebc386e404573ddc2a4ed121f6aa">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga00f8f34bd15dd5c58ca4dc862eb9542d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga00f8f34bd15dd5c58ca4dc862eb9542d">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s8_s8_sym()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sym </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for signed 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga73d114c22b760478a000822022cfdf33"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga73d114c22b760478a000822022cfdf33">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s16_s8_sym()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s16_s8_sym </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga7af8b80dcc72efb34b1833f72c4f6a54"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga7af8b80dcc72efb34b1833f72c4f6a54">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_u8_s8_sym()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_u8_s8_sym </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to (in_tensor_ch * ker_dim * ker_dim + 1) / 2. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga4cebb309d779013f326006c1beb12426"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4cebb309d779013f326006c1beb12426">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_s8_s8_sym()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_s8_s8_sym </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs, and with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gac461f22b2b1d925cd215ea8c21c00726"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac461f22b2b1d925cd215ea8c21c00726">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_s16_s8_sym()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_s16_s8_sym </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gae6a6617bfa51e56bf1336de65f45d724"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae6a6617bfa51e56bf1336de65f45d724">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga1152e7c4a8672901ec7ddbe0a56af52d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1152e7c4a8672901ec7ddbe0a56af52d">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga0131e9e63030415546c06e738f0f9f45"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga0131e9e63030415546c06e738f0f9f45">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga4afbb543d24c35eb8666bc892cc4ee45"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4afbb543d24c35eb8666bc892cc4ee45">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga44ffadb407dc90da074d84ad332abb5f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga44ffadb407dc90da074d84ad332abb5f">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaf23fa04ad83ead1ff955114c40c19ee4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf23fa04ad83ead1ff955114c40c19ee4">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s8_s8_sym_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sym_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gabc238b7d8fa8cf4c14a6249e4fd08bc6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gabc238b7d8fa8cf4c14a6249e4fd08bc6">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s16_s8_sym_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s16_s8_sym_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga2876b85637e219ca6ab2692254446912"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2876b85637e219ca6ab2692254446912">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_u8_s8_sym_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_u8_s8_sym_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gad04e7f4d6ff4f633dc17c39cdaae13af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad04e7f4d6ff4f633dc17c39cdaae13af">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_s8_s8_sym_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_s8_s8_sym_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga5abc7465c684db4237884784221b3e3f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5abc7465c684db4237884784221b3e3f">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_s16_s8_sym_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_s16_s8_sym_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp is enabled and its size must be equal to "(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga21a900727b07cf4b5f64ef37cb3616b2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga21a900727b07cf4b5f64ef37cb3616b2">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_sym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void riscv_nn_conv_HWC_s8_s8_s8_sym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pre_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>post_rshift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None </dd></dl>

</div>
</div>
<a id="gaffe21e2c04c4b6206e7cb3a6b7454624"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaffe21e2c04c4b6206e7cb3a6b7454624">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1x1 kernels convolution for signed 8-bit interger inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_batch</td><td>size of input tensor batches </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>offset value for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>offset value for the input tensor. It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga13a646cc7f2d1eff194ceb09219aaad6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga13a646cc7f2d1eff194ceb09219aaad6">&#9670;&nbsp;</a></span>riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function is used to obtain the required size, in bytes, for the input temporary buffer of riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the size required by the temporary buffer. </dd></dl>

</div>
</div>
<a id="ga4c3bf56f976e682acbe89995e0b86b2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4c3bf56f976e682acbe89995e0b86b2e">&#9670;&nbsp;</a></span>riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs 1xn kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_batch</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>offset value for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>offset value for the input tensor. It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its needed size can be obtained by calling riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that out_tensor_dim_x is a multiple of 4.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </dd></dl>

</div>
</div>
<a id="gad37e8489144806520a267f5549bdee84"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad37e8489144806520a267f5549bdee84">&#9670;&nbsp;</a></span>riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function is used to obtain the required size, in bytes, for the input temporary buffer of riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel. It is always 1. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the needed size by the temporary buffer. </dd></dl>

</div>
</div>
<a id="ga5e3a64ba631b8c441e39ef43f0c5fd1a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5e3a64ba631b8c441e39ef43f0c5fd1a">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_batch</td><td>size of input tensor batches </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>offset value for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>offset value for the input tensor. It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its needed size could be obtained by calling riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>bias could be a null pointer as the bias vector is optional for this function.</li>
<li>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="gade20f23c0dd7a95b881e5264eb2bc948"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gade20f23c0dd7a95b881e5264eb2bc948">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function is used to obtain the required size, in bytes, for the input temporary buffer of riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the required size of the temporary buffer. </dd></dl>

</div>
</div>
<a id="ga4da9f20943c47ba73ed488479184af8b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4da9f20943c47ba73ed488479184af8b">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>dilation_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>dilation_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs dilated convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_batch</td><td>size of input tensor batches </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>offset value for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>offset value for the input tensor. It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dilation factor for the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dilation factor for the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its needed size could be obtained by calling riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated_get_buffer_size. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>bias could be a null pointer as the bias vector is optional for this function.</li>
<li>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="gaac59b1a72098f4dde21117f04ff1784f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaac59b1a72098f4dde21117f04ff1784f">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function is used to obtain the required size, in bytes, for the input temporary buffer of riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int32_t </dd></dl>

</div>
</div>
<a id="gab716338311449b90be0e572b197f1c15"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab716338311449b90be0e572b197f1c15">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>dilation_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>dilation_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs convolution for signed 16-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_batch</td><td>size of input tensor batches </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on the outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on the outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -32768 to 32767. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -32768 to 32767. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dilation factor for the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dilation factor for the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>bias could be a null pointer as the bias vector is optional for this function.</li>
<li>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga6646acdf91fb6a02cddc71c7cacf1e2f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6646acdf91fb6a02cddc71c7cacf1e2f">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function is used to obtain the required size, in bytes, for the input temporary buffer of riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the required size of the temporary buffer. </dd></dl>

</div>
</div>
<a id="ga9495e92d12a80c19899c6534ac23a242"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga9495e92d12a80c19899c6534ac23a242">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs convolution for signed 16-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. When compared with riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any, this function uses a faster algorithm but there has more constraints on input parameters. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_batch</td><td>size of input tensor batches </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -32768 to 32767. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -32768 to 32767. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The product of (in_tensor_ch * ker_dim_x * ker_dim_x) should be less than or equal to 512.</li>
<li>bias could be a null pointer as the bias vector is optional for this function.</li>
<li>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="gae778b1228c3f07fa8e440456bcd1acf3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae778b1228c3f07fa8e440456bcd1acf3">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function is used to obtain the required size, in bytes, for the input temporary buffer of riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the required size of the temporary buffer. </dd>
<dd>
int32_t </dd></dl>

</div>
</div>
<a id="ga0e6d3305f85fa68a83acf15ed5b091e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga0e6d3305f85fa68a83acf15ed5b091e4">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This is a wrapper function for riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any, riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any and riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any. This function calls one among the three convolution functions according to the provided parameters. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_batch</td><td>size of input tensor batches </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>offset value for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>offset value for the input tensor It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its needed size could be obtained by calling riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym_get_buffer_size. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </dd></dl>

</div>
</div>
<a id="gae9e421731a7d68af393b49699bb4997a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae9e421731a7d68af393b49699bb4997a">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function is used to obtain the required size, in bytes, for the input temporary buffer of riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_batch</td><td>size of input tensor batches </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the required size of the temporary buffer. </dd></dl>

</div>
</div>
<a id="ga46a7ec8b73c8c88c4c18e81200c6424b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga46a7ec8b73c8c88c4c18e81200c6424b">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym </td>
          <td>(</td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>dilation_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>dilation_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This is a wrapper function for riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any and riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any. This function calls one of the two convolution functions according to the provided parameters. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_batch</td><td>size of input tensor batches </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -32768 to 32767. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -32768 to 32767. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dilation factor for the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dilation factor for the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>bias could be a null pointer as the bias vector is optional for this function.</li>
<li>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="gaeb04f0eadb58e81adcf264820ea9056a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaeb04f0eadb58e81adcf264820ea9056a">&#9670;&nbsp;</a></span>riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>dilation_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>dilation_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function is used to obtain the required size, in bytes, for the input temporary buffer of riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dilation factor for the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dilation factor for the y dimension </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the required size of the temporary buffer. </dd></dl>

</div>
</div>
<a id="ga3178f7c5258c3f0ed069ad34989a9756"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3178f7c5258c3f0ed069ad34989a9756">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>dilation_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>dilation_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int16_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise 3x3 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>offset value for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>offset value for the input tensor It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch and pad_x is less than or equal to 1.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </dd></dl>

</div>
</div>
<a id="gaa324a39d61b24176834dc04882e972fe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa324a39d61b24176834dc04882e972fe">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ch_mult</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for signed 8-bit interger inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels. out_tensor_ch is equal to "ch_mult *
                                     in_tensor_ch". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ch_mult</td><td>multiplier of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>value of offset for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>value of offset for the input tensor It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dilation factor for the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dilation factor for the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>bias could be a null pointer as the bias vector is optional for this function.</li>
<li>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="gae58a1f52f9db32cf3d549e338459df52"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae58a1f52f9db32cf3d549e338459df52">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>in_tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs fast depthwise convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>offset value for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>offset value for the input tensor. It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its needed size could be obtained by calling riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </dd></dl>

</div>
</div>
<a id="ga2b66cb29b91f373cae715f5e8a6b0d41"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2b66cb29b91f373cae715f5e8a6b0d41">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function is used to obtain the required size, in bytes, for the input temporary buffer of riscv_nn_conv_dw_HWC_s8_fast_any. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the size required by the temporary buffer. </dd></dl>

</div>
</div>
<a id="ga70c6a08d04a5cdeffa121992f017a5c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga70c6a08d04a5cdeffa121992f017a5c8">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const uint8_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint8_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t&#160;</td>
          <td class="paramname"><em>ch_mult</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t&#160;</td>
          <td class="paramname"><em>dilation_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t&#160;</td>
          <td class="paramname"><em>dilation_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>ker_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint8_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_scale</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ch_mult</td><td>multiplier of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>offset value for the input tensor. It should be in the range of -255 to 0. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_offset</td><td>offset value for the filter kernel. It should be in the range of -255 to 0. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>offset value for the output tensor. It should be in the range of 0 to 255. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of 0 to 255. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of 0 to 255. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>shift amount for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>scaling value for the quantization on outputs </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that both ch_mult and ker_dim_x are multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </dd></dl>

</div>
</div>
<a id="ga901b8737e18570edc8b862241d48fbb5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga901b8737e18570edc8b862241d48fbb5">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_s16_s16_s8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_s16_s16_s8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const int16_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ch_mult</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int16_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int16_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function performs depthwise convolution for signed 16-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_batch</td><td>number of input tensor batches </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ch_mult</td><td>multiplier of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on the outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on the outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -32768 to 32767. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -32768 to 32767. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dilation factor for the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dilation factor for the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>bias could be a null pointer as the bias vector is optional for this function.</li>
<li>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga41775a9f700b666336a779f1469e264b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga41775a9f700b666336a779f1469e264b">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>in_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>ker_weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ch_mult</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>out_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>out_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_tensor_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>out_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>in_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_min</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>act_max</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>tmp_buf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This is a wrapper function for riscv_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any, riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any and riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any. This function calls one among the three depthwise convolution functions according to the provided parameters. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels. out_tensor_ch is equal to ch_mult * in_tensor_ch. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ch_mult</td><td>multiplier of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for the quantization on outputs </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>offset value for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>offset value for the input tensor. It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value that the output tensor is limited to. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its needed size could be obtained by calling riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym_get_buffer_size. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>During the quantization process, a positive out_shift value is used to left shift calculation results whereas a negative one is used to right shift. </dd></dl>

</div>
</div>
<a id="gab354e5c6b7fd27de531a81c1f6cb67ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab354e5c6b7fd27de531a81c1f6cb67ae">&#9670;&nbsp;</a></span>riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>in_tensor_ch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ch_mult</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>ker_dim_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pad_x</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function is used to obtain the required size, in bytes, for the input temporary buffer of riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ch_mult</td><td>multiplier of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the size required by the temporary buffer. </dd></dl>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<div class="ttc" id="agroup__Convolution_html_gafb242463d8fe330aae86ed20c35a62db"><div class="ttname"><a href="group__Convolution.html#gafb242463d8fe330aae86ed20c35a62db">riscv_nn_conv_HWC_s16_s16_s16_sft_bias</a></div><div class="ttdeci">int32_t riscv_nn_conv_HWC_s16_s16_s16_sft_bias(const q15_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q15_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q15_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</div><div class="ttdoc">This function performs signed 16-bit integer convolution with shift-based quantization on the outputs...</div></div>
<div class="ttc" id="agroup__Convolution_html_ga0114bf25be0e886cfc5082157ce217dd"><div class="ttname"><a href="group__Convolution.html#ga0114bf25be0e886cfc5082157ce217dd">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast</a></div><div class="ttdeci">int32_t riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast(const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q15_t *wt_tmp_buf)</div><div class="ttdoc">This function performs fast signed 8-bit integer convolution for RGB images with shift-based quantiza...</div></div>
<div class="ttc" id="agroup__Convolution_html_ga6349568d6ce5be71ab37670fab334cf9"><div class="ttname"><a href="group__Convolution.html#ga6349568d6ce5be71ab37670fab334cf9">riscv_nn_conv_HWC_s8_s8_s8_sft_bias</a></div><div class="ttdeci">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias(const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</div><div class="ttdoc">This function performs signed 8-bit integer convolution with shift-based quantization on the outputs.</div></div>
<div class="ttc" id="agroup__Convolution_html_ga76dd8cc6a11522305e9ec5ddb968877e"><div class="ttname"><a href="group__Convolution.html#ga76dd8cc6a11522305e9ec5ddb968877e">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias</a></div><div class="ttdeci">int32_t riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias(const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</div><div class="ttdoc">This function performs signed 8-bit integer convolution for RGB images with shift-based quantization ...</div></div>
<div class="ttc" id="agroup__Convolution_html_ga01c17cfd9b6bc224bb2329fa9ac7668e"><div class="ttname"><a href="group__Convolution.html#ga01c17cfd9b6bc224bb2329fa9ac7668e">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any</a></div><div class="ttdeci">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any(const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf, q7_t *tmp_buf)</div><div class="ttdoc">This function performs signed 8-bit integer depthwise convolution in any x and y dimensions with shif...</div></div>
<div class="ttc" id="agroup__Convolution_html_gaff8aeef6b452c567ed13804449576f11"><div class="ttname"><a href="group__Convolution.html#gaff8aeef6b452c567ed13804449576f11">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any</a></div><div class="ttdeci">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any(const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf, q7_t *tmp_buf)</div><div class="ttdoc">This function performs fast signed 8-bit integer convolution in any x and y dimensions with shift-bas...</div></div>
<div class="ttc" id="agroup__Convolution_html_gab4c2811e5fde9441edd373a492d8cc72"><div class="ttname"><a href="group__Convolution.html#gab4c2811e5fde9441edd373a492d8cc72">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias</a></div><div class="ttdeci">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias(const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</div><div class="ttdoc">This function performs signed 8-bit integer depthwise convolution with shift-based quantization on th...</div></div>
<div class="ttc" id="agroup__Convolution_html_ga75095bb9dbfe0344ca04324ac11493bb"><div class="ttname"><a href="group__Convolution.html#ga75095bb9dbfe0344ca04324ac11493bb">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any</a></div><div class="ttdeci">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any(const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf, q7_t *tmp_buf)</div><div class="ttdoc">This function performs signed 8-bit integer convolution in any x and y dimensions with shift-based qu...</div></div>
<div class="ttc" id="agroup__Convolution_html_ga37169c70f07977dec222eaa63f82a7b1"><div class="ttname"><a href="group__Convolution.html#ga37169c70f07977dec222eaa63f82a7b1">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast</a></div><div class="ttdeci">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast(const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</div><div class="ttdoc">This function performs fast signed 8-bit integer convolution with shift-based quantization on the out...</div></div>
<div class="ttc" id="agroup__Convolution_html_gabfb034c6133f003ed595846e8e9ecfa4"><div class="ttname"><a href="group__Convolution.html#gabfb034c6133f003ed595846e8e9ecfa4">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast</a></div><div class="ttdeci">int32_t riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast(const q15_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q15_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q15_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *in_tmp_buf, q7_t *tmp_buf)</div><div class="ttdoc">This function performs fast signed 16-bit integer convolution with shift-based quantization on the ou...</div></div>
<div class="ttc" id="agroup__Convolution_html_ga43ac72a8511cbaf132ae0edc1fdb6276"><div class="ttname"><a href="group__Convolution.html#ga43ac72a8511cbaf132ae0edc1fdb6276">riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any</a></div><div class="ttdeci">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any(const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf, q7_t *tmp_buf)</div><div class="ttdoc">This function performs 1x1 kernels convolution for signed 8-bit integer inputs/outputs in any x and y...</div></div>
<div class="ttc" id="agroup__Convolution_html_ga23816c40e33fa7fa6e00ad6a8353f08b"><div class="ttname"><a href="group__Convolution.html#ga23816c40e33fa7fa6e00ad6a8353f08b">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any</a></div><div class="ttdeci">int32_t riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any(const q15_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q15_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q15_t *bias, const uint16_t bias_lshift, const uint16_t out_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *in_tmp_buf, q7_t *tmp_buf)</div><div class="ttdoc">This function performs fast signed 16-bit integer convolution in any x and y dimensions with shift-ba...</div></div>
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
