<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.10">
<meta name="author" content="Andes Technology">
<meta name="copyright" content="2020-{sys: date +%Y}">
<title>AndesAIRE&#8482; Neural Network Library User Manual</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
:not(pre)>code.nobreak{word-wrap:normal}
:not(pre)>code.nowrap{white-space:nowrap}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;text-align:left;margin-right:0}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
td.tableblock>.content>:last-child.sidebarblock{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
</head>
<body class="article">
<div id="header">
<h1>AndesAIRE&#8482; Neural Network Library User Manual</h1>
<div class="details">
<span id="author" class="author">Andes Technology</span><br>
<span id="email" class="email"><a href="mailto:support@andestech.com">support@andestech.com</a></span><br>
<span id="revnumber">version 3.4.0</span>
</div>
<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#section:overview">Overview</a>
<ul class="sectlevel2">
<li><a href="#section:linking_newlib_mculib">Linking Options for Newlib and MCUlib Toolchains</a></li>
<li><a href="#section:linking_glibc">Linking Options for Glibc Toolchains</a></li>
<li><a href="#_notes_for_newlib_mculib_and_glibc_toolchains">Notes for Newlib, MCUlib, and Glibc Toolchains</a></li>
</ul>
</li>
<li><a href="#section:function_documentation">Function Documentation</a></li>
<li><a href="#section:function_activation">Activation Functions</a>
<ul class="sectlevel2">
<li><a href="#section:riscv_nn_activate_s8">riscv_nn_activate_s8</a></li>
<li><a href="#section:riscv_nn_activate_s8_2buf">riscv_nn_activate_s8_2buf</a></li>
<li><a href="#section:riscv_nn_activate_s16">riscv_nn_activate_s16</a></li>
<li><a href="#section:riscv_nn_activate_s16_2buf">riscv_nn_activate_s16_2buf</a></li>
<li><a href="#section:riscv_nn_activate_s16_hp">riscv_nn_activate_s16_hp</a></li>
<li><a href="#section:riscv_nn_gelu_f16">riscv_nn_gelu_f16</a></li>
<li><a href="#section:riscv_nn_gelu_f32">riscv_nn_gelu_f32</a></li>
<li><a href="#section:riscv_nn_leaky_relu_s8">riscv_nn_leaky_relu_s8</a></li>
<li><a href="#section:riscv_nn_leaky_relu_s8_2buf">riscv_nn_leaky_relu_s8_2buf</a></li>
<li><a href="#section:riscv_nn_leaky_relu_s8_asym">riscv_nn_leaky_relu_s8_asym</a></li>
<li><a href="#section:riscv_nn_leaky_relu_s16_asym">riscv_nn_leaky_relu_s16_asym</a></li>
<li><a href="#section:riscv_nn_leaky_relu_f16">riscv_nn_leaky_relu_f16</a></li>
<li><a href="#section:riscv_nn_prelu_s8_asym">riscv_nn_prelu_s8_asym</a></li>
<li><a href="#section:riscv_nn_relu_any_s8">riscv_nn_relu_any_s8</a></li>
<li><a href="#section:riscv_nn_relu_any_s8_2buf">riscv_nn_relu_any_s8_2buf</a></li>
<li><a href="#section:riscv_nn_relu_any_s16">riscv_nn_relu_any_s16</a></li>
<li><a href="#section:riscv_nn_relu_any_f16">riscv_nn_relu_any_f16</a></li>
<li><a href="#section:riscv_nn_relu_s8">riscv_nn_relu_s8</a></li>
<li><a href="#section:riscv_nn_relu_s8_2buf">riscv_nn_relu_s8_2buf</a></li>
<li><a href="#section:riscv_nn_relu_s16">riscv_nn_relu_s16</a></li>
<li><a href="#section:riscv_nn_relu_s16_2buf">riscv_nn_relu_s16_2buf</a></li>
<li><a href="#section:riscv_nn_relu_f16">riscv_nn_relu_f16</a></li>
<li><a href="#section:riscv_nn_sigmoid_s8">riscv_nn_sigmoid_s8</a></li>
<li><a href="#section:riscv_nn_sigmoid_s16">riscv_nn_sigmoid_s16</a></li>
<li><a href="#section:riscv_nn_sigmoid_f16">riscv_nn_sigmoid_f16</a></li>
<li><a href="#section:riscv_nn_silu_f16">riscv_nn_silu_f16</a></li>
<li><a href="#section:riscv_nn_silu_f32">riscv_nn_silu_f32</a></li>
<li><a href="#section:riscv_nn_tanh_s8">riscv_nn_tanh_s8</a></li>
<li><a href="#section:riscv_nn_tanh_s16">riscv_nn_tanh_s16</a></li>
<li><a href="#section:riscv_nn_tanh_f16">riscv_nn_tanh_f16</a></li>
<li><a href="#section:riscv_nn_tanh_f32">riscv_nn_tanh_f32</a></li>
</ul>
</li>
<li><a href="#section:function_basic">Basic Functions</a>
<ul class="sectlevel2">
<li><a href="#section:riscv_nn_add_s8_sym">riscv_nn_add_s8_sym</a></li>
<li><a href="#section:riscv_nn_add_s8_sym_round">riscv_nn_add_s8_sym_round</a></li>
<li><a href="#section:riscv_nn_broadcast_mul_asym_s8">riscv_nn_broadcast_mul_asym_s8</a></li>
<li><a href="#section:riscv_nn_broadcast_mul_asym_s16">riscv_nn_broadcast_mul_asym_s16</a></li>
<li><a href="#section:riscv_nn_ew_add_s8_asym">riscv_nn_ew_add_s8_asym</a></li>
<li><a href="#section:riscv_nn_ew_add_s16_asym">riscv_nn_ew_add_s16_asym</a></li>
<li><a href="#section:riscv_nn_ew_add_f16">riscv_nn_ew_add_f16</a></li>
<li><a href="#section:riscv_nn_ew_addc_s8_asym">riscv_nn_ew_addc_s8_asym</a></li>
<li><a href="#section:riscv_nn_ew_addc_s16_asym">riscv_nn_ew_addc_s16_asym</a></li>
<li><a href="#section:riscv_nn_ew_mul_s8_asym">riscv_nn_ew_mul_s8_asym</a></li>
<li><a href="#section:riscv_nn_ew_mul_s16_asym">riscv_nn_ew_mul_s16_asym</a></li>
<li><a href="#section:riscv_nn_ew_mul_s16_s8_asym">riscv_nn_ew_mul_s16_s8_asym</a></li>
<li><a href="#section:riscv_nn_ew_mulc_s8_asym">riscv_nn_ew_mulc_s8_asym</a></li>
<li><a href="#section:riscv_nn_ew_mulc_s16_asym">riscv_nn_ew_mulc_s16_asym</a></li>
<li><a href="#section:riscv_nn_ew_mul_f16">riscv_nn_ew_mul_f16</a></li>
<li><a href="#section:riscv_nn_ew_rsubc_s8_asym">riscv_nn_ew_rsubc_s8_asym</a></li>
<li><a href="#section:riscv_nn_ew_rsubc_s16_asym">riscv_nn_ew_rsubc_s16_asym</a></li>
<li><a href="#section:riscv_nn_ew_sub_s8_asym">riscv_nn_ew_sub_s8_asym</a></li>
<li><a href="#section:riscv_nn_ew_sub_s16_asym">riscv_nn_ew_sub_s16_asym</a></li>
<li><a href="#section:riscv_nn_ew_subc_s8_asym">riscv_nn_ew_subc_s8_asym</a></li>
<li><a href="#section:riscv_nn_ew_subc_s16_asym">riscv_nn_ew_subc_s16_asym</a></li>
</ul>
</li>
<li><a href="#section:function_concatenation">Concatenation Functions</a>
<ul class="sectlevel2">
<li><a href="#section:riscv_nn_concate_s8_w">riscv_nn_concate_s8_w</a></li>
<li><a href="#section:riscv_nn_concate_s8_x">riscv_nn_concate_s8_x</a></li>
<li><a href="#section:riscv_nn_concate_s8_y">riscv_nn_concate_s8_y</a></li>
<li><a href="#section:riscv_nn_concate_s8_z">riscv_nn_concate_s8_z</a></li>
<li><a href="#section:riscv_nn_concate_s16_w">riscv_nn_concate_s16_w</a></li>
<li><a href="#section:riscv_nn_concate_s16_x">riscv_nn_concate_s16_x</a></li>
<li><a href="#section:riscv_nn_concate_s16_y">riscv_nn_concate_s16_y</a></li>
<li><a href="#section:riscv_nn_concate_s16_z">riscv_nn_concate_s16_z</a></li>
<li><a href="#section:riscv_nn_concate_f16_w">riscv_nn_concate_f16_w</a></li>
<li><a href="#section:riscv_nn_concate_f16_x">riscv_nn_concate_f16_x</a></li>
<li><a href="#section:riscv_nn_concate_f16_y">riscv_nn_concate_f16_y</a></li>
<li><a href="#section:riscv_nn_concate_f16_z">riscv_nn_concate_f16_z</a></li>
<li><a href="#section:riscv_nn_pad_s8">riscv_nn_pad_s8</a></li>
<li><a href="#section:riscv_nn_pad_s16">riscv_nn_pad_s16</a></li>
<li><a href="#section:riscv_nn_slice_s16_w">riscv_nn_slice_s16_w</a></li>
<li><a href="#section:riscv_nn_slice_s16_x">riscv_nn_slice_s16_x</a></li>
<li><a href="#section:riscv_nn_slice_s16_y">riscv_nn_slice_s16_y</a></li>
<li><a href="#section:riscv_nn_slice_s16_z">riscv_nn_slice_s16_z</a></li>
<li><a href="#section:riscv_nn_split_s8_w">riscv_nn_split_s8_w</a></li>
<li><a href="#section:riscv_nn_split_s8_x">riscv_nn_split_s8_x</a></li>
<li><a href="#section:riscv_nn_split_s8_y">riscv_nn_split_s8_y</a></li>
<li><a href="#section:riscv_nn_split_s8_z">riscv_nn_split_s8_z</a></li>
<li><a href="#section:riscv_nn_split_s16_w">riscv_nn_split_s16_w</a></li>
<li><a href="#section:riscv_nn_split_s16_x">riscv_nn_split_s16_x</a></li>
<li><a href="#section:riscv_nn_split_s16_y">riscv_nn_split_s16_y</a></li>
<li><a href="#section:riscv_nn_split_s16_z">riscv_nn_split_s16_z</a></li>
<li><a href="#section:riscv_nn_strided_slice_s8">riscv_nn_strided_slice_s8</a></li>
<li><a href="#section:riscv_nn_strided_slice_s16">riscv_nn_strided_slice_s16</a></li>
</ul>
</li>
<li><a href="#section:function_convolution">Convolution Functions</a>
<ul class="sectlevel2">
<li><a href="#section:riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any">riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_sft_bias">riscv_nn_conv_HWC_s8_s8_s8_sft_bias</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s16_s16_s16_sft_bias">riscv_nn_conv_HWC_s16_s16_s16_sft_bias</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any">riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any">riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any">riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any">riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any">riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any">riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any">riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any">riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any">riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any">riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_sym_get_buffer_size">riscv_nn_conv_1x1_sym_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast">riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast">riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast">riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast">riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast">riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_fast">riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_fast">riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_fast">riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_fast">riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_fast">riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast">riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast">riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast">riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast">riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_sym_fast">riscv_nn_conv_HWC_s8_s8_s8_sym_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s16_s8_sym_fast">riscv_nn_conv_HWC_s8_s16_s8_sym_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_u8_s8_sym_fast">riscv_nn_conv_HWC_u8_u8_s8_sym_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s8_s8_sym_fast">riscv_nn_conv_HWC_u8_s8_s8_sym_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s16_s8_sym_fast">riscv_nn_conv_HWC_u8_s16_s8_sym_fast</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any">riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any">riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any">riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any">riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_sym_fast_any">riscv_nn_conv_HWC_s8_s8_s8_sym_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s16_s8_sym_fast_any">riscv_nn_conv_HWC_s8_s16_s8_sym_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_u8_s8_sym_fast_any">riscv_nn_conv_HWC_u8_u8_s8_sym_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s8_s8_sym_fast_any">riscv_nn_conv_HWC_u8_s8_s8_sym_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_u8_s16_s8_sym_fast_any">riscv_nn_conv_HWC_u8_s16_s8_sym_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_sym_bias_any">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_sym_get_buffer_size">riscv_nn_conv_sym_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s8_s8_sym">riscv_nn_conv_dw_HWC_s8_s8_s8_sym</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s16_s8_sym">riscv_nn_conv_dw_HWC_s8_s16_s8_sym</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_u8_s8_sym">riscv_nn_conv_dw_HWC_u8_u8_s8_sym</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_s8_s8_sym">riscv_nn_conv_dw_HWC_u8_s8_s8_sym</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_s16_s8_sym">riscv_nn_conv_dw_HWC_u8_s16_s8_sym</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s8_s8_sym_any">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s16_s8_sym_any">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_u8_s8_sym_any">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_s8_s8_sym_any">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_s16_s8_sym_any">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any">riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any_get_buffer_size">riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any">riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size">riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any">riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any_get_buffer_size">riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any">riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_1xn_HWC_s16_s16_s8_asym_bias_any">riscv_nn_conv_1xn_HWC_s16_s16_s8_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any">riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any_get_buffer_size">riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated_get_buffer_size">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any_get_buffer_size">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym">riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym</a></li>
<li><a href="#section:riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym_get_buffer_size">riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym">riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym</a></li>
<li><a href="#section:riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym_get_buffer_size">riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym">riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym</a></li>
<li><a href="#section:riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym_get_buffer_size">riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any">riscv_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any">riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any_get_buffer_size">riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any">riscv_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_s16_s16_s8_asym_bias_any">riscv_nn_conv_dw_HWC_s16_s16_s8_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym">riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym_get_buffer_size">riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any">riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any_get_buffer_size">riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any">riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any">riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any">riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any">riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any</a></li>
<li><a href="#section:riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any_get_buffer_size">riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_HWC_f16_f16_f16_bias">riscv_nn_conv_HWC_f16_f16_f16_bias</a></li>
<li><a href="#section:riscv_nn_conv_HWC_f16_f16_f16_bias_get_buffer_size">riscv_nn_conv_HWC_f16_f16_f16_bias_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_f16_f16_f16_bias">riscv_nn_conv_dw_HWC_f16_f16_f16_bias</a></li>
<li><a href="#section:riscv_nn_conv_dw_HWC_f32_f32_f32_bias_any">riscv_nn_conv_dw_HWC_f32_f32_f32_bias_any</a></li>
</ul>
</li>
<li><a href="#section:function_fully_connected">Fully-Connected Layer Functions</a>
<ul class="sectlevel2">
<li><a href="#section:riscv_nn_batch_matmul_s8_s8_s8">riscv_nn_batch_matmul_s8_s8_s8</a></li>
<li><a href="#section:riscv_nn_batch_matmul_s16_s16_s16">riscv_nn_batch_matmul_s16_s16_s16</a></li>
<li><a href="#section:riscv_nn_fc_s8_s8_s8_sft_bias">riscv_nn_fc_s8_s8_s8_sft_bias</a></li>
<li><a href="#section:riscv_nn_fc_s8_s8_s8_sft_bias_fast">riscv_nn_fc_s8_s8_s8_sft_bias_fast</a></li>
<li><a href="#section:riscv_nn_fc_s16_s16_s16_sft_bias">riscv_nn_fc_s16_s16_s16_sft_bias</a></li>
<li><a href="#section:riscv_nn_fc_s16_s16_s16_sft_bias_fast">riscv_nn_fc_s16_s16_s16_sft_bias_fast</a></li>
<li><a href="#section:riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias">riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias</a></li>
<li><a href="#section:riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias_fast">riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias_fast</a></li>
<li><a href="#section:riscv_nn_fc_s8_s8_s8_sym_bias">riscv_nn_fc_s8_s8_s8_sym_bias</a></li>
<li><a href="#section:riscv_nn_fc_s8_s16_s8_sym_bias">riscv_nn_fc_s8_s16_s8_sym_bias</a></li>
<li><a href="#section:riscv_nn_fc_u8_u8_s8_sym_bias">riscv_nn_fc_u8_u8_s8_sym_bias</a></li>
<li><a href="#section:riscv_nn_fc_u8_s8_s8_sym_bias">riscv_nn_fc_u8_s8_s8_sym_bias</a></li>
<li><a href="#section:riscv_nn_fc_u8_s16_s8_sym_bias">riscv_nn_fc_u8_s16_s8_sym_bias</a></li>
<li><a href="#section:riscv_nn_fc_s8_s8_s8_sym">riscv_nn_fc_s8_s8_s8_sym</a></li>
<li><a href="#section:riscv_nn_fc_s8_s16_s8_sym">riscv_nn_fc_s8_s16_s8_sym</a></li>
<li><a href="#section:riscv_nn_fc_u8_u8_s8_sym">riscv_nn_fc_u8_u8_s8_sym</a></li>
<li><a href="#section:riscv_nn_fc_u8_s8_s8_sym">riscv_nn_fc_u8_s8_s8_sym</a></li>
<li><a href="#section:riscv_nn_fc_u8_s16_s8_sym">riscv_nn_fc_u8_s16_s8_sym</a></li>
<li><a href="#section:riscv_nn_fc_s8_s8_s8_sym_bias_fast">riscv_nn_fc_s8_s8_s8_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_fc_s8_s16_s8_sym_bias_fast">riscv_nn_fc_s8_s16_s8_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_fc_u8_u8_s8_sym_bias_fast">riscv_nn_fc_u8_u8_s8_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_fc_u8_s8_s8_sym_bias_fast">riscv_nn_fc_u8_s8_s8_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_fc_u8_s16_s8_sym_bias_fast">riscv_nn_fc_u8_s16_s8_sym_bias_fast</a></li>
<li><a href="#section:riscv_nn_fc_s8_s8_s8_sym_fast">riscv_nn_fc_s8_s8_s8_sym_fast</a></li>
<li><a href="#section:riscv_nn_fc_s8_s16_s8_sym_fast">riscv_nn_fc_s8_s16_s8_sym_fast</a></li>
<li><a href="#section:riscv_nn_fc_u8_u8_s8_sym_fast">riscv_nn_fc_u8_u8_s8_sym_fast</a></li>
<li><a href="#section:riscv_nn_fc_u8_s8_s8_sym_fast">riscv_nn_fc_u8_s8_s8_sym_fast</a></li>
<li><a href="#section:riscv_nn_fc_u8_s16_s8_sym_fast">riscv_nn_fc_u8_s16_s8_sym_fast</a></li>
<li><a href="#section:riscv_nn_fc_s8_wt_converter">riscv_nn_fc_s8_wt_converter</a></li>
<li><a href="#section:riscv_nn_fc_s16_wt_converter">riscv_nn_fc_s16_wt_converter</a></li>
<li><a href="#section:riscv_nn_fc_mat_vec_s8_wt_converter">riscv_nn_fc_mat_vec_s8_wt_converter</a></li>
<li><a href="#section:riscv_nn_fc_s8_s8_s8_asym_bias">riscv_nn_fc_s8_s8_s8_asym_bias</a></li>
<li><a href="#section:riscv_nn_fc_s8_s8_s8_asym_bias_get_buffer_size">riscv_nn_fc_s8_s8_s8_asym_bias_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_fc_s16_s16_s8_asym_bias">riscv_nn_fc_s16_s16_s8_asym_bias</a></li>
<li><a href="#section:riscv_nn_fc_s16_s16_s8_asym_bias_get_buffer_size">riscv_nn_fc_s16_s16_s8_asym_bias_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_fc_f16_f16_f16_bias">riscv_nn_fc_f16_f16_f16_bias</a></li>
</ul>
</li>
<li><a href="#section:function_pooling">Pooling Functions</a>
<ul class="sectlevel2">
<li><a href="#section:riscv_nn_avepool_HWC_s8">riscv_nn_avepool_HWC_s8</a></li>
<li><a href="#section:riscv_nn_avepool_HWC_s8_any">riscv_nn_avepool_HWC_s8_any</a></li>
<li><a href="#section:riscv_nn_avepool_HWC_s8_any_act">riscv_nn_avepool_HWC_s8_any_act</a></li>
<li><a href="#section:riscv_nn_avepool_HWC_s8_any_act_get_buffer_size">riscv_nn_avepool_HWC_s8_any_act_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_avepool_HWC_s16_any_act">riscv_nn_avepool_HWC_s16_any_act</a></li>
<li><a href="#section:riscv_nn_avepool_HWC_s16_any_act_get_buffer_size">riscv_nn_avepool_HWC_s16_any_act_get_buffer_size</a></li>
<li><a href="#section:riscv_nn_avepool_HWC_s8_asym">riscv_nn_avepool_HWC_s8_asym</a></li>
<li><a href="#section:riscv_nn_avepool_HWC_s16_asym">riscv_nn_avepool_HWC_s16_asym</a></li>
<li><a href="#section:riscv_nn_avepool_HWC_f16_any">riscv_nn_avepool_HWC_f16_any</a></li>
<li><a href="#section:riscv_nn_maxpool_HWC_s8">riscv_nn_maxpool_HWC_s8</a></li>
<li><a href="#section:riscv_nn_maxpool_HWC_s8_any_act">riscv_nn_maxpool_HWC_s8_any_act</a></li>
<li><a href="#section:riscv_nn_maxpool_HWC_s16_any_act">riscv_nn_maxpool_HWC_s16_any_act</a></li>
<li><a href="#section:riscv_nn_maxpool_HWC_f16_any">riscv_nn_maxpool_HWC_f16_any</a></li>
</ul>
</li>
<li><a href="#section:function_softmax">Softmax Functions</a>
<ul class="sectlevel2">
<li><a href="#section:riscv_nn_softmax_s8_fast">riscv_nn_softmax_s8_fast</a></li>
<li><a href="#section:riscv_nn_softmax_s16_fast">riscv_nn_softmax_s16_fast</a></li>
<li><a href="#section:riscv_nn_softmax_s8_hp">riscv_nn_softmax_s8_hp</a></li>
<li><a href="#section:riscv_nn_softmax_s8_s16_hp">riscv_nn_softmax_s8_s16_hp</a></li>
<li><a href="#section:riscv_nn_softmax_u8_hp">riscv_nn_softmax_u8_hp</a></li>
<li><a href="#section:riscv_nn_softmax_s16_hp">riscv_nn_softmax_s16_hp</a></li>
<li><a href="#section:riscv_nn_softmax_f16">riscv_nn_softmax_f16</a></li>
<li><a href="#section:riscv_nn_softmax_f32">riscv_nn_softmax_f32</a></li>
<li><a href="#section:riscv_nn_softmax_f32_2pass">riscv_nn_softmax_f32_2pass</a></li>
<li><a href="#section:riscv_nn_softmax2d_f16">riscv_nn_softmax2d_f16</a></li>
<li><a href="#section:riscv_nn_softmax2d_f32">riscv_nn_softmax2d_f32</a></li>
</ul>
</li>
<li><a href="#section:function_utils">Utils Functions</a>
<ul class="sectlevel2">
<li><a href="#section:get_version_libnn">get_version_libnn</a></li>
<li><a href="#section:riscv_nn_argmax_f32">riscv_nn_argmax_f32</a></li>
<li><a href="#section:riscv_nn_channel_shuffle_CHW_s8">riscv_nn_channel_shuffle_CHW_s8</a></li>
<li><a href="#section:riscv_nn_channel_shuffle_HWC_s8">riscv_nn_channel_shuffle_HWC_s8</a></li>
<li><a href="#section:riscv_nn_dequantize_s8_f16">riscv_nn_dequantize_s8_f16</a></li>
<li><a href="#section:riscv_nn_dequantize_s8_f32">riscv_nn_dequantize_s8_f32</a></li>
<li><a href="#section:riscv_nn_dequantize_s16_f32">riscv_nn_dequantize_s16_f32</a></li>
<li><a href="#section:riscv_nn_exp_f16">riscv_nn_exp_f16</a></li>
<li><a href="#section:riscv_nn_exp_f32">riscv_nn_exp_f32</a></li>
<li><a href="#section:riscv_nn_gather_HWC_s8">riscv_nn_gather_HWC_s8</a></li>
<li><a href="#section:riscv_nn_gather_HWC_s16">riscv_nn_gather_HWC_s16</a></li>
<li><a href="#section:riscv_nn_layer_norm_f16">riscv_nn_layer_norm_f16</a></li>
<li><a href="#section:riscv_nn_layer_norm_f32">riscv_nn_layer_norm_f32</a></li>
<li><a href="#section:riscv_nn_lstm_unidirectional_s16_s8">riscv_nn_lstm_unidirectional_s16_s8</a></li>
<li><a href="#section:riscv_nn_pixel_shuffle_HWC_s8">riscv_nn_pixel_shuffle_HWC_s8</a></li>
<li><a href="#section:riscv_nn_quantize_f16_s8">riscv_nn_quantize_f16_s8</a></li>
<li><a href="#section:riscv_nn_quantize_f32_s8">riscv_nn_quantize_f32_s8</a></li>
<li><a href="#section:riscv_nn_quantize_f32_s16">riscv_nn_quantize_f32_s16</a></li>
<li><a href="#section:riscv_nn_reduce_sum_s8">riscv_nn_reduce_sum_s8</a></li>
<li><a href="#section:riscv_nn_reduce_sum_s16">riscv_nn_reduce_sum_s16</a></li>
<li><a href="#section:riscv_nn_requantize_s8_s8">riscv_nn_requantize_s8_s8</a></li>
<li><a href="#section:riscv_nn_requantize_s16_s8">riscv_nn_requantize_s16_s8</a></li>
<li><a href="#section:riscv_nn_requantize_s16_s16">riscv_nn_requantize_s16_s16</a></li>
<li><a href="#section:riscv_nn_reshape_s8">riscv_nn_reshape_s8</a></li>
<li><a href="#section:riscv_nn_reshape_f16">riscv_nn_reshape_f16</a></li>
<li><a href="#section:riscv_nn_reverseV2_s8">riscv_nn_reverseV2_s8</a></li>
<li><a href="#section:riscv_nn_reverseV2_s16">riscv_nn_reverseV2_s16</a></li>
<li><a href="#section:riscv_nn_rms_norm_f16">riscv_nn_rms_norm_f16</a></li>
<li><a href="#section:riscv_nn_scatter_nd_s8">riscv_nn_scatter_nd_s8</a></li>
<li><a href="#section:riscv_nn_scatter_nd_s16">riscv_nn_scatter_nd_s16</a></li>
<li><a href="#section:riscv_nn_subspectral_norm_f32">riscv_nn_subspectral_norm_f32</a></li>
<li><a href="#section:riscv_nn_svdf_s8">riscv_nn_svdf_s8</a></li>
<li><a href="#section:riscv_nn_svdf_s8_state_s8">riscv_nn_svdf_s8_state_s8</a></li>
<li><a href="#section:riscv_nn_top_k_s8">riscv_nn_top_k_s8</a></li>
<li><a href="#section:riscv_nn_top_k_f16">riscv_nn_top_k_f16</a></li>
<li><a href="#section:riscv_nn_transpose_4d_s8">riscv_nn_transpose_4d_s8</a></li>
<li><a href="#section:riscv_nn_transpose_4d_s16">riscv_nn_transpose_4d_s16</a></li>
<li><a href="#section:riscv_nn_transpose_4d_s32">riscv_nn_transpose_4d_s32</a></li>
<li><a href="#section:riscv_nn_upsampling2d_HWC_s8">riscv_nn_upsampling2d_HWC_s8</a></li>
<li><a href="#section:riscv_nn_upsampling2d_HWC_s16">riscv_nn_upsampling2d_HWC_s16</a></li>
<li><a href="#section:riscv_nn_upsampling2d_HWC_f16">riscv_nn_upsampling2d_HWC_f16</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<!-- toc disabled -->
</div>
</div>
<div class="sect1">
<h2 id="section:overview">Overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This document contains information about neural network function specifications in
AndesAIRE Neural Network Library (NN Library, also known as libnn) for
Andes toolchains and describes how to use these functions.</p>
</div>
<div class="paragraph">
<p>NN Library provides comprehensive functions that have been optimized for DSP ISA and RISC-V Vector Extension.
These functions include activation, convolution, fully-connected layer, pooling, and miscellaneous auxiliary functions.</p>
</div>
<div class="paragraph">
<p>Designed and developed with toolchains from AndeSight v5.0.0 and later versions,
NN Library provides easy-to-use APIs to encapsulate the complexity of calculations in neural network computations.
It benefits you by saving development resources, allowing you to focus on your system, and reducing development time.</p>
</div>
<div class="paragraph">
<p>The functions can be classified into several categories: activation, basic math, concatenation, convolution,
fully-connected layer, pooling, softmax, and utilities.</p>
</div>
<div class="paragraph">
<p>To call the library functions, simply include header files provided by NN Library.
These header files define prototypes of functions and are named according to the function categories, as listed below:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>riscv_nn_activation.h</code></p>
</li>
<li>
<p><code>riscv_nn_basic.h</code></p>
</li>
<li>
<p><code>riscv_nn_concatenation.h</code></p>
</li>
<li>
<p><code>riscv_nn_convolution.h</code></p>
</li>
<li>
<p><code>riscv_nn_fully_connected.h</code></p>
</li>
<li>
<p><code>riscv_nn_pooling.h</code></p>
</li>
<li>
<p><code>riscv_nn_softmax.h</code></p>
</li>
<li>
<p><code>riscv_nn_util.h</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For example, to use activation functions to activate the neural network data, you can include <code>riscv_nn_activation.h</code> in your C files.</p>
</div>
<div class="paragraph">
<p>NN Library defines several data types in <code>riscv_math_types.h</code> (as quoted below) to properly keep the data during computation.</p>
</div>
<div class="listingblock">
<div class="title">riscv_math_types.h</div>
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef int8_t q7_t;        /* for signed 8-bit integer */
typedef uint8_t u8_t;       /* for unsigned 8-bit integer */
typedef int16_t q15_t;      /* for signed 16-bit integer */
typedef uint16_t u16_t;     /* for unsigned 16-bit integer */
typedef int32_t q31_t;      /* for signed 32-bit integer */
typedef uint32_t u32_t;     /* for unsigned 32-bit integer */
typedef int64_t q63_t;      /* for signed 64-bit integer */
typedef uint64_t u64_t;     /* for unsigned 64-bit integer */
typedef _Float16 float16_t; /* for half-precision (16-bit) floating-point */
typedef float float32_t;  /* for single-precision (32-bit) floating-point */
typedef double float64_t; /* for double-precision (64-bit) floating-point */</code></pre>
</div>
</div>
<div class="paragraph">
<p>These data types are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>q7_t</code> for signed 8-bit integer</p>
</li>
<li>
<p><code>u8_t</code> for unsigned 8-bit integer</p>
</li>
<li>
<p><code>q15_t</code> for signed 16-bit integer</p>
</li>
<li>
<p><code>u16_t</code> for unsigned 16-bit integer</p>
</li>
<li>
<p><code>q31_t</code> for signed 32-bit integer</p>
</li>
<li>
<p><code>u32_t</code> for unsigned 32-bit integer</p>
</li>
<li>
<p><code>q63_t</code> for signed 64-bit integer</p>
</li>
<li>
<p><code>u64_t</code> for unsigned 64-bit integer</p>
</li>
<li>
<p><code>float16_t</code> for 16-bit half-precision floating-point data type</p>
</li>
<li>
<p><code>float32_t</code> for 32-bit single-precision floating-point data type</p>
</li>
<li>
<p><code>float64_t</code> for 64-bit double-precision floating-point data type</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>NN Library also defines enumeration types <code>riscv_nn_activation_fun</code> for selecting the activation function
and <code>riscv_nn_upsample_method</code> for selecting the upsampling algorithm.</p>
</div>
<div class="paragraph">
<p>The definition of <code>riscv_nn_activation_fun</code> is provided below and can be found in <code>riscv_nn_activation.h</code>.</p>
</div>
<div class="listingblock">
<div class="title">riscv_nn_activation.h</div>
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef enum
{
    NN_SIGMOID = 0,    /* Use Sigmoid activation function */
    NN_TANH = 1,       /* Use Tanh activation function */
} riscv_nn_activation_fun;</code></pre>
</div>
</div>
<div class="paragraph">
<p>The definition of <code>riscv_nn_upsample_method</code> is provided below and can be found in <code>riscv_nn_util.h</code>.</p>
</div>
<div class="listingblock">
<div class="title">riscv_nn_util.h</div>
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef enum
{
    NN_UPSAMPLE_NEAREST = 0,
} riscv_nn_upsample_method;</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>riscv_nn_types.h</code> defines additional types for the <code>riscv_nn_lstm_unidirectional_s16_s8</code> function, and their definitions are as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef struct
{
    int32_t min;
    int32_t max;
} riscv_nn_activation;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef struct
{
    int32_t max_time;
    int32_t num_inputs;
    int32_t num_batches;
    int32_t num_outputs;
} riscv_nn_lstm_dims;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef struct
{
    int32_t input_variance;
    int32_t forget_variance;
    int32_t cell_variance;
    int32_t output_variance;
} riscv_nn_lstm_guard_params;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef struct
{
    int16_t * input_gate;
    int16_t * forget_gate;
    int16_t * cell_gate;
    int16_t * output_gate;
} riscv_nn_lstm_context;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef struct
{
    int16_t cell;
    int8_t projection;
} riscv_nn_lstm_clip_params;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef struct
{
    int32_t multiplier;
    int32_t shift;
} riscv_nn_scaling</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef struct
{
    int16_t * input_weight;
    int16_t * forget_weight;
    int16_t * cell_weight;
    int16_t * output_weight;
} riscv_nn_layer_norm;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef struct
{
    int32_t time_major;
    riscv_nn_scaling input_to_input_scaling;
    riscv_nn_scaling input_to_forget_scaling;
    riscv_nn_scaling input_to_cell_scaling;
    riscv_nn_scaling input_to_output_scaling;
    riscv_nn_scaling recurrent_to_input_scaling;
    riscv_nn_scaling recurrent_to_forget_scaling;
    riscv_nn_scaling recurrent_to_cell_scaling;
    riscv_nn_scaling recurrent_to_output_scaling;
    riscv_nn_scaling cell_to_input_scaling;
    riscv_nn_scaling cell_to_forget_scaling;
    riscv_nn_scaling cell_to_output_scaling;
    riscv_nn_scaling projection_scaling;
    riscv_nn_scaling hidden_scaling;
    riscv_nn_scaling layer_norm_input_scaling;
    riscv_nn_scaling layer_norm_forget_scaling;
    riscv_nn_scaling layer_norm_cell_scaling;
    riscv_nn_scaling layer_norm_output_scaling;

    int32_t cell_state_shift;
    int32_t hidden_offset;
    int32_t output_state_offset;

    riscv_nn_lstm_clip_params clip;
    riscv_nn_lstm_guard_params guard;
    riscv_nn_layer_norm layer_norm;

    const int32_t * i2i_effective_bias;
    const int32_t * i2f_effective_bias;
    const int32_t * i2c_effective_bias;
    const int32_t * i2o_effective_bias;

    const int32_t * r2i_effective_bias;
    const int32_t * r2f_effective_bias;
    const int32_t * r2c_effective_bias;
    const int32_t * r2o_effective_bias;

    const int32_t * projection_effective_bias;

    const int32_t * input_gate_bias;
    const int32_t * forget_gate_bias;
    const int32_t * cell_gate_bias;
    const int32_t * output_gate_bias;

    riscv_nn_activation activation;

} riscv_nn_lstm_params;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">typedef enum
{
    NN_WZYX_2_WZXY = 0,
    NN_WZYX_2_WYZX = 1,
    NN_WZYX_2_WYXZ = 2,
    NN_WZYX_2_WXZY = 3,
    NN_WZYX_2_WXYZ = 4,
    NN_WZYX_2_ZWXY = 5,
    NN_WZYX_2_ZWYX = 6,
    NN_WZYX_2_YWZX = 7,
} riscv_nn_transpose_format;</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="section:linking_newlib_mculib">Linking Options for Newlib and MCUlib Toolchains</h3>
<div class="paragraph">
<p>In addition to the above header files, different linking options are required depending on the toolchain in use.
<a href="#table-newlib-mculib-toolchains-options">Options for Newlib and MCUlib Toolchains</a> describes the options for Newlib and MCUlib toolchains.</p>
</div>
<table id="table-newlib-mculib-toolchains-options" class="tableblock frame-topbot grid-rows stretch">
<caption class="title">Table 1. Options for Newlib and MCUlib Toolchains</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Option</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lm</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links the standard C math library</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links NN Library <code>libnn.a</code> with plain C or DSP ISA Extension implementation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links NN Library <code>libnn_v.a</code> with RISC-V Vector Extension,
                          AndeStar V5 Vector Dot Product Extension, and ELEN=32 support</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v_seg</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links NN Library <code>libnn_v_seg.a</code> with RISC-V Vector Extension,
                          AndeStar V5 Vector Dot Product Extension, ELEN=32 support,
                          and RISC-V Vector segment load/store instructions</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v_elen64</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links NN Library <code>libnn_v_elen64.a</code> with RISC-V Vector Extension,
                          AndeStar V5 Vector Dot Product Extension, and ELEN=64 support</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v_elen64_seg</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links NN Library <code>libnn_v_elen64_seg.a</code> with RISC-V Vector Extension,
                          AndeStar V5 Vector Dot Product Extension, ELEN=64 support,
                          and RISC-V Vector segment load/store instructions</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-mext-dsp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables DSP ISA Extension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-mext-vector</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables RISC-V Vector Extension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-mext-zc</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables RISC-V Code Size Reduction Extension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-mtune=andes-23-series</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables optimizations for AndesCore 23-series processors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-mtune=andes-45-series</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables optimizations for AndesCore 45-series processors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-mzfh</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables the half-precision floating-point data type and Zfh Extension</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>To ensure successful compilation of programs that use library functions relying
on the standard C math library, be sure to link against it by specifying the
<code>-lm</code> option.</p>
</div>
<div class="paragraph">
<p><a href="#table-linking-options">Supported Linking Options for Different Extensions</a> summarizes the required linking options depending on the extension supportability of running targets.</p>
</div>
<table id="table-linking-options" class="tableblock frame-topbot grid-rows stretch">
<caption class="title">Table 2. Supported Linking Options for Different Extensions</caption>
<colgroup>
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 42.8572%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">DSP ISA Extension</th>
<th class="tableblock halign-left valign-top">RISC-V Vector and AndeStar V5 Vector Dot Product Extensions</th>
<th class="tableblock halign-left valign-top">RISC-V Vector Segment Load/Store Instructions</th>
<th class="tableblock halign-left valign-top">RISC-V Vector ELEN</th>
<th class="tableblock halign-left valign-top">Linking Options</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn -mext-dsp</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v -mext-vector</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v_seg -mext-vector</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v_elen64 -mext-vector</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v_elen64_seg -mext-vector</code></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>For example, if your target system lacks support for DSP ISA Extension nor RISC-V Vector Extension,
which are used to accelerate NN Library, you should use the <code>-lnn</code> option.
This will build an application that links against NN Library <code>libnn.a</code> using plain C implementation.</p>
</div>
<div class="paragraph">
<p>Conversely, if your system supports DSP ISA Extension, use the <code>-mext-dsp</code> option
to enable DSP ISA Extension and enhance performance.</p>
</div>
</div>
<div class="sect2">
<h3 id="section:linking_glibc">Linking Options for Glibc Toolchains</h3>
<div class="paragraph">
<p><a href="#table-glibc-toolchain-linking-options">Options for Glibc Toolchains</a> describes the available options for Glibc toolchains.</p>
</div>
<table id="table-glibc-toolchain-linking-options" class="tableblock frame-topbot grid-rows stretch">
<caption class="title">Table 3. Options for Glibc Toolchains</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Option</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-static</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Applies static linking</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lm</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links the standard C math library</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links NN Library with plain C implementation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_p</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links NN Library with DSP ISA Extension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links NN Library with RISC-V Vector Extension, AndeStar V5
                           Vector Dot Product Extension, and ELEN=32 support</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v_seg</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links NN Library with RISC-V Vector Extension, AndeStar V5
                           Vector Dot Product Extension, ELEN=32 support, and
                           RISC-V Vector segment load/store instructions</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v_elen64</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links NN Library with RISC-V Vector Extension, AndeStar V5
                           Vector Dot Product Extension, and ELEN=64 support</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn_v_elen64_seg</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Links NN Library with RISC-V Vector Extension, AndeStar V5
                           Vector Dot Product Extension, ELEN=64 support, and
                           RISC-V Vector segment load/store instructions</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-mext-dsp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables DSP ISA Extension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-mext-vector</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables RISC-V Vector Extension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-mext-zc</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables RISC-V Code Size Reduction Extension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-mtune=andes-45-series</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables optimizations for AndesCore 45-series processors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-mzfh</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables the half-precision floating-point data type and Zfh Extension</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Static and dynamic linking require different options. <a href="#table-linking-options-type">Linking Options for Different Types</a> summarizes
the linking needed based on the type of linking and the application&#8217;s requirement for DSP ISA support.</p>
</div>
<table id="table-linking-options-type" class="tableblock frame-topbot grid-rows stretch">
<caption class="title">Table 4. Linking Options for Different Types</caption>
<colgroup>
<col style="width: 12.5%;">
<col style="width: 12.5%;">
<col style="width: 12.5%;">
<col style="width: 12.5%;">
<col style="width: 12.5%;">
<col style="width: 37.5%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Linking Type</th>
<th class="tableblock halign-left valign-top">DSP ISA Extension</th>
<th class="tableblock halign-left valign-top">RISC-V Vector and AndeStar V5 Vector Dot Product Extensions</th>
<th class="tableblock halign-left valign-top">RISC-V Vector Segment Load/Store Instructions</th>
<th class="tableblock halign-left valign-top">RISC-V Vector ELEN</th>
<th class="tableblock halign-left valign-top">Linking Options</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top" rowspan="6"><p class="tableblock">Static Linking</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-static -lnn</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-static -lnn_p -mext-dsp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-static -lnn_v -mext-vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-static -lnn_v_seg -mext-vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-static -lnn_v_elen64 -mext-vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-static -lnn_v_elen64_seg -mext-vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="6"><p class="tableblock">Dynamic Linking (default)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-lnn</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-lnn_p -mext-dsp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-lnn_v -mext-vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-lnn_v_seg -mext-vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-lnn_v_elen64 -mext-vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Without</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">With</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-lnn_v_elen64_seg -mext-vector</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>The linking options required depend on whether the target system supports DSP ISA Extension.
For systems with this support, use options such as <code>-static -lnn_p -mext-dsp</code> and <code>-lnn_p -mext-dsp</code> to build applications.
For systems without the DSP ISA Extension support, use options like <code>-static -lnn</code> and <code>-lnn</code>.</p>
</div>
<div class="paragraph">
<p>Additionally, if your target system is integrated with AndesCore 45-series processors,
enable optimizations for these processors with the <code>-mtune=andes-45-series</code> option.
Ensure you select the correct options for your specific target system.</p>
</div>
</div>
<div class="sect2">
<h3 id="_notes_for_newlib_mculib_and_glibc_toolchains">Notes for Newlib, MCUlib, and Glibc Toolchains</h3>
<div class="paragraph">
<p>When targeting AndesCore 23-series processors, use the <code>-mtune=andes-23-series</code> option;
for AndesCore 45-series processors, use the <code>-mtune=andes-45-series</code> option to enable processor-specific optimizations.</p>
</div>
<div class="paragraph">
<p>If your application uses functions involving the half-precision floating-point data type, compile it with the
<code>-mzfh</code> option and ensure that your toolchain (e.g., <code>v5f</code> or <code>v5d</code> toolchain) supports hard-float.</p>
</div>
<div class="paragraph">
<p>In addition, to prevent potential issues when loading the program,
be aware that applications built with the following options cannot be executed on targets that lack the corresponding support:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>-mext-dsp</code>: DSP ISA Extension</p>
</li>
<li>
<p><code>-mext-vector</code>: RISC-V Vector Extension</p>
</li>
<li>
<p><code>-lnn_v_seg -mext-vector</code> or <code>-lnn_v_elen64_seg -mext-vector</code>: RISC-V Vector segment load/store instructions</p>
</li>
<li>
<p><code>-lnn_v_elen64 -mext-vector</code> or <code>-lnn_v_elen64_seg -mext-vector</code>: ELEN=64</p>
</li>
<li>
<p><code>-mzfh</code>: Half-precision floating-point extension</p>
</li>
<li>
<p><code>-mext-zc</code>: RISC-V Code Size Reduction Extension</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="section:function_documentation">Function Documentation</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="#table-libnn-function-list">NN Library Function List</a> categorizes all functions of NN Library and includes a <strong>Supported Since</strong> column.
This column uses numbers to indicate the AndesAIRE NN SDK version in which each function first became available:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>1 = AndesAIRE NN SDK 1.0.0 Beta (NN Library 3.1.0)</p>
</li>
<li>
<p>2 = AndesAIRE NN SDK 1.0.0 Official (NN Library 3.2.0)</p>
</li>
<li>
<p>3 = AndesAIRE NN SDK 1.1.0 Official (NN Library 3.3.0)</p>
</li>
</ul>
</div>
<table id="table-libnn-function-list" class="tableblock frame-topbot grid-rows stretch">
<caption class="title">Table 5. NN Library Function List</caption>
<colgroup>
<col style="width: 22.2222%;">
<col style="width: 66.6666%;">
<col style="width: 11.1112%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Category</th>
<th class="tableblock halign-left valign-top">Function</th>
<th class="tableblock halign-left valign-top">Supported Since</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top" rowspan="31"><p class="tableblock">Activation Functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>riscv_nn_activate_s8</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_activate_s8_2buf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_activate_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_activate_s16_2buf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_activate_s16_hp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_gelu_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_gelu_f32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_leaky_relu_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_leaky_relu_s8_2buf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_leaky_relu_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_leaky_relu_s16_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_leaky_relu_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_prelu_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_relu_any_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_relu_any_s8_2buf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_relu_any_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_relu_any_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_relu_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_relu_s8_2buf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_relu_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_relu_s16_2buf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_relu_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_sigmoid_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_sigmoid_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_sigmoid_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_silu_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_silu_f32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_tanh_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_tanh_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_tanh_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_tanh_f32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="21"><p class="tableblock">Basic Functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>riscv_nn_add_s8_sym</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_add_s8_sym_round</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_broadcast_mul_asym_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_broadcast_mul_asym_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_add_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_add_s16_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_add_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_addc_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_addc_s16_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_mul_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_mul_s16_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_mul_s16_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_mulc_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_mulc_s16_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_mul_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_rsubc_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_rsubc_s16_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_sub_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_sub_s16_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_subc_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_ew_subc_s16_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="28"><p class="tableblock">Concatenation Functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>riscv_nn_concate_s8_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_concate_s8_x</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_concate_s8_y</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_concate_s8_z</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_concate_s16_w</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_concate_s16_x</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_concate_s16_y</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_concate_s16_z</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_concate_f16_w</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_concate_f16_x</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_concate_f16_y</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_concate_f16_z</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_pad_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_pad_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_slice_s16_w</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_slice_s16_x</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_slice_s16_y</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_slice_s16_z</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_split_s8_w</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_split_s8_x</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_split_s8_y</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_split_s8_z</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_split_s16_w</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_split_s16_x</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_split_s16_y</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_split_s16_z</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_strided_slice_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_strided_slice_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="124"><p class="tableblock">Convolution Functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_sft_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s16_s16_s16_sft_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_sym_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s16_s8_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_u8_s8_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s8_s8_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s16_s8_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_sym_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s16_s8_sym_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_u8_s8_sym_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s8_s8_sym_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_u8_s16_s8_sym_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_sym_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s8_s8_sym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s16_s8_sym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_u8_s8_sym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_s8_s8_sym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_s16_s8_sym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1xn_HWC_s16_s16_s8_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_s16_s16_s8_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_f16_f16_f16_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_HWC_f16_f16_f16_bias_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_f16_f16_f16_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_conv_dw_HWC_f32_f32_f32_bias_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="36"><p class="tableblock">Fully-Connected Layer Functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>riscv_nn_batch_matmul_s8_s8_s8</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_batch_matmul_s16_s16_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s8_s8_sft_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s8_s8_sft_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s16_s16_s16_sft_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s16_s16_s16_sft_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s8_s8_sym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s16_s8_sym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_u8_s8_sym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_s8_s8_sym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_s16_s8_sym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s8_s8_sym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s16_s8_sym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_u8_s8_sym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_s8_s8_sym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_s16_s8_sym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s8_s8_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s16_s8_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_u8_s8_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_s8_s8_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_s16_s8_sym_bias_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s8_s8_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s16_s8_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_u8_s8_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_s8_s8_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_u8_s16_s8_sym_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_wt_converter</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s16_wt_converter</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_mat_vec_s8_wt_converter</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s8_s8_asym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s8_s8_s8_asym_bias_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s16_s16_s8_asym_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_s16_s16_s8_asym_bias_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_fc_f16_f16_f16_bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="13"><p class="tableblock">Pooling Functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>riscv_nn_avepool_HWC_s8</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_avepool_HWC_s8_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_avepool_HWC_s8_any_act</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_avepool_HWC_s8_any_act_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_avepool_HWC_s16_any_act</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_avepool_HWC_s16_any_act_get_buffer_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_avepool_HWC_s8_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_avepool_HWC_s16_asym</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_avepool_HWC_f16_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_maxpool_HWC_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_maxpool_HWC_s8_any_act</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_maxpool_HWC_s16_any_act</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_maxpool_HWC_f16_any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="11"><p class="tableblock">Softmax Functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>riscv_nn_softmax_s8_fast</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_softmax_s16_fast</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_softmax_s8_hp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_softmax_s8_s16_hp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_softmax_u8_hp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_softmax_s16_hp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_softmax_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_softmax_f32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_softmax_f32_2pass</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_softmax2d_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_softmax2d_f32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="41"><p class="tableblock">Utils Functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>get_version_libnn</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_argmax_f32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_channel_shuffle_CHW_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_channel_shuffle_HWC_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_dequantize_s8_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_dequantize_s8_f32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_dequantize_s16_f32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_exp_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_exp_f32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_gather_HWC_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_gather_HWC_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_layer_norm_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_layer_norm_f32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_lstm_unidirectional_s16_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_pixel_shuffle_HWC_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_quantize_f16_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_quantize_f32_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_quantize_f32_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_reduce_sum_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_reduce_sum_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_requantize_s8_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_requantize_s16_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_requantize_s16_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_reshape_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_reshape_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_reverseV2_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_reverseV2_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_rms_norm_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_scatter_nd_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_scatter_nd_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_subspectral_norm_f32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_svdf_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_svdf_s8_state_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_top_k_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_top_k_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_transpose_4d_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_transpose_4d_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_transpose_4d_s32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_upsampling2d_HWC_s8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_upsampling2d_HWC_s16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>3</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">riscv_nn_upsampling2d_HWC_f16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect1">
<h2 id="section:function_activation">Activation Functions</h2>
<div class="sectionbody">
<div class="paragraph">
<p>These functions introduce nonlinearity to the neural network by filtering the input data.
These include Gaussian Error Linear Unit (GELU), Hyperbolic tangent (Tanh), Rectified Linear Unit (ReLU), and Sigmoid functions.</p>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_activate_s8">riscv_nn_activate_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_activate_s8 (q7_t * in_out, uint32_t size, uint16_t int_bits, riscv_nn_activation_fun act_fun)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input vectors using
either the Sigmoid or Tanh function, along with in-place and look-up table (LUT) algorithms.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in, out] in_out</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] int_bits</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of the bits in the integer part should be less than 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_fun</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Selection of activation functions</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Supported activation functions include:</p>
<table class="tableblock frame-none grid-none" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>NN_SIGMOID</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sigmoid activation function</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>NN_TANH</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tanh activation function</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_activate_s8_2buf">riscv_nn_activate_s8_2buf</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_activate_s8_2buf (q7_t * in_vec, uint32_t size, uint16_t int_bits, riscv_nn_activation_fun act_fun, q7_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input vectors using
either the Sigmoid or Tanh function, along with out-of-place and LUT algorithms.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] int_bits</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of the bits in the integer part should be less than 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_fun</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Selection of activation functions</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Supported activation functions include:</p>
<table class="tableblock frame-none grid-none" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>NN_SIGMOID</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sigmoid activation function</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>NN_TANH</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tanh activation function</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_activate_s16">riscv_nn_activate_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_activate_s16 (q15_t * in_out, uint32_t size, uint16_t int_bits, riscv_nn_activation_fun act_fun)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 16-bit integer input vectors using
either the Sigmoid or Tanh function, along with in-place and LUT algorithms.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in, out] in_out</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] int_bits</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of the bits in the integer part should be less than 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_fun</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Selection of activation functions</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Supported activation functions include:</p>
<table class="tableblock frame-none grid-none" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>NN_SIGMOID</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sigmoid activation function</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>NN_TANH</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tanh activation function</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_activate_s16_2buf">riscv_nn_activate_s16_2buf</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_activate_s16_2buf (q15_t * in_vec, uint32_t size, uint16_t int_bits, riscv_nn_activation_fun act_fun, q15_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 16-bit integer input vectors using
either the Sigmoid or Tanh function, along with out-of-place and LUT algorithms.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] int_bits</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of the bits in the integer part should be less than 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_fun</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Selection of activation functions</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Supported activation functions include:</p>
<table class="tableblock frame-none grid-none" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>NN_SIGMOID</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sigmoid activation function</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>NN_TANH</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tanh activation function</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_activate_s16_hp">riscv_nn_activate_s16_hp</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_activate_s16_hp (const q15_t * in_vec, q15_t * out_vec, const uint32_t size, const uint32_t left_shift, const riscv_nn_activation_fun act_fun)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 16-bit integer input vectors using
either the Sigmoid or Tanh function, along with a high-precision algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] left_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_fun</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Selection of activation functions</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Let <code>INT_BITS</code> represent the number of the bits in the integer part of the inputs.
Set <code>left_shift</code> to <code>INT_BITS - 3</code> if <code>INT_BITS</code> is 3 or greater. Otherwise, set <code>left_shift</code> to 0.</p>
</li>
<li>
<p>The inputs should be scaled down by the following if <code>INT_BITS</code> is less than 3:</p>
<div class="stemblock">
<div class="content">
\[
\mathtt{\frac{1}{2^{(3 - INT\_BITS)}}}
\]
</div>
</div>
</li>
<li>
<p>Supported activation functions include:</p>
<table class="tableblock frame-none grid-none" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>NN_SIGMOID</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sigmoid activation function</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>NN_TANH</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tanh activation function</p></td>
</tr>
</tbody>
</table>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_gelu_f16">riscv_nn_gelu_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_gelu_f16 (const float16_t * in_vec, uint32_t size, float16_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on half-precision floating-point input vectors using the GELU function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_gelu_f32">riscv_nn_gelu_f32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_gelu_f32 (const float32_t * in_vec, uint32_t size, float32_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on single-precision floating-point input vectors using the GELU function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_leaky_relu_s8">riscv_nn_leaky_relu_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_leaky_relu_s8 (q7_t * in_out, uint32_t size, q15_t slope)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input vectors
using the Leaky ReLU function, along with an in-place algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in, out] in_out</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] slope</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Slope value to be multiplied with the negative inputs.
                         The result is right-shifted 15 bits to scale back to signed 8-bit integer.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">#define SIZE    1024
q15_t slope = 16384;
q7_t in_out[SIZE] = {...};
riscv_nn_leaky_relu_s8 (in_out, SIZE, slope);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_leaky_relu_s8_2buf">riscv_nn_leaky_relu_s8_2buf</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_leaky_relu_s8_2buf (q7_t * in_vec, uint32_t size, q15_t slope, q7_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input vectors
using the Leaky ReLU function, along with an out-of-place algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] slope</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Slope value to be multiplied with the negative inputs.
                         The result is right-shifted 15 bits to scale back to signed 8-bit integer.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_leaky_relu_s8_asym">riscv_nn_leaky_relu_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_leaky_relu_s8_asym (int8_t * in_vec, int8_t * out_vec, const uint32_t size, const int32_t multi_identity, const int32_t shift_identity, const int32_t multi_alpha, const int32_t shift_alpha, const int32_t in_offset, const int32_t out_offset, const int8_t act_min, const int8_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input vectors
using the Leaky ReLU function and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] multi_identity</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing nonnegative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] shift_identity</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for quantizing nonnegative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] multi_alpha</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing negative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] shift_alpha</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for quantizing negative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input vector. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the outputs. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>shift_identity</code> or <code>shift_alpha</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_leaky_relu_s16_asym">riscv_nn_leaky_relu_s16_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_leaky_relu_s16_asym (int16_t * in_vec, int16_t * out_vec, const uint32_t size, const int32_t multi_identity, const int32_t shift_identity, const int32_t multi_alpha, const int32_t shift_alpha, const int32_t in_offset, const int32_t out_offset, const int16_t act_min, const int16_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 16-bit integer input vectors
using the Leaky ReLU function and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] multi_identity</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing nonnegative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] shift_identity</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for quantizing nonnegative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] multi_alpha</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing negative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] shift_alpha</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for quantizing negative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input vector. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the outputs. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>shift_identity</code> or <code>shift_alpha</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_leaky_relu_f16">riscv_nn_leaky_relu_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_leaky_relu_f16 (const float16_t * in_vec, uint32_t size, float16_t slope, float16_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on half-precision floating-point input vectors using the Leaky ReLU function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] slope</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Slope value to be multiplied with the negative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_prelu_s8_asym">riscv_nn_prelu_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_prelu_s8_asym (int8_t * in_vec, int8_t * out_vec, const int8_t * alpha_data, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const int32_t multi_identity, const int32_t shift_identity, const int32_t multi_alpha, const int32_t shift_alpha, const int32_t in_offset, const int32_t alpha_offset, const int32_t out_offset, const int8_t act_min, const int8_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input tensors
using the PReLU function and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] alpha_data</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the negative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] multi_identity</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing nonnegative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] shift_identity</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for quantizing nonnegative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] multi_alpha</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing negative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] shift_alpha</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for quantizing negative inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input vector. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the outputs. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>shift_identity</code> or <code>shift_alpha</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_relu_any_s8">riscv_nn_relu_any_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_relu_any_s8 (q7_t * data, uint32_t size, q7_t max_val)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input vectors
using the ReLU function, along with an in-place algorithm.
The maximum output from the ReLU function is user-specified, for example:</p>
<div class="stemblock">
<div class="content">
\[
\mathtt{f(x) = \min(\max(0, x), \max\_val)}
\]
</div>
</div>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in, out] data</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] max_val</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value to limit the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_relu_any_s8_2buf">riscv_nn_relu_any_s8_2buf</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_relu_any_s8_2buf (q7_t * in_vec, uint32_t size, q7_t max_val, q7_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input vectors
using the ReLU function, along with an out-of-place algorithm.
The maximum output from the ReLU function is user-specified, for example:</p>
<div class="stemblock">
<div class="content">
\[
\mathtt{f(x) = \min(\max(0, x), \max\_val)}
\]
</div>
</div>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] max_val</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value to limit the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_relu_any_s16">riscv_nn_relu_any_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_relu_any_s16 (q15_t * data, uint32_t size, q15_t max_val)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 16-bit integer input vectors
using the ReLU function, along with an in-place algorithm.
The maximum output from the ReLU function is user-specified, for example:</p>
<div class="stemblock">
<div class="content">
\[
\mathtt{f(x) = \min(\max(0, x), \max\_val)}
\]
</div>
</div>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in, out] data</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] max_val</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value to limit the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_relu_any_f16">riscv_nn_relu_any_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_relu_any_f16 (const float16_t * in_vec, uint32_t size, float16_t max_val, float16_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on half-precision floating-point input vectors
using the ReLU function. The maximum output from the ReLU function is user-specified, for example:</p>
<div class="stemblock">
<div class="content">
\[
\mathtt{f(x) = \min(\max(0, x), \max\_val)}
\]
</div>
</div>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] max_val</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value to limit the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_relu_s8">riscv_nn_relu_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_relu_s8 (q7_t * in_out, uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input vectors
using the ReLU function, along with an in-place algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in, out] in_out</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">#define H    16
#define W    16
#define CH   5
#define NUM (H * W * CH)
q7_t in_out[NUM] = {...};
riscv_nn_relu_s8 (in_out, NUM);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_relu_s8_2buf">riscv_nn_relu_s8_2buf</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_relu_s8_2buf (q7_t * in_vec, uint32_t size, q7_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input vectors
using the ReLU function, along with an out-of-place algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_relu_s16">riscv_nn_relu_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_relu_s16 (q15_t * in_out, uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 16-bit integer input vectors
using the ReLU function, along with an in-place algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in, out] in_out</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_relu_s16_2buf">riscv_nn_relu_s16_2buf</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_relu_s16_2buf (q15_t * in_vec, uint32_t size, q15_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 16-bit integer input vectors
using the ReLU function, along with an out-of-place algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_relu_f16">riscv_nn_relu_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_relu_f16 (const float16_t * in_vec, uint32_t size, float16_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on half-precision floating-point input vectors using the ReLU function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_sigmoid_s8">riscv_nn_sigmoid_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_sigmoid_s8 (const int32_t in_offset, const int32_t in_range_radius, const int16_t in_mult, const int16_t in_shift, const uint32_t size, const int8_t * in_vec, int8_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input vectors using the Sigmoid function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_range_radius</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum or minimum value for the inputs.
                         If the input is less than or equal to <code>in_range_radius</code>, the output is limited to -128.
                         Conversely, if the input is greater than <code>in_range_radius</code>, the output is limited to 127.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied when rescaling the inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied when rescaling the inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>in_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_sigmoid_s16">riscv_nn_sigmoid_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_sigmoid_s16 (const int32_t in_offset, const int32_t in_range_radius, const int16_t in_mult, const int16_t in_lshift, const uint32_t size, const int16_t * in_vec, int16_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 16-bit integer input vectors using the Sigmoid function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_range_radius</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum or minimum value for the inputs.
                         If the input is less than or equal to <code>in_range_radius</code>, the output is limited to -32768.
                         Conversely, if the input is greater than <code>in_range_radius</code>, the output is limited to 32767.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied when rescaling the inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied when rescaling the inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>in_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_sigmoid_f16">riscv_nn_sigmoid_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_sigmoid_f16 (const float16_t * in_vec, uint32_t size, float16_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on half-precision floating-point input vectors using the Sigmoid function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The inputs are restricted to the range <code>[-10, 10]</code>.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_silu_f16">riscv_nn_silu_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_silu_f16(const float16_t * in_vec, uint32_t size, float16_t * out_vec);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on half-precision floating-point input vectors using the SiLU function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_silu_f32">riscv_nn_silu_f32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_silu_f32(const float32_t * in_vec, uint32_t size, float32_t * out_vec);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on single-precision floating-point input vectors using the SiLU function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_tanh_s8">riscv_nn_tanh_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_tanh_s8 (const int32_t in_offset, const int32_t in_range_radius, const int16_t in_mult, const int16_t in_shift, const uint32_t size, const int8_t * in_vec, int8_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 8-bit integer input vectors using the Tanh function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_range_radius</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum or minimum value for the inputs.
                         If the input is less than or equal to <code>in_range_radius</code>, the output is limited to -128.
                         Conversely, if the input is greater than <code>in_range_radius</code>, the output is limited to 127.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied when rescaling the inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied when rescaling the inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>in_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_tanh_s16">riscv_nn_tanh_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_tanh_s16 (const int32_t in_offset, const int32_t in_range_radius, const int16_t in_mult, const int16_t in_shift, const uint32_t size, const int16_t * in_vec, int16_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on signed 16-bit integer input vectors using the Tanh function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_range_radius</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum or minimum value for the inputs.
                         If the input is less than or equal to <code>in_range_radius</code>, the output is limited to -32768.
                         Conversely, if the input is greater than <code>in_range_radius</code>, the output is limited to 32767.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied when rescaling the inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied when rescaling the inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>in_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_tanh_f16">riscv_nn_tanh_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_tanh_f16 (const float16_t * in_vec, uint32_t size, float16_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on half-precision floating-point input vectors using the Tanh function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The inputs are restricted to the range <code>[-10, 10]</code>.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_tanh_f32">riscv_nn_tanh_f32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_tanh_f32 (const float32_t * in_vec, uint32_t size, float32_t * out_vec);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs activation on single-precision floating-point input vectors using the Tanh function.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input/output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="section:function_basic">Basic Functions</h2>
<div class="sectionbody">
<div class="paragraph">
<p>These functions perform elementwise basic arithmetic operations.</p>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_add_s8_sym">riscv_nn_add_s8_sym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_add_s8_sym (const q7_t * in_vec1, const q7_t * in_vec2, const int16_t * scale1, const int16_t * scale2, const uint32_t size, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise addition on signed 8-bit integer input vectors,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first scaling vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second scaling vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vectors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the accumulator</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the elementwise addition results</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p><a href="#figure:riscv_nn_add_s8_sym_algorithm_flowchart">Symmetric Quantization for Elementwise Addition</a> illustrates the calculation of each element,
where rectangles represent inputs or outputs, circles denote arithmetic operations,
solid lines indicate the required steps, and dashed lines represents optional ones.</p>
<div id="figure:riscv_nn_add_s8_sym_algorithm_flowchart" class="imageblock text-center">
<div class="content">
<img src="images/riscv_nn_add_s8_sym_algorithm_flowchart.png" alt="riscv nn add s8 sym algorithm flowchart">
</div>
<div class="title">Figure 1. Symmetric Quantization for Elementwise Addition</div>
</div>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">#define SIZE    1024
uint16_t pre_rshift = 8;    //The scaled input addition result fits in
                            //24 bits; pre_rshift should be [0, 24] to
                            //scale down to 16-bit.
uint16_t out_scale = 3;     //Scale up the result to 18-bit range.
uint16_t post_rshift = 11;  //Scale down the result to 7-bit range.

q7_t in_vec1[SIZE] = {...};
q7_t in_vec2[SIZE] = {...};
int16_t scale1[SIZE] = {...};
int16_t scale2[SIZE] = {...};
q7_t out_vec[SIZE];

riscv_nn_add_s8_sym (in_vec1, in_vec2, scale1, scale2, SIZE, pre_rshift, out_scale, post_rshift, out_vec);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_add_s8_sym_round">riscv_nn_add_s8_sym_round</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_add_s8_sym_round (const q7_t * in_vec1, const q7_t * in_vec2, const uint32_t scale1, const uint32_t scale2, const uint32_t size, const uint16_t pre_rshift, const uint32_t out_scale, const uint16_t post_rshift, q7_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise addition on signed 8-bit integer input vectors,
applying symmetric quantization and rounding to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for the first input vector. It should be in the range [0, 2<sup>23</sup>].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for the second input vector. It should be in the range [0, 2<sup>23</sup>].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vectors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the accumulator</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the elementwise addition results</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><a href="#figure:riscv_nn_add_s8_sym_algorithm_flowchart">Symmetric Quantization for Elementwise Addition</a> illustrates the calculation of each element.</p>
</li>
<li>
<p>The right-shift operations for this function include rounding.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_broadcast_mul_asym_s8">riscv_nn_broadcast_mul_asym_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_broadcast_mul_asym_s8 (const int8_t * in_tensor, const int8_t * in_alpha, int8_t * out_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const int32_t out_scale, const int32_t out_shift, const int32_t in_offset, const int32_t alpha_offset, const int32_t out_offset, const int8_t act_min, const int8_t act_max);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs broadcast multiplication on signed 8-bit integer inputs,
applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_alpha</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the multiplier vector and its length should be in_tensor_ch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for the quantization on the outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the inputs. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] alpha_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the multiplier vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_broadcast_mul_asym_s16">riscv_nn_broadcast_mul_asym_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_broadcast_mul_asym_s16 (const int16_t * in_tensor, const int16_t * in_alpha, int16_t * out_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const int32_t out_scale, const int32_t out_shift, const int32_t in_offset, const int32_t alpha_offset, const int32_t out_offset, const int16_t act_min, const int16_t act_max);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs broadcast multiplication on signed 16-bit integer inputs,
applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_alpha</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the multiplier vector and its length should be in_tensor_ch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for the quantization on the outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] alpha_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_add_s8_asym">riscv_nn_ew_add_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_add_s8_asym (const int8_t * in_vec1, const int8_t * in_vec2, const int32_t in_offset1, const int32_t in_scale1, const int32_t in_rshift1, const int32_t in_offset2, const int32_t in_scale2, const int32_t in_rshift2, const int32_t lshift, int8_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_rshift, const int32_t act_min, const int32_t act_max, const uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise addition on signed 8-bit integer input vectors,
applying asymmetric quantization to both the inputs and outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the first input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the second input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the first and second input vectors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the elementwise addition results</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the outputs. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vectors</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><a href="#figure:riscv_nn_ew_add_s8_asym_algorithm_flowchart">Asymmetric Quantization for Elementwise Addition</a> illustrates the calculation of each element.</p>
<div id="figure:riscv_nn_ew_add_s8_asym_algorithm_flowchart" class="imageblock text-center">
<div class="content">
<img src="images/riscv_nn_ew_add_s8_asym_algorithm_flowchart.png" alt="riscv nn ew add s8 asym algorithm flowchart">
</div>
<div class="title">Figure 2. Asymmetric Quantization for Elementwise Addition</div>
</div>
</li>
<li>
<p>The multiplication formula involving <code>in_scale1</code>, <code>in_scale2</code>, and <code>out_scale</code> can be roughly expressed as follows:</p>
<div class="listingblock">
<div class="content">
<pre>32b = ((int64_t)32b * 32b) &gt;&gt; 31</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">#define SIZE    1024
int32_t in_offset1 = 16;        //Offset for in_vec1
int32_t in_scale1 = (1&lt;&lt;28);    //Scale down in_vec1 by 1/2^3
int32_t in_rshift1 = 3;         //Scale down in_vec1 by 1/2^3
int32_t in_offset2 = 17;        //Offset for in_vec2
int32_t in_scale2 = (1&lt;&lt;28);    //Scale down in_vec2 by 1/2^3
int32_t in_rshift2 = 3;         //Scale down in_vec2 by 1/2^3
int32_t lshift = 10;            //Scale up the input tensor by 2^10
int32_t out_offset = 18;        //Offset for the output tensor
int32_t out_scale = (1&lt;&lt;30);    //Scale down the result by 1/2
int32_t out_rshift = 4;         //Scale down the result 1/2^4
int32_t act_min = 0xffffffa3;   //Limit the outputs to the range
                                //[0xffffffa3, 0x0000005d]
int32_t act_max = 0x0000005d;   //Limit the outputs to the range
                                //[0xffffffa3, 0x0000005d]

int8_t in_vec1[SIZE] = {...};
int8_t in_vec2[SIZE] = {...};
int8_t out_vec[SIZE];

riscv_nn_ew_add_s8_asym (in_vec1, in_vec2, in_offset1, in_scale1, in_rshift1, in_offset2, in_scale2, in_rshift2, lshift, out_vec, out_offset, out_scale, out_rshift, act_min, act_max, SIZE);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_add_s16_asym">riscv_nn_ew_add_s16_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_add_s16_asym (const int16_t * in_vec1, const int16_t * in_vec2, const int32_t in_offset1, const int32_t in_scale1, const int32_t in_rshift1, const int32_t in_offset2, const int32_t in_scale2, const int32_t in_rshift2, const int32_t lshift, int16_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_rshift, const int32_t act_min, const int32_t act_max, const int32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise addition on signed 16-bit integer input vectors,
applying asymmetric quantization to both the inputs and outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the first and second input vectors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the elementwise addition results</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vectors</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p><a href="#figure:riscv_nn_ew_add_s8_asym_algorithm_flowchart">Asymmetric Quantization for Elementwise Addition</a> illustrates the calculation of each element,
where <code>in_offset1</code>, <code>in_offset2</code>, and <code>out_offset</code> are dummies for this function.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_add_f16">riscv_nn_ew_add_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_add_f16 (const float16_t * in_vec1, const float16_t * in_vec2, float16_t * out_vec, const uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise addition on half-precision floating-point input vectors.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the elementwise addition results</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vectors</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_addc_s8_asym">riscv_nn_ew_addc_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_addc_s8_asym (const int8_t * in_vec, const int32_t in_const, const int32_t in_offset, const int32_t in_scale, const int32_t in_rshift, const int32_t lshift, int8_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_rshift, const int32_t act_min, const int32_t act_max, const uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise addition on a signed 8-bit integer input vector and a constant,
applying asymmetric quantization to either the inputs or the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_const</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant value to be added. It should be in the range [-255, 255].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the outputs. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_addc_s16_asym">riscv_nn_ew_addc_s16_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_addc_s16_asym (const int16_t * in_vec, const int32_t in_const, const int32_t in_offset, const int32_t in_scale, const int32_t in_rshift, const int32_t lshift, int16_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_rshift, const int32_t act_min, const int32_t act_max, const uint32_t size);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise addition on a signed 16-bit integer input vector and a constant,
applying asymmetric quantization to either the inputs or the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_const</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant value to be added</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_mul_s8_asym">riscv_nn_ew_mul_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_mul_s8_asym (const int8_t * in_vec1, const int8_t * in_vec2, const int32_t in_offset1, const int32_t in_offset2, int8_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_shift, const int32_t act_min, const int32_t act_max, const uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise multiplication on signed 8-bit integer input vectors,
applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the first input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the second input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the elementwise multiplication results</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the outputs. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for the quantization on the outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vectors</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><a href="#figure:riscv_nn_ew_mul_s8_asym_algorithm_flowchart">Asymmetric Quantization for Elementwise Multiplication</a> illustrates the calculation of each element.</p>
<div id="figure:riscv_nn_ew_mul_s8_asym_algorithm_flowchart" class="imageblock text-center">
<div class="content">
<img src="images/riscv_nn_ew_mul_s8_asym_algorithm_flowchart.png" alt="riscv nn ew mul s8 asym algorithm flowchart">
</div>
<div class="title">Figure 3. Asymmetric Quantization for Elementwise Multiplication</div>
</div>
</li>
<li>
<p>The multiplication formula involving <code>out_scale</code> can be roughly expressed as follows:</p>
<div class="listingblock">
<div class="content">
<pre>32b = ((int64_t)32b * 32b) &gt;&gt; 31</pre>
</div>
</div>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">#define SIZE    1024
int32_t in_offset1 = 16;        //Offset for in_vec1
int32_t in_offset2 = 17;        //Offset for in_vec2
int32_t out_offset = 18;        //Offset for the output tensor
int32_t out_scale = (1&lt;&lt;30);    //Scale down the output tensor by 1/2
int32_t out_shift = -4;         //Scale down the output tensor by 1/2^4
int32_t act_min = 0xffffffa3;   //Limit the outputs to the range
                                //[0xffffffa3, 0x0000005d]
int32_t act_max = 0x0000005d;   //Limit the outputs to the range
                                //[0xffffffa3, 0x0000005d]

int8_t in_vec1[SIZE] = {...};
int8_t in_vec2[SIZE] = {...};
int8_t out_vec[SIZE];

riscv_nn_ew_mul_s8_asym (in_vec1, in_vec2, in_offset1, in_offset2, out_vec, out_offset, out_scale, out_shift, act_min, act_max, SIZE);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_mul_s16_asym">riscv_nn_ew_mul_s16_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_mul_s16_asym (const int16_t * in_vec1, const int16_t * in_vec2, const int32_t in_offset1, const int32_t in_offset2, int16_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_shift, const int32_t act_min, const int32_t act_max, const int32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise multiplication on signed 16-bit integer input and output vectors,
applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the elementwise multiplication results</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for the quantization on the outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vectors</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><a href="#figure:riscv_nn_ew_mul_s8_asym_algorithm_flowchart">Asymmetric Quantization for Elementwise Multiplication</a> illustrates the calculation of each element,
where <code>in_offset1</code>, <code>in_offset2</code>, and <code>out_offset</code> are dummies for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_mul_s16_s8_asym">riscv_nn_ew_mul_s16_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_mul_s16_s8_asym (const int16_t * in_vec1, const int16_t * in_vec2, int8_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_shift, const int32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise multiplication on signed 16-bit integer input vectors
and signed 8-bit integer output vectors, applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the elementwise multiplication results</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the outputs. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for the quantization on the outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vectors</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_mulc_s8_asym">riscv_nn_ew_mulc_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_mulc_s8_asym (const int8_t * in_vec, const int32_t in_const, const int32_t in_offset, int8_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_shift, const int32_t act_min, const int32_t act_max, const uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise multiplication on a signed 8-bit integer input vector and a constant,
applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_const</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant multiplier</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the outputs. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for the quantization on the outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_mulc_s16_asym">riscv_nn_ew_mulc_s16_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_mulc_s16_asym (const int16_t * in_vec, const int32_t in_const, const int32_t in_offset, int16_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_shift, const int32_t act_min, const int32_t act_max, const uint32_t size);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise multiplication on a signed 16-bit integer input vector and a constant,
applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_const</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant multiplier</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for the quantization on the outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_mul_f16">riscv_nn_ew_mul_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_mul_f16 (const float16_t * in_vec1, const float16_t * in_vec2, float16_t * out_vec, const uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise multiplication on half-precision floating-point input vectors.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the elementwise multiplication results</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vectors</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_rsubc_s8_asym">riscv_nn_ew_rsubc_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_rsubc_s8_asym (const int8_t * in_vec, const int32_t in_const, const int32_t in_offset, const int32_t in_scale, const int32_t in_rshift, const int32_t lshift, int8_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_rshift, const int32_t act_min, const int32_t act_max, const uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise subtraction of a constant from a signed 8-bit integer input vector,
applying asymmetric quantization to both the inputs and outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_const</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant value used for subtraction</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount for inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_rsubc_s16_asym">riscv_nn_ew_rsubc_s16_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_rsubc_s16_asym (const int16_t * in_vec, const int32_t in_const, const int32_t in_offset, const int32_t in_scale, const int32_t in_rshift, const int32_t lshift, int16_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_rshift, const int32_t act_min, const int32_t act_max, const uint32_t size);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise subtraction of a constant from a signed 16-bit integer input vector,
applying asymmetric quantization to both the inputs and outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_const</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant value used for subtraction</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount for inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_sub_s8_asym">riscv_nn_ew_sub_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_sub_s8_asym (const int8_t * in_vec1, const int8_t * in_vec2, const int32_t in_offset1, const int32_t in_scale1, const int32_t in_rshift1, const int32_t in_offset2, const int32_t in_scale2, const int32_t in_rshift2, const int32_t lshift, int8_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_rshift, const int32_t act_min, const int32_t act_max, const uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise subtraction on signed 8-bit integer input vectors,
applying asymmetric quantization to either the inputs or the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the first input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the second input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the first and second input vectors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the outputs. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vectors</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_sub_s16_asym">riscv_nn_ew_sub_s16_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_sub_s16_asym (const int16_t * in_vec1, const int16_t * in_vec2, const int32_t in_offset1, const int32_t in_scale1, const int32_t in_rshift1, const int32_t in_offset2, const int32_t in_scale2, const int32_t in_rshift2, const int32_t lshift, int16_t * out_vec, const int32_t out_offset,const int32_t out_scale, const int32_t out_rshift, const int32_t act_min, const int32_t act_max, const uint32_t size);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise subtraction on signed 16-bit integer input vectors,
applying asymmetric quantization to either the inputs or the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the first input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing the second input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the first and second input vectors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vectors</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_subc_s8_asym">riscv_nn_ew_subc_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_subc_s8_asym (const int8_t * in_vec, const int32_t in_const, const int32_t in_offset, const int32_t in_scale, const int32_t in_rshift, const int32_t lshift, int8_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_rshift, const int32_t act_min, const int32_t act_max, const uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise subtraction of a constant from a signed 8-bit integer input vector,
applying asymmetric quantization to either the inputs or the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_const</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant value used for subtraction</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the outputs. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_ew_subc_s16_asym">riscv_nn_ew_subc_s16_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_ew_subc_s16_asym (const int16_t * in_vec, const int32_t in_const, const int32_t in_offset, const int32_t in_scale, const int32_t in_rshift, const int32_t lshift, int16_t * out_vec, const int32_t out_offset, const int32_t out_scale, const int32_t out_rshift, const int32_t act_min, const int32_t act_max, const uint32_t size);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs elementwise subtraction of a constant from a signed 16-bit integer input vector,
applying asymmetric quantization to either the inputs or the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_const</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant value used for subtraction</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount for quantizing outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the outputs are limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="section:function_concatenation">Concatenation Functions</h2>
<div class="sectionbody">
<div class="paragraph">
<p>These functions concatenate or split the tensor along the specified axis.</p>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_s8_w">riscv_nn_concate_s8_w</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_s8_w (const int8_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, int8_t * out_tensor, const uint32_t out_offset_w)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a signed 8-bit integer input tensor with an output tensor along the W-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s W-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Y, and Z dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_s8_x">riscv_nn_concate_s8_x</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_s8_x (const int8_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, int8_t * out_tensor, const uint16_t out_tensor_x, const uint32_t out_offset_x)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a signed 8-bit integer input tensor with an output tensor along the X-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s X-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same Y, Z, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_s8_y">riscv_nn_concate_s8_y</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_s8_y (const int8_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, int8_t * out_tensor, const uint16_t out_tensor_y, const uint32_t out_offset_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a signed 8-bit integer input tensor with an output tensor along the Y-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s Y-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Z, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_s8_z">riscv_nn_concate_s8_z</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_s8_z (const int8_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, int8_t * out_tensor, const uint16_t out_tensor_z, const uint32_t out_offset_z)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a signed 8-bit integer input tensor with an output tensor along the Z-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s Z-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Y, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_s16_w">riscv_nn_concate_s16_w</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_s16_w (const int16_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, int16_t * out_tensor, const uint32_t out_offset_w)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a signed 16-bit integer input tensor with an output tensor along the W-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s W-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Y, and Z dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_s16_x">riscv_nn_concate_s16_x</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_s16_x (const int16_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, int16_t * out_tensor, const uint16_t out_tensor_x, const uint32_t out_offset_x)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a signed 16-bit integer input tensor with an output tensor along the X-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s X-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same Y, Z, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_s16_y">riscv_nn_concate_s16_y</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_s16_y (const int16_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, int16_t * out_tensor, const uint16_t out_tensor_y, const uint32_t out_offset_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a signed 16-bit integer input tensor with an output tensor along the Y-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s Y-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Z, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_s16_z">riscv_nn_concate_s16_z</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_s16_z (const int16_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, int16_t * out_tensor, const uint16_t out_tensor_z, const uint32_t out_offset_z)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a signed 16-bit integer input tensor with an output tensor along the Z-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s Z-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Y, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_f16_w">riscv_nn_concate_f16_w</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_f16_w (const float16_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, float16_t * out_tensor, const uint32_t out_offset_w)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a half-precision floating-point input tensor with an output tensor along the W-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s W-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Y, and Z dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_f16_x">riscv_nn_concate_f16_x</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_f16_x (const float16_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, float16_t * out_tensor, const uint16_t out_tensor_x, const uint32_t out_offset_x)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a half-precision floating-point input tensor with an output tensor along the X-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s X-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same Y, Z, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_f16_y">riscv_nn_concate_f16_y</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_f16_y (const float16_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, float16_t * out_tensor, const uint16_t out_tensor_y, const uint32_t out_offset_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a half-precision floating-point input tensor with an output tensor along the Y-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s Y-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Z, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_concate_f16_z">riscv_nn_concate_f16_z</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_concate_f16_z (const float16_t * in_tensor, const uint16_t in_tensor_x, const uint16_t in_tensor_y, const uint16_t in_tensor_z, const uint16_t in_tensor_w, float16_t * out_tensor, const uint16_t out_tensor_z, const uint32_t out_offset_z)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function concatenates a half-precision floating-point input tensor with an output tensor along the Z-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset added to the output tensor&#8217;s Z-axis before concatenation</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Y, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_pad_s8">riscv_nn_pad_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_pad_s8 (const int8_t * in_tensor, const uint32_t in_tensor_w, const uint32_t in_tensor_z, const uint32_t in_tensor_y, const uint32_t in_tensor_x, const uint32_t pre_pad_w, const uint32_t pre_pad_z, const uint32_t pre_pad_y, const uint32_t pre_pad_x, const uint32_t post_pad_w, const uint32_t post_pad_z, const uint32_t post_pad_y, const uint32_t post_pad_x, const int8_t pad_value, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function pads a signed 8-bit integer input tensor with the specified value along the W, Z, Y, and X dimensions.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_pad_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the beginning of the W dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_pad_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the beginning of the Z dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the beginning of the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the beginning of the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_pad_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the end of the W dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_pad_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the end of the Z dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the end of the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the end of the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_value</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Value for padding</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_pad_s16">riscv_nn_pad_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_pad_s16 (const int16_t * in_tensor, const uint32_t in_tensor_w, const uint32_t in_tensor_z, const uint32_t in_tensor_y, const uint32_t in_tensor_x, const uint32_t pre_pad_w, const uint32_t pre_pad_z, const uint32_t pre_pad_y, const uint32_t pre_pad_x, const uint32_t post_pad_w, const uint32_t post_pad_z, const uint32_t post_pad_y, const uint32_t post_pad_x, const int16_t pad_value, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function pads a signed 16-bit integer input tensor with the specified value along the W, Z, Y, and X dimensions.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_pad_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the beginning of the W dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_pad_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the beginning of the Z dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the beginning of the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the beginning of the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_pad_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the end of the W dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_pad_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the end of the Z dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the end of the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size at the end of the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_value</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Value for padding</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_slice_s16_w">riscv_nn_slice_s16_w</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_slice_s16_w (const int16_t * in_tensor, const uint32_t in_tensor_w, const uint32_t in_tensor_z, const uint32_t in_tensor_y, const uint32_t in_tensor_x, const uint32_t begin_w, const uint32_t end_w, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function copies a portion of a signed 16-bit integer input tensor along the W-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the W-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the W-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same Z, Y, and X dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_slice_s16_x">riscv_nn_slice_s16_x</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_slice_s16_x (const int16_t * in_tensor, const uint32_t in_tensor_w, const uint32_t in_tensor_z, const uint32_t in_tensor_y, const uint32_t in_tensor_x, const uint32_t begin_x, const uint32_t end_x, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function copies a portion of a signed 16-bit integer input tensor along the X-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the X-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the X-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same W, Z, and Y dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_slice_s16_y">riscv_nn_slice_s16_y</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_slice_s16_y (const int16_t * in_tensor, const uint32_t in_tensor_w, const uint32_t in_tensor_z, const uint32_t in_tensor_y, const uint32_t in_tensor_x, const uint32_t begin_y, const uint32_t end_y, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function copies a portion of a signed 16-bit integer input tensor along the Y-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the Y-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the Y-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same W, Z, and X dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_slice_s16_z">riscv_nn_slice_s16_z</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_slice_s16_z (const int16_t * in_tensor, const uint32_t in_tensor_w, const uint32_t in_tensor_z, const uint32_t in_tensor_y, const uint32_t in_tensor_x, const uint32_t begin_z, const uint32_t end_z, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function copies a portion of a signed 16-bit integer input tensor along the Z-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the Z-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the Z-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same W, Y, and X dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_split_s8_w">riscv_nn_split_s8_w</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_split_s8_w (const int8_t * in_tensor, const uint32_t in_tensor_x, const uint32_t in_tensor_y, const uint32_t in_tensor_z, const uint32_t in_tensor_w, int8_t * out_tensor, const uint32_t split_len_w, const uint32_t in_offset)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function splits a signed 8-bit integer input tensor along the W-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] split_len_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length to be split along the W-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset from the start of the input tensor to the split position</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Y, and Z dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_split_s8_x">riscv_nn_split_s8_x</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_split_s8_x (const int8_t * in_tensor, const uint32_t in_tensor_x, const uint32_t in_tensor_y, const uint32_t in_tensor_z, const uint32_t in_tensor_w, int8_t * out_tensor, const uint32_t split_len_x, const uint32_t in_offset)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function splits a signed 8-bit integer input tensor along the X-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] split_len_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length to be split along the X-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset from the start of the input tensor to the split position</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same Y, Z, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_split_s8_y">riscv_nn_split_s8_y</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_split_s8_y (const int8_t * in_tensor, const uint32_t in_tensor_x, const uint32_t in_tensor_y, const uint32_t in_tensor_z, const uint32_t in_tensor_w, int8_t * out_tensor, const uint32_t split_len_y, const uint32_t in_offset)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function splits a signed 8-bit integer input tensor along the Y-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] split_len_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length to be split along the Y-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset from the start of the input tensor to the split position</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Z, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_split_s8_z">riscv_nn_split_s8_z</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_split_s8_z (const int8_t * in_tensor, const uint32_t in_tensor_x, const uint32_t in_tensor_y, const uint32_t in_tensor_z, const uint32_t in_tensor_w, int8_t * out_tensor, const uint32_t split_len_z, const uint32_t in_offset)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function splits a signed 8-bit integer input tensor along the Z-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] split_len_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length to be split along the Z-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset from the start of the input tensor to the split position</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Y, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_split_s16_w">riscv_nn_split_s16_w</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_split_s16_w (const int16_t * in_tensor, const uint32_t in_tensor_x, const uint32_t in_tensor_y, const uint32_t in_tensor_z, const uint32_t in_tensor_w, int16_t * out_tensor, const uint32_t split_len_w, const uint32_t in_offset)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function splits a signed 16-bit integer input tensor along the W-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] split_len_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length to be split along the W-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset from the start of the input tensor to the split position</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Y, and Z dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_split_s16_x">riscv_nn_split_s16_x</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_split_s16_x (const int16_t * in_tensor, const uint32_t in_tensor_x, const uint32_t in_tensor_y, const uint32_t in_tensor_z, const uint32_t in_tensor_w, int16_t * out_tensor, const uint32_t split_len_x, const uint32_t in_offset)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function splits a signed 16-bit integer input tensor along the X-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] split_len_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length to be split along the X-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset from the start of the input tensor to the split position</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same Y, Z, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_split_s16_y">riscv_nn_split_s16_y</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_split_s16_y (const int16_t * in_tensor, const uint32_t in_tensor_x, const uint32_t in_tensor_y, const uint32_t in_tensor_z, const uint32_t in_tensor_w, int16_t * out_tensor, const uint32_t split_len_y, const uint32_t in_offset)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function splits a signed 16-bit integer input tensor along the Y-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] split_len_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length to be split along the Y-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset from the start of the input tensor to the split position</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Z, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_split_s16_z">riscv_nn_split_s16_z</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_split_s16_z (const int16_t * in_tensor, const uint32_t in_tensor_x, const uint32_t in_tensor_y, const uint32_t in_tensor_z, const uint32_t in_tensor_w, int16_t * out_tensor, const uint32_t split_len_z, const uint32_t in_offset)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function splits a signed 16-bit integer input tensor along the Z-axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] split_len_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length to be split along the Z-axis</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset from the start of the input tensor to the split position</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The output tensor has the same X, Y, and W dimensions as the input tensor.</p>
</li>
<li>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_strided_slice_s8">riscv_nn_strided_slice_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_strided_slice_s8(const int8_t * in_tensor, const uint32_t in_tensor_w, const uint32_t in_tensor_z, const uint32_t in_tensor_y, const uint32_t in_tensor_x, const uint32_t begin_w, const uint32_t begin_z, const uint32_t begin_y, const uint32_t begin_x, const uint32_t end_w, const uint32_t end_z, const uint32_t end_y, const uint32_t end_x, const uint32_t stride_w, const uint32_t stride_z, const uint32_t stride_y, const uint32_t stride_x, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function copies a portion of a signed 8-bit integer input tensor along the W-, Z-, Y-, and X-axes.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the W dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the Z dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the W dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the Z dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride for slicing along the W dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride for slicing along the Z dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride for slicing along the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride for slicing along the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_strided_slice_s16">riscv_nn_strided_slice_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_strided_slice_s16(const int16_t * in_tensor, const uint32_t in_tensor_w, const uint32_t in_tensor_z, const uint32_t in_tensor_y, const uint32_t in_tensor_x, const uint32_t begin_w, const uint32_t begin_z, const uint32_t begin_y, const uint32_t begin_x, const uint32_t end_w, const uint32_t end_z, const uint32_t end_y, const uint32_t end_x, const uint32_t stride_w, const uint32_t stride_z, const uint32_t stride_y, const uint32_t stride_x, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function copies a portion of a signed 16-bit integer input tensor along the W-, Z-, Y-, and X-axes.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the W dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the Z dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] begin_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Start position for slicing along the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the W dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the Z dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] end_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">End position for slicing along the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride for slicing along the W dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride for slicing along the Z dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride for slicing along the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride for slicing along the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The input and output tensors are assumed to use the <code>WZYX</code> data layout.</p>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="section:function_convolution">Convolution Functions</h2>
<div class="sectionbody">
<div class="paragraph">
<p>These functions transform the input matrix into a column vector with <code>im2col</code>,
and then use matrix-matrix multiplication to get the convolution results.
There are three types of quantization on the convolution outputs:
shift-based quantization (named with <code>sft</code>),
symmetric quantization (named with <code>sym</code>),
and asymmetric quantization (named with <code>asym</code>).</p>
</div>
<div class="paragraph">
<p><a href="#figure:convolution_functions_shift-based_quantization">Convolution Functions With Shift-based Quantization</a>,
<a href="#figure:convolution_functions_symmetric_quantization">Convolution Functions With Symmetric Quantization</a>, and
<a href="#figure:convolution_functions_asymmetric_quantization">Convolution Functions With Asymmetric Quantization</a>
illustrate the algorithm flow of respective quantization types
where rectangles represent inputs or outputs, circles represent arithmetical operations,
solid lines are for required steps and dashed lines are for optional ones.</p>
</div>
<div id="figure:convolution_functions_shift-based_quantization" class="imageblock text-center">
<div class="content">
<img src="images/convolution_functions_shift-based_quantization.png" alt="convolution functions shift based quantization">
</div>
<div class="title">Figure 4. Convolution Functions With Shift-based Quantization</div>
</div>
<div id="figure:convolution_functions_symmetric_quantization" class="imageblock text-center">
<div class="content">
<img src="images/convolution_functions_symmetric_quantization.png" alt="convolution functions symmetric quantization">
</div>
<div class="title">Figure 5. Convolution Functions With Symmetric Quantization</div>
</div>
<div id="figure:convolution_functions_asymmetric_quantization" class="imageblock text-center">
<div class="content">
<img src="images/convolution_functions_asymmetric_quantization.png" alt="convolution functions asymmetric quantization">
</div>
<div class="title">Figure 6. Convolution Functions With Asymmetric Quantization</div>
</div>
<div class="paragraph">
<p>Note that in the convolution functions with asymmetric quantization,
the multiplication operation (<code>*1</code>) has an input that can either be
<code>ker_weight + ker_offset</code> or <code>ker_weight</code> depending on the presence of the parameter <code>ker_offset</code>.</p>
</div>
<div class="paragraph">
<p>Besides, the left-shift operation performs only when <code>out_shift</code> is positive and
the right-shift operation performs only when <code>out_shift</code> is negative.</p>
</div>
<div class="paragraph">
<p>The multiplication for <code>out_scale</code> can be roughly expressed as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>32b = ((int64_t)32b * 32b) &gt;&gt; 31</pre>
</div>
</div>
<div style="page-break-after: always;"></div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any">riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on signed 8-bit integer inputs and outputs across any X and Y dimensions,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be equal to <code>2 * in_tensor_ch * ker_dim_x * ker_dim_y</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform 1x1 convolution on a 160x120x20 input to
//produce a 160x120x8 output.
//Set padding for both dimensions to 0 and stride to 1.

#define IN_X           160
#define IN_Y           120
#define IN_CH          20
#define OUT_CH         8
#define KER_DIM_X      1
#define KER_DIM_Y      1
#define PAD_X          0
#define PAD_Y          0
#define STRIDE_X       1
#define STRIDE_Y       1
#define BIAS_LSHIFT    6    //Scale up the bias by 2^(6)
#define OUT_RSHIFT     9    //Scale down the output by 1/2^(9)
#define OUT_X          160
#define OUT_Y          120

q7_t in_data[IN_CH * IN_X * IN_Y] = {...};
q7_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};
q7_t bias[OUT_CH] = {...};
q15_t in_tmp_buf[2 * IN_CH * KER_DIM_X * KER_DIM_Y] = {0};
q7_t out_data[OUT_CH * OUT_X * OUT_Y];

riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any (in_data, IN_X, IN_Y, IN_CH, weight, OUT_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X, STRIDE_Y, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_X, OUT_Y, in_tmp_buf, NULL);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias (const q7_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs convolution on RGB images with signed 8-bit integers,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be equal to <code>2 * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform 5x5 convolution on a 28x28x3 input
//to produce a 24x24x20 output.
//Set padding for both dimensions to 0 and stride to 1.

#define IN_DIM         28
#define KER_DIM        5
#define PAD            0
#define STRIDE         1
#define BIAS_LSHIFT    6   //Scale up the bias by 2^(6)
#define OUT_RSHIFT     10  //Scale down the output by 1/2^(10)
#define OUT_CH         20
#define OUT_DIM        24

q7_t in_data[3 * IN_DIM * IN_DIM] = {...};
q7_t weight[3 * KER_DIM * KER_DIM * OUT_CH] = {...};
q7_t bias[OUT_CH] = {...};
q15_t in_tmp_buf[2 * 3 * KER_DIM * KER_DIM] = {0};
q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];

riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias (in_data, IN_DIM, weight, OUT_CH, KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_DIM,in_tmp_buf, NULL);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast (const q7_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q15_t * wt_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on RGB images with signed 8-bit integers,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform 5x5 convolution on a 28x28x3 input
//to produce a 24x24x20 output.
//Set padding for both dimensions to 0 and stride to 1.

#define IN_DIM         28
#define KER_DIM        5
#define PAD            0
#define STRIDE         1
#define BIAS_LSHIFT    6   //Scale up the bias by 2^(6)
#define OUT_RSHIFT     10  //Scale down the output by 1/2^(10)
#define OUT_CH         20
#define OUT_DIM        24

q7_t in_data[3 * IN_DIM * IN_DIM] = {...};
q7_t weight[3 * KER_DIM * KER_DIM * OUT_CH] = {...};
q7_t bias[OUT_CH] = {...};
q15_t in_tmp_buf[2 * (3 * KER_DIM * KER_DIM + 1)] = {0};
q15_t wt_tmp_buf[OUT_CH * (3 * KER_DIM * KER_DIM + 1)];
q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];

riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast (in_data, IN_DIM, weight, OUT_CH, KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_DIM, in_tmp_buf, wt_tmp_buf);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_sft_bias">riscv_nn_conv_HWC_s8_s8_s8_sft_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias (const q7_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs convolution on signed 8-bit integers,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be equal to <code>2 * in_tensor_ch * ker_dim * ker_dim</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform 5x5 convolution on a 28x28x1 input
//to produce a 24x24x20 output.
//Set padding for both dimensions to 0 and stride to 1.

#define IN_DIM         28
#define IN_CH          1
#define KER_DIM        5
#define PAD            0
#define STRIDE         1
#define BIAS_LSHIFT    6   //Scale up the bias by 2^(6)
#define OUT_RSHIFT     10  //Scale down the output by 1/2^(10)
#define OUT_CH         20
#define OUT_DIM        24

q7_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};
q7_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};
q7_t bias[OUT_CH] = {...};
q15_t in_tmp_buf[2 * IN_CH * KER_DIM * KER_DIM] = {0};
q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];

riscv_nn_conv_HWC_s8_s8_s8_sft_bias (in_data, IN_DIM, IN_CH, weight, OUT_CH, KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_DIM, in_tmp_buf, NULL);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs convolution on signed 8-bit integers across any X and Y dimensions,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be equal to <code>2 * in_tensor_ch * ker_dim_x * ker_dim_y</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform 3x5 convolution on a 160x120x3 input
//to produce a 80x59x5 output.
//Set padding for both dimensions to 1 and stride to 2.

#define IN_X           160
#define IN_Y           120
#define IN_CH          3
#define OUT_CH         5
#define KER_DIM_X      3
#define KER_DIM_Y      5
#define PAD_X          1
#define PAD_Y          1
#define STRIDE_X       2
#define STRIDE_Y       2
#define BIAS_LSHIFT    6   //Scale up the bias by 2^(6)
#define OUT_RSHIFT     9   //Scale down the output by 1/2^(9)
#define OUT_X          80
#define OUT_Y          59

q7_t in_data[IN_CH * IN_X * IN_Y] = {...};
q7_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};
q7_t bias[OUT_CH] = {...};
q15_t in_tmp_buf[2 * IN_CH * KER_DIM_X * KER_DIM_Y] = {0};
q7_t out_data[OUT_CH * OUT_X * OUT_Y];

riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any (in_data, IN_X, IN_Y , IN_CH, weight, OUT_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X, STRIDE_Y, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_X, OUT_Y, in_tmp_buf, NULL);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast (const q7_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 8-bit integers,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be equal to <code>2 * in_tensor_ch * ker_dim * ker_dim</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform 5x5 convolution on a 12x12x20 input
//to produce a 8x8x50 output.
//Set padding for both dimensions to 0 and stride to 1.

#define IN_DIM         12
#define IN_CH          20
#define KER_DIM        5
#define PAD            0
#define STRIDE         1
#define BIAS_LSHIFT    6   //Scale up the bias by 2^(6)
#define OUT_RSHIFT     10  //Scale down the output by 1/2^(10)
#define OUT_CH         50
#define OUT_DIM        8

q7_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};
q7_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};
q7_t bias[OUT_CH] = {...};
q15_t in_tmp_buf[2 * IN_CH * KER_DIM * KER_DIM] = {0};
q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];

riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast (in_data, IN_DIM, IN_CH, weight, OUT_CH, KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_DIM, in_tmp_buf, NULL);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 8-bit integers
across any X and Y dimensions, applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be equal to <code>2 * in_tensor_ch * ker_dim_x * ker_dim_y</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform 3x5 convolution on a 160x120x20 input
//to produce a 80x59x8 output.
//Set padding for both dimensions to 1 and stride to 2.

#define IN_X           160
#define IN_Y           120
#define IN_CH          20
#define OUT_CH         8
#define KER_DIM_X      3
#define KER_DIM_Y      5
#define PAD_X          1
#define PAD_Y          1
#define STRIDE_X       2
#define STRIDE_Y       2
#define BIAS_LSHIFT    6   //Scale up the bias by 2^(6)
#define OUT_RSHIFT     9   //Scale down the output by 1/2^(9)
#define OUT_X          80
#define OUT_Y          59

q7_t in_data[IN_CH * IN_X * IN_Y] = {...};
q7_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};
q7_t bias[OUT_CH] = {...};
q15_t in_tmp_buf[2 * IN_CH * KER_DIM_X * KER_DIM_Y] = {0};
q7_t out_data[OUT_CH * OUT_Y * OUT_X];

riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any (in_data, IN_W, IN_Y , IN_CH, weight, OUT_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X, STRIDE_Y, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_X, OUT_Y, in_tmp_buf, NULL);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s16_s16_s16_sft_bias">riscv_nn_conv_HWC_s16_s16_s16_sft_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s16_s16_s16_sft_bias (const q15_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q15_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q15_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs convolution on signed 16-bit integers,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be equal to <code>in_tensor_ch * ker_dim * ker_dim</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform 5x5 convolution on a 28x28x1 input
//to produce a 24x24x20 output.
//Set padding for both dimensions to 0 and stride to 1.

#define IN_DIM         28
#define IN_CH          1
#define KER_DIM        5
#define PAD            0
#define STRIDE         1
#define BIAS_LSHIFT    6   //Scale up the bias by 2^(6)
#define OUT_RSHIFT     10  //Scale down the output by 1/2^(10)
#define OUT_CH         20
#define OUT_DIM        24

q15_t input_data[IN_CH * IN_DIM * IN_DIM] = {...};
q15_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};
q15_t bias[OUT_CH] = {...};
q15_t in_tmp_buf[IN_CH * KER_DIM * KER_DIM] = {0};
q15_t out_data[OUT_CH * OUT_DIM * OUT_DIM];
riscv_nn_conv_HWC_s16_s16_s16_sft_bias (input_data, IN_DIM, IN_CH, weight, OUT_CH, KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_DIM, in_tmp_buf, NULL);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast (const q15_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q15_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q15_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 16-bit integers,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be equal to <code>2 * in_tensor_ch * ker_dim * ker_dim</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform 5x5 convolution on a 28x28x4 input
//to produce a 24x24x8 output.
//Set padding for both dimensions to 0 and stride to 1.

#define IN_DIM         28
#define IN_CH          4
#define KER_DIM        5
#define PAD            0
#define STRIDE         1
#define BIAS_LSHIFT    6
#define OUT_RSHIFT     10
#define OUT_CH         8
#define OUT_DIM        24

q15_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};
q15_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};
q15_t bias[OUT_CH] = {...};
q15_t in_tmp_buf[IN_CH * KER_DIM * KER_DIM] = {0};
q15_t out_data[OUT_CH * OUT_DIM * OUT_DIM];

riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast (in_data, IN_DIM, IN_CH, weight, OUT_CH, KER_DIM, PAD, STRIDE, bias, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_DIM, in_tmp_buf, NULL);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any (const q15_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q15_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q15_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 16-bit integers
across X and Y dimensions, applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be equal to <code>2 * in_tensor_ch * ker_dim_x * ker_dim_y</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constrain</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform 3x5 convolution on a 160x120x20 input
//to produce a 80x59x8 output tensor.
//Set padding for both dimensions to 1 and stride to 2.

#define IN_X           160
#define IN_Y           120
#define IN_CH          20
#define OUT_CH         8
#define KER_DIM_X      3
#define KER_DIM_Y      5
#define PAD_X          1
#define PAD_Y          1
#define STRIDE_X       2
#define STRIDE_Y       2
#define BIAS_LSHIFT    6   //Scale up the bias by 2^(6)
#define OUT_RSHIFT     9   //Scale down the output by 1/2^(9)
#define OUT_X          80
#define OUT_Y          59

q15_t in_data[IN_CH * IN_X * IN_Y] = {...};
q15_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};
q15_t bias[OUT_CH] = {...};
q15_t in_tmp_buf[2 * IN_CH * KER_DIM_X  * KER_DIM_Y] = {0};
q15_t out_data[OUT_CH * OUT_X * OUT_Y];</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias (const q7_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integers,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be equal to <code>(in_tensor_ch * ker_dim * ker_dim + 1) / 2</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform 3x3 convolution on a 11x11x28 input
//to produce a 9x9x48 output.
//Set padding for both dimensions to 0 and stride to 1.

#define IN_DIM        11
#define IN_CH         28
#define OUT_CH        48
#define KER_DIM       3
#define PAD           0
#define STRIDE        1
#define OUT_RSHIFT    7
#define OUT_DIM       9

q7_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};
q7_t weight[IN_CH * KER_DIM * KER_DIM] = {...};
q7_t bias[IN_CH] = {...};
q15_t in_tmp_buf[2 * OUT_CH * KER_DIM * KER_DIM] = {0};
q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];

riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias (in_data, IN_DIM, IN_CH, weight, OUT_CH, KER_DIM, PAD, STRIDE, bias, 0, OUT_RSHIFT, out_data, OUT_DIM, in_tmp_buf, NULL);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t * bias, const uint16_t bias_lshift, const uint16_t out_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integers
across any X and Y dimensions, applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be equal to <code>(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">//Perform a depthwise 3x3 convolution on a 79x59x12 input
//to produce a 77x57x12 output.
//Set padding for both dimensions to 0 and stride to 1.

#define IN_DIM_X      79
#define IN_DIM_Y      59
#define IN_CH         12
#define OUT_CH        12
#define KER_DIM       3
#define PAD           0
#define STRIDE        1
#define BIAS_SHIFT    0
#define OUT_RSHIFT    7
#define OUT_DIM_X     77
#define OUT_DIM_Y     57

q7_t in_data[IN_CH * IN_DIM_X * IN_DIM_Y] = {...};
q7_t weight[IN_CH * KER_DIM * KER_DIM] = {...};
q7_t bias[IN_CH] = {...};
q15_t in_tmp_buf[2 * OUT_CH * KER_DIM * KER_DIM] = {0};
q7_t out_data[OUT_CH * OUT_DIM_X * OUT_DIM_Y];

riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any (in_data, IN_DIM_X, IN_DIM_Y, IN_CH, weight, OUT_CH, KER_DIM, KER_DIM, PAD, PAD, STRIDE, STRIDE, bias, BIAS_SHIFT, OUT_RSHIFT, out_data, OUT_DIM_X, OUT_DIM_Y, in_tmp_buf, NULL);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any">riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on signed 8-bit integer inputs and outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any">riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on signed 8-bit integer inputs and
signed 16-bit integer outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any">riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift,   u8_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on unsigned 8-bit integer inputs and outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any">riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on unsigned 8-bit integer inputs and
signed 8-bit integer outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any">riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on unsigned 8-bit integer inputs and
signed 16-bit integer outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any">riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on signed 8-bit integer inputs and outputs
across any X and Y dimensions, applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any">riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on signed 8-bit integer inputs and
signed 16-bit integer outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any">riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on unsigned 8-bit integer inputs and outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any">riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on unsigned 8-bit integer inputs and
signed 8-bit integer outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any">riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on unsigned 8-bit integer inputs and
signed 16-bit integer outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_sym_get_buffer_size">riscv_nn_conv_1x1_sym_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">uint32_t riscv_nn_conv_1x1_sym_get_buffer_size (const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
convolution functions that use symmetric quantization with a 1x1 kernel.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast">riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast (const q7_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q15_t * wt_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on RGB images with signed 8-bit integer inputs and outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast">riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast (const q7_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q15_t * wt_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on RGB images with signed 8-bit integers inputs and signed 16-bit integer outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast">riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q15_t * wt_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on RGB images with unsigned 8-bit integers
for both inputs and outputs, applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast">riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q15_t * wt_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on RGB images with unsigned 8-bit integers
for inputs and signed 8-bit integers for outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast">riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q15_t * wt_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on RGB images with unsigned 8-bit integers
for inputs and signed 16-bit integers for outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_fast">riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_RGB_sym_fast (const q7_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q15_t * wt_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on RGB images with signed 8-bit integer inputs and outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_fast">riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s16_s8_RGB_sym_fast (const q7_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q15_t * wt_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on RGB images with signed 8-bit integer inputs and signed 16-bit integer outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> enabled.<br>
                         The required size must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_fast">riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_u8_s8_RGB_sym_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q15_t * wt_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on RGB images with unsigned 8-bit integer
for both inputs and outputs, applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_fast">riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s8_s8_RGB_sym_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q15_t * wt_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on RGB images with unsigned 8-bit integers
for inputs and signed 8-bit integers for outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_fast">riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s16_s8_RGB_sym_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf, q15_t * wt_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on RGB images with unsigned 8-bit integers
for inputs and signed 16-bit integers for outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for kernel weights.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required must be <code>out_tensor_ch * (3 * ker_dim * ker_dim + 1)</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast (const q7_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 8-bit integer inputs and outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast">riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast (const q7_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 8-bit integer inputs and signed 16-bit integer outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast">riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for both inputs and outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast">riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for inputs and signed 8-bit integers for outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast">riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for inputs and signed 16-bit integers for outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_sym_fast">riscv_nn_conv_HWC_s8_s8_s8_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_sym_fast (const q7_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 8-bit integer inputs and outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s16_s8_sym_fast">riscv_nn_conv_HWC_s8_s16_s8_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s16_s8_sym_fast (const q7_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 8-bit integer inputs and signed 16-bit integer outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_u8_s8_sym_fast">riscv_nn_conv_HWC_u8_u8_s8_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_u8_s8_sym_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for both inputs and outputs, applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s8_s8_sym_fast">riscv_nn_conv_HWC_u8_s8_s8_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s8_s8_sym_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for inputs and signed 8-bit integers for outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s16_s8_sym_fast">riscv_nn_conv_HWC_u8_s16_s8_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s16_s8_sym_fast (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for inputs and signed 16-bit integers for outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 8-bit integer inputs and outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any">riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 8-bit integer inputs and signed 16-bit integer outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any">riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift,   u8_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for both inputs and outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any">riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for inputs and signed 8-bit integers for outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any">riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for inputs and signed 16-bit integers for outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_sym_fast_any">riscv_nn_conv_HWC_s8_s8_s8_sym_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_sym_fast_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 8-bit integer inputs and outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s16_s8_sym_fast_any">riscv_nn_conv_HWC_s8_s16_s8_sym_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s16_s8_sym_fast_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution on signed 8-bit integer inputs and signed 16-bit integer outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_u8_s8_sym_fast_any">riscv_nn_conv_HWC_u8_u8_s8_sym_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_u8_s8_sym_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for both inputs and outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s8_s8_sym_fast_any">riscv_nn_conv_HWC_u8_s8_s8_sym_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s8_s8_sym_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for inputs and signed 8-bit integers for outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_u8_s16_s8_sym_fast_any">riscv_nn_conv_HWC_u8_s16_s8_sym_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_u8_s16_s8_sym_fast_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs fast convolution with unsigned 8-bit integers
for inputs and signed 16-bit integers for outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_sym_bias_any">riscv_nn_conv_HWC_s8_s8_s8_sym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_conv_HWC_s8_s8_s8_sym_bias_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf, q7_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs convolution on signed 8-bit integer inputs and outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_sym_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_sym_get_buffer_size">riscv_nn_conv_sym_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">uint32_t riscv_nn_conv_sym_get_buffer_size (const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
convolution functions that use symmetric quantization with any kernel sizes.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias (const q7_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integer inputs and outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim * ker_dim + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias (const q7_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integer inputs and signed 16-bit integer outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim * ker_dim + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for both inputs and outputs, incorporating bias inputs and
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim * ker_dim + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for inputs and signed 8-bit integers for outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim * ker_dim + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for inputs and signed 16-bit integers for outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim * ker_dim + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s8_s8_sym">riscv_nn_conv_dw_HWC_s8_s8_s8_sym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sym (const q7_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integer inputs and outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim * ker_dim + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s16_s8_sym">riscv_nn_conv_dw_HWC_s8_s16_s8_sym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s16_s8_sym (const q7_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integer inputs and signed 16-bit integer outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim * ker_dim + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_u8_s8_sym">riscv_nn_conv_dw_HWC_u8_u8_s8_sym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_u8_s8_sym (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for both inputs and outputs, applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim * ker_dim + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_s8_s8_sym">riscv_nn_conv_dw_HWC_u8_s8_s8_sym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_s8_s8_sym (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for inputs and signed 8-bit integers for outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim * ker_dim + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_s16_s8_sym">riscv_nn_conv_dw_HWC_u8_s16_s8_sym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_s16_s8_sym (const u8_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for inputs and signed 16-bit integers for outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim * ker_dim + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integer inputs and outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integer inputs and signed 16-bit integer outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift,   u8_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for both inputs and outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for inputs and signed 8-bit integers for outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for inputs and signed 16-bit integers for outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s8_s8_sym_any">riscv_nn_conv_dw_HWC_s8_s8_s8_sym_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_sym_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integer inputs and outputs across any X and Y dimensions,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s16_s8_sym_any">riscv_nn_conv_dw_HWC_s8_s16_s8_sym_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s16_s8_sym_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integer inputs and signed 16-bit integer outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_u8_s8_sym_any">riscv_nn_conv_dw_HWC_u8_u8_s8_sym_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_u8_s8_sym_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for both inputs and outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_s8_s8_sym_any">riscv_nn_conv_dw_HWC_u8_s8_s8_sym_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_s8_s8_sym_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for inputs and signed 8-bit integers for outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_s16_s8_sym_any">riscv_nn_conv_dw_HWC_u8_s16_s8_sym_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_s16_s8_sym_any (const u8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution with unsigned 8-bit integers
for inputs and signed 16-bit integers for outputs across any X and Y dimensions,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The buffer length must be at least <code>(in_tensor_ch * ker_dim_x * ker_dim_y + 1) / 2</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any">riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any (const int8_t * in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int8_t * ker_weight, const int32_t out_tensor_ch, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, int8_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on signed 8-bit integer inputs and outputs,
using signed 4-bit integer kernel weights across any X and Y dimensions,
and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_fast_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal 0</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any_get_buffer_size">riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_any_get_buffer_size (const int32_t in_tensor_ch, const int32_t out_tensor_ch);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_fast_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any">riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any (const int8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const int8_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, int16_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on signed 8-bit integer inputs, outputs,
and kernel weights across any X and Y dimensions,
applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal 0</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size">riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size (const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t out_tensor_ch, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any">riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any (const int8_t * in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int8_t * ker_weight, const int32_t out_tensor_ch, const int32_t ker_dim_x, const int32_t pad_x, const int32_t stride_x, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_dim_x, const int32_t dilation_x, int8_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1xN convolution on signed 8-bit integer inputs and outputs,
using signed 4-bit integer kernel weights across any X and Y dimensions,
and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any_get_buffer_size">riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any_get_buffer_size (const int32_t in_tensor_dim_x, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int32_t out_tensor_ch, const int32_t ker_dim_x, const int32_t pad_x, const int32_t stride_x, const int32_t out_tensor_dim_x, const int32_t dilation_x)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any">riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any (const int8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const int8_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t pad_x, const uint16_t stride_x, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, int16_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1xN convolution on signed 8-bit integer inputs, outputs,
and kernel weights across any X dimensions, applying asymmetric
quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size (const uint16_t in_tensor_dim_x, const uint16_t in_tensor_ch, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t pad_x, const uint16_t stride_x, const uint16_t out_tensor_dim_x);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1xn_HWC_s16_s16_s8_asym_bias_any">riscv_nn_conv_1xn_HWC_s16_s16_s8_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1xn_HWC_s16_s16_s8_asym_bias_any (const int16_t * in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int8_t * ker_weight, const int32_t ker_dim_x, const int32_t pad_x, const int32_t stride_x, const int64_t * bias, int16_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_ch, const int32_t out_tensor_dim_x, const int32_t dilation_x, int16_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1xN convolution on signed 16-bit integer inputs and outputs,
using signed 8-bit integer kernel weights across any X and Y dimensions,
and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any">riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any (const int8_t * in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int8_t * ker_weight, const int32_t out_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t dilation_x, const int32_t dilation_y, int8_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs convolution on signed 8-bit integer inputs and outputs,
using signed 4-bit integer kernel weights across any X and Y dimensions,
and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any_get_buffer_size">riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any_get_buffer_size (const int32_t in_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t out_tensor_ch)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any (const int8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const int8_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, int16_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs convolution on signed 8-bit integer inputs, outputs,
and kernel weights across any X and Y dimensions, applying asymmetric
quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_HWC_s8_s8_s8_asym_ bias_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size (const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated (const int8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const int8_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t ker_ch, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t dilation_x, const int32_t dilation_y, int16_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs dilated convolution on signed 8-bit integer inputs,
outputs, and kernel weights across any X and Y dimensions, applying
asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of kernel weight channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated_get_buffer_size">riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated_get_buffer_size (const uint16_t ker_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t out_tensor_ch)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of kernel weight channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any(const int16_t * in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int8_t * ker_weight, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const void * bias, const bool is_32b_bias, int16_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_ch, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t dilation_x, const int32_t dilation_y, int16_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs convolution on signed 16-bit integer inputs and outputs,
using signed 8-bit integer kernel weights across any X and Y dimensions,
and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] is_32b_bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Flag indicating whether the bias vector is 32-bit</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any_get_buffer_size (const int32_t in_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any (const int16_t * in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int8_t * ker_weight, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int64_t * bias, int16_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_ch, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, int16_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs convolution on signed 16-bit integer inputs and outputs,
using signed 8-bit integer kernel weights across any X and Y dimensions,
and applies asymmetric quantization to the outputs.</p>
<div class="paragraph">
<p>Compared to <code>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any</code>, this function uses a
faster algorithm but imposes more constraints on the input parameters.</p>
</div>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<div class="ulist">
<ul>
<li>
<p>The product of <code>(in_tensor_ch * ker_dim_x * ker_dim_y)</code> must be less than or equal to 512.</p>
</li>
</ul>
</div>
</li>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any_get_buffer_size">riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any_get_buffer_size (const int32_t in_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym">riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym (const int8_t * in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int8_t * ker_weight, const int32_t out_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t dilation_x, const int32_t dilation_y, int8_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This is a wrapper function for <code>riscv_nn_conv_1x1_HWC_s8_s8_s4_asym_bias_fast_any</code>,
<code>riscv_nn_conv_1xn_HWC_s8_s8_s4_asym_bias_any</code> and <code>riscv_nn_conv_HWC_s8_s8_s4_asym_bias_any</code>.
This function calls one among the three convolution functions according to the
provided parameters.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym_get_buffer_size">riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym_get_buffer_size (const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t out_tensor_ch, const int32_t dilation_x, const int32_t dilation_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_HWC_wrapper_s8_s8_s4_asym</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym">riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym (const int8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const int8_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t ker_ch, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t dilation_x, const int32_t dilation_y, int16_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This is a wrapper function for <code>riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any</code>,
<code>riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any</code>, and <code>riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_dilated</code>.
This function calls one among the three convolution functions according to the provided parameters.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym_get_buffer_size">riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym_get_buffer_size (const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t ker_ch, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const uint16_t out_tensor_ch, const int32_t dilation_x, const int32_t dilation_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_HWC_wrapper_s8_s8_s8_asym</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  ker_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of kernel weight channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in]  dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym">riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym (const int16_t * in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int8_t * ker_weight, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const void * bias, const bool is_32b_bias, int16_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_ch, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t dilation_x, const int32_t dilation_y, int16_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This is a wrapper function for <code>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_any</code> and
<code>riscv_nn_conv_HWC_s16_s16_s8_asym_bias_fast_any</code>.
This function calls one of the two convolution functions according to the provided parameters.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym_get_buffer_size">riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym_get_buffer_size (const int32_t in_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t dilation_x, const int32_t dilation_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_HWC_wrapper_s16_s16_s8_asym</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any">riscv_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any (const int8_t * in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int8_t * ker_weight, const int32_t out_tensor_ch, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t dilation_x, const int32_t dilation_y, int16_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise 3x3 convolution on signed 8-bit integer inputs,
outputs, and kernel weights across any X and Y dimensions,
applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to <code>out_tensor_ch</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be less than or equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any">riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any (const int8_t * in_tensor, const int32_t in_tensor_batch, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int8_t * ker_weight, const int32_t out_tensor_ch, const int32_t ch_mult, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t dilation_x, const int32_t dilation_y, int8_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integer inputs and outputs,
using signed 4-bit integer kernel weights across any X and Y dimensions,
and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ch_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplier of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any_get_buffer_size">riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any_get_buffer_size (const int32_t in_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t ch_mult)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_dw_HWC_s8_s8_s4_asym_bias_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ch_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplier of input tensor channels</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any (const int8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const int8_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ch_mult, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t dilation_x, const uint16_t dilation_y, int16_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integer inputs,
outputs, and kernel weights across any X and Y dimensions, applying
asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels. <code>out_tensor_ch</code> is equal to <code>ch_mult * in_tensor_ch</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ch_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplier of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Value of offset for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Value of offset for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any (const int8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const int8_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t dilation_x, const uint16_t dilation_y, int16_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 8-bit integer inputs,
outputs, and kernel weights across any X and Y dimensions, applying
asymmetric quantization to the outputs.</p>
<div class="paragraph">
<p>Compared to <code>riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any</code>, this function uses a
faster algorithm but imposes more constraints on the input parameters.</p>
</div>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size">riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size (const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_dw_HWC_s8_fast_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any">riscv_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any (const uint8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint8_t * ker_weight, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const int16_t ch_mult, const int16_t pad_x, const int16_t pad_y, const int16_t stride_x, const int16_t stride_y, const int16_t dilation_x, const int16_t dilation_y, const int32_t * bias, const int32_t in_offset, const int32_t ker_offset, const int32_t out_offset, uint8_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t act_min, const int32_t act_max, const int32_t out_shift, const int32_t out_scale)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on unsigned 8-bit integer inputs,
outputs, and kernel weights across any X and Y dimensions, applying
asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ch_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplier of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-255, 0].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the filter kernel. It should be in the range [-255, 0].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [0, 255].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [0, 255].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [0, 255].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling value for the quantization on outputs</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ch_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_s16_s16_s8_asym_bias_any">riscv_nn_conv_dw_HWC_s16_s16_s8_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_s16_s16_s8_asym_bias_any (const int16_t * in_tensor, const uint16_t in_tensor_batch, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const int8_t * ker_weight, const uint16_t ch_mult, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int64_t * bias, int16_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t dilation_x, const uint16_t dilation_y, int16_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on signed 16-bit integer inputs and outputs,
using signed 8-bit integer kernel weights across any X and Y dimensions,
and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor batches</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ch_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplier of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym">riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym (const int8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const int8_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ch_mult, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t dilation_x, const uint16_t dilation_y, int16_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This is a wrapper function for <code>riscv_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any</code>,
<code>riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any</code>,
and <code>riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any</code>.
This function calls one among the three depthwise convolution functions according to the provided parameters.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels. <code>out_tensor_ch</code> is equal to <code>ch_mult * in_tensor_ch</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ch_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplier of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dilation_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dilation factor for the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                         Required when <code>-mext-dsp</code> or <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Input constraints:</p>
<div class="paragraph">
<p>When <code>ch_mult == 1</code>, <code>ker_dim_x == 3</code>, <code>ker_dim_y == 3</code>, <code>pad_x &#8656; 2</code>,
<code>dilation_x == 1</code>, and <code>dilation_y == 1</code>:</p>
</div>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to <code>out_tensor_ch</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be less than or equal to 1</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym_get_buffer_size">riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym_get_buffer_size (const uint16_t in_tensor_ch, const uint16_t ch_mult, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_dw_HWC_wrapper_s8_s8_s8_asym</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ch_mult</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplier of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any">riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any (const q7_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const q7_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t pad_offset_x, const uint16_t pad_offset_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t * bias, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, int8_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs transposed convolution on signed 8-bit integer inputs,
outputs, and kernel weights across any X and Y dimensions,
and applies symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_offset_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_offset_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Value of scaling for the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for calculations.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any_get_buffer_size">riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any_get_buffer_size (const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_trans_HWC_s8_s8_s8_sym_bias_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch Size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any">riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any (const int16_t * in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int8_t * ker_weight, const int32_t out_tensor_ch, const int32_t ker_dim_x, const int32_t pad_x, const int32_t stride_x, const int64_t * bias, int16_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_dim_x, int8_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs transposed 1xN convolution on signed 16-bit integer inputs and outputs,
using signed 8-bit kernel weights across any X and Y dimensions,
and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">uint32_t riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any_get_buffer_size (const uint32_t in_tensor_dim_x, const uint32_t in_tensor_ch, const uint32_t in_tensor_batch, const uint32_t out_tensor_ch, const uint32_t ker_dim_x, const uint32_t pad_x, const uint32_t stride_x, const uint32_t out_tensor_dim_x)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_trans_1xn_HWC_s16_s16_s8_asym_bias_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any">riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any (const int8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const int8_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t pad_offset_x, const uint16_t pad_offset_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t * bias, int8_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, int8_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs transposed convolution on signed 8-bit integer inputs,
outputs, and kernel weights across any X and Y dimensions,
applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_offset_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_offset_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any_get_buffer_size (const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_batch, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_trans_HWC_s8_s8_s8_asym_bias_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any">riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any (const int16_t * in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int8_t * ker_weight, const int32_t out_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t pad_offset_x, const int32_t pad_offset_y, const int32_t stride_x, const int32_t stride_y, const int64_t * bias, int16_t * out_tensor, const int32_t * out_shift, const int32_t * out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, int8_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs transposed convolution on signed 16-bit integer inputs and outputs,
using signed 8-bit kernel weights across any X and Y dimensions,
and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_offset_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_offset_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the shift vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for the quantization on outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any_get_buffer_size">riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">uint32_t riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any_get_buffer_size (const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int32_t in_tensor_batch, const int32_t out_tensor_ch, const int32_t ker_dim_x, const int32_t ker_dim_y, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_conv_trans_HWC_s16_s16_s8_asym_bias_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any">riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any (const float16_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const float16_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const float16_t * bias, float16_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, float16_t * in_tmp_buf, float16_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs 1x1 convolution on half-precision floating-point inputs,
outputs, and kernel weights across any X and Y dimensions.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size can be obtained by calling <code>riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any_get_buffer_size</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be a multiple of 2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be equal to 1</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any_get_buffer_size">riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any_get_buffer_size (const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer length for
<code>riscv_nn_conv_1x1_HWC_f16_f16_f16_bias_any</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer length</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_f16_f16_f16_bias">riscv_nn_conv_HWC_f16_f16_f16_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_f16_f16_f16_bias (const float16_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const float16_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const float16_t * bias, float16_t * out_tensor, const uint16_t out_tensor_dim, float16_t * in_tmp_buf, float16_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs convolution on half-precision floating-point inputs,
outputs, and kernel weights over square spatial dimensions.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         The required size can be obtained by calling  <code>riscv_nn_conv_HWC_f16_f16_f16_bias_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_HWC_f16_f16_f16_bias_get_buffer_size">riscv_nn_conv_HWC_f16_f16_f16_bias_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_HWC_f16_f16_f16_bias_get_buffer_size (const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t out_tensor_dim)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer length for
<code>riscv_nn_conv_HWC_f16_f16_f16_bias</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer length</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_f16_f16_f16_bias">riscv_nn_conv_dw_HWC_f16_f16_f16_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_f16_f16_f16_bias (const float16_t * in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const float16_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const float16_t * bias, float16_t * out_tensor, const uint16_t out_tensor_dim, float16_t * in_tmp_buf, float16_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on half-precision floating-point
inputs, outputs, and kernel weights over square spatial dimensions.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for internal calculations.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The buffer length must be at least <code>in_tensor_ch * ker_dim * ker_dim</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_conv_dw_HWC_f32_f32_f32_bias_any">riscv_nn_conv_dw_HWC_f32_f32_f32_bias_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_conv_dw_HWC_f32_f32_f32_bias_any (float32_t * in_tensor, const uint16_t in_tensor_batch, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const float32_t * ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const float32_t * bias, float32_t * out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, float32_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs depthwise convolution on single-precision floating-point
inputs, outputs, and kernel weights across any X and Y dimensions.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer of kernel weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of output tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the filter kernel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Convolution stride in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the constraints described in <strong>Note</strong></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Input constraints:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Constraint</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">must equal <code>out_tensor_ch</code></p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="section:function_fully_connected">Fully-Connected Layer Functions</h2>
<div class="sectionbody">
<div class="paragraph">
<p>These functions multiply the input vector by a weight matrix and add a bias, if any, to the results.</p>
</div>
<div class="paragraph">
<p>Supported inputs include 8-bit and 16-bit integers, as well as half-precision
floating-point values. For integer inputs, the supported quantization types are
shift-based, symmetric, and asymmetric.</p>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_batch_matmul_s8_s8_s8">riscv_nn_batch_matmul_s8_s8_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_batch_matmul_s8_s8_s8 (const int8_t * in_lhs, const int8_t * in_rhs, const int16_t lhs_offset, const int16_t rhs_offset, const int32_t * bias, int8_t * dst, const int16_t out_offset, const int32_t out_scale, const int32_t out_shift, const int32_t lhs_dim_n, const int32_t lhs_dim_h, const int32_t lhs_dim_w, const int32_t rhs_dim_n, const int32_t rhs_dim_h, const int32_t rhs_dim_w, const int32_t rhs_dim_c, const int32_t out_dim_n, const int32_t out_dim_h, const int32_t act_min, const int32_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs batch matrix multiplication on signed 8-bit integer inputs and outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_lhs</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the left-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rhs</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the right-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lhs_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the left-hand side inputs. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rhs_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the right-hand side inputs. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dst</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lhs_dim_n</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N dimension of the left-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lhs_dim_h</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">H dimension of the left-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lhs_dim_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the left-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rhs_dim_n</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N dimension of the right-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rhs_dim_h</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">H dimension of the right-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rhs_dim_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the right-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rhs_dim_c</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">C dimension of the right-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_dim_n</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_dim_h</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">H dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in in the range [-128, 127].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_batch_matmul_s16_s16_s16">riscv_nn_batch_matmul_s16_s16_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_batch_matmul_s16_s16_s16 (const int16_t * in_lhs, const int16_t * in_rhs, const int16_t lhs_offset, const int16_t rhs_offset, const int64_t * bias, int16_t * dst, const int16_t out_offset, const int32_t out_scale, const int32_t out_shift, const int32_t lhs_dim_n, const int32_t lhs_dim_h, const int32_t lhs_dim_w, const int32_t rhs_dim_n, const int32_t rhs_dim_h, const int32_t rhs_dim_w, const int32_t rhs_dim_c, const int32_t dst_dim_n, const int32_t dst_dim_h, const int32_t act_min, const int32_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs batch matrix multiplication on signed 16-bit integer inputs and outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_lhs</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the left-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_rhs</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the right-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lhs_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rhs_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] dst</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lhs_dim_n</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N dimension of the left-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lhs_dim_h</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">H dimension of the left-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lhs_dim_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the left-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rhs_dim_n</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N dimension of the right-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rhs_dim_h</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">H dimension of the right-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rhs_dim_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the right-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rhs_dim_c</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">C dimension of the right-hand side input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_dim_n</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_dim_h</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">H dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in in the range [-32768, 32767].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s8_s8_sft_bias">riscv_nn_fc_s8_s8_s8_sft_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s8_s8_sft_bias (const q7_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t bias_lshift, const uint16_t out_rshift, const q7_t * bias, q7_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on signed 8-bit integers for inputs,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">#define IN_SIZE        2048
#define OUT_SIZE       256
#define BIAS_LSHIFT    9     //Scale up the bias by 2^9
#define OUT_RSHIFT     9     //Scale down the output by 1/2^9

q7_t in_vec[IN_SIZE] = {...};;
q7_t wt_mat[IN_SIZE * OUT_SIZE] {...};
q7_t bias[OUT_SIZE] = {...};
q7_t out_vec[OUT_SIZE];

riscv_nn_fc_s8_s8_s8_sft_bias (in_vec, wt_mat, IN_SIZE, OUT_SIZE, BIAS_LSHIFT, OUT_RSHIFT, bias, out_vec, NULL);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s8_s8_sft_bias_fast">riscv_nn_fc_s8_s8_s8_sft_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s8_s8_sft_bias_fast (const q7_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t bias_lshift, const uint16_t out_rshift, const q7_t * bias, q7_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs interleaved multiplication on signed 8-bit integers for inputs,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s8_wt_converter</code>.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s16_s16_s16_sft_bias">riscv_nn_fc_s16_s16_s16_sft_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s16_s16_s16_sft_bias (const q15_t * in_vec, const q15_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t bias_lshift, const uint16_t out_rshift, const q15_t * bias, q15_t * out_vec, q15_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on signed 16-bit integers for inputs,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s16_s16_s16_sft_bias_fast">riscv_nn_fc_s16_s16_s16_sft_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s16_s16_s16_sft_bias_fast (const q15_t * in_vec, const q15_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t bias_lshift, const uint16_t out_rshift, const q15_t * bias, q15_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs interleaved multiplication on signed 16-bit integers for inputs,
applying shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>4 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s16_wt_converter</code>.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias">riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias (const q15_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t bias_lshift, const uint16_t out_rshift, const q7_t * bias, q15_t * out_vec, q15_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function multiplies a signed 16-bit integer input vector
by a signed 8-bit integer weight matrix,
and applies shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias_fast">riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias_fast (const q15_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t bias_lshift, const uint16_t out_rshift, const q7_t * bias, q15_t * out_vec, q15_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function multiplies a signed 16-bit integer input vector
by a signed 8-bit integer weight matrix in interleaved format,
then applies shift-based quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_mat_vec_s8_wt_converter</code>.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s8_s8_sym_bias">riscv_nn_fc_s8_s8_s8_sym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s8_s8_sym_bias (const q7_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, const q31_t * bias, q7_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on signed 8-bit integer inputs and outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The required size must be <code>size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s16_s8_sym_bias">riscv_nn_fc_s8_s16_s8_sym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s16_s8_sym_bias (const q7_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, const q31_t * bias, q15_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on signed 8-bit integer inputs and signed 16-bit integer outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The required size must be <code>size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_u8_s8_sym_bias">riscv_nn_fc_u8_u8_s8_sym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_u8_s8_sym_bias (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, const q31_t * bias, u8_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on unsigned 8-bit integer inputs and outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The required size must be <code>size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_s8_s8_sym_bias">riscv_nn_fc_u8_s8_s8_sym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_s8_s8_sym_bias (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, const q31_t * bias, q7_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on unsigned 8-bit integer inputs and signed 8-bit integer outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The required size must be <code>size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_s16_s8_sym_bias">riscv_nn_fc_u8_s16_s8_sym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_s16_s8_sym_bias (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, const q31_t * bias, q15_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on unsigned 8-bit integer inputs and signed 16-bit integer outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The required size must be <code>size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s8_s8_sym">riscv_nn_fc_s8_s8_s8_sym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s8_s8_sym (const q7_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on signed 8-bit integer inputs and outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The required size must be <code>size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s16_s8_sym">riscv_nn_fc_s8_s16_s8_sym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s16_s8_sym (const q7_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on signed 8-bit integer inputs and signed 16-bit integer outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The required size must be <code>size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_u8_s8_sym">riscv_nn_fc_u8_u8_s8_sym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_u8_s8_sym (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on unsigned 8-bit integer inputs and outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The required size must be <code>size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_s8_s8_sym">riscv_nn_fc_u8_s8_s8_sym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_s8_s8_sym (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on unsigned 8-bit integer inputs and signed 8-bit integer outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The required size must be <code>size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_s16_s8_sym">riscv_nn_fc_u8_s16_s8_sym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_s16_s8_sym (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_vec, q15_t * in_tmp_buf);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on unsigned 8-bit integer inputs and signed 16-bit integer outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-dsp</code> is enabled.<br>
                         The required size must be <code>size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s8_s8_sym_bias_fast">riscv_nn_fc_s8_s8_s8_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s8_s8_sym_bias_fast (const q7_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, const q31_t * bias, q7_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs interleaved multiplication on signed 8-bit integer inputs and outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s8_wt_converter</code>.</p>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s16_s8_sym_bias_fast">riscv_nn_fc_s8_s16_s8_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s16_s8_sym_bias_fast (const q7_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, const q31_t * bias, q15_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs interleaved multiplication on signed 8-bit integer inputs and signed 16-bit integer outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s8_wt_converter</code>.</p>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_u8_s8_sym_bias_fast">riscv_nn_fc_u8_u8_s8_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_u8_s8_sym_bias_fast (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, const q31_t * bias, u8_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs interleaved multiplication on unsigned 8-bit integer inputs and outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s8_wt_converter</code>.</p>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_s8_s8_sym_bias_fast">riscv_nn_fc_u8_s8_s8_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_s8_s8_sym_bias_fast (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, const q31_t * bias, q7_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs interleaved multiplication on unsigned 8-bit integer inputs and signed 8-bit integer outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s8_wt_converter</code>.</p>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_s16_s8_sym_bias_fast">riscv_nn_fc_u8_s16_s8_sym_bias_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_s16_s8_sym_bias_fast (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, const q31_t * bias, q15_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This performs interleaved multiplication on unsigned 8-bit integer inputs and signed 16-bit integer outputs,
incorporating bias inputs and applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s8_wt_converter</code>.</p>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s8_s8_sym_fast">riscv_nn_fc_s8_s8_s8_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s8_s8_sym_fast (const q7_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs interleaved multiplication on signed 8-bit integer inputs and outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s8_wt_converter</code>.</p>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s16_s8_sym_fast">riscv_nn_fc_s8_s16_s8_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s16_s8_sym_fast (const q7_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs interleaved multiplication on signed 8-bit integer inputs and signed 16-bit integer outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s8_wt_converter</code>.</p>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_u8_s8_sym_fast">riscv_nn_fc_u8_u8_s8_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_u8_s8_sym_fast (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs interleaved multiplication on unsigned 8-bit integer inputs and outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s8_wt_converter</code>.</p>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_s8_s8_sym_fast">riscv_nn_fc_u8_s8_s8_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_s8_s8_sym_fast (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs interleaved multiplication on unsigned 8-bit integer inputs and signed 8-bit integer outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s8_wt_converter</code>.</p>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_u8_s16_s8_sym_fast">riscv_nn_fc_u8_s16_s8_sym_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_u8_s16_s8_sym_fast (const u8_t * in_vec, const q7_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t * out_vec, q15_t * in_tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs interleaved multiplication on unsigned 8-bit integer inputs and signed 16-bit integer outputs,
applying symmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pre_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output before scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] post_rshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-shift amount applied to the output after scaling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input vector.<br>
                         Required when <code>-mext-vector</code> is enabled.<br>
                         The required size must be <code>2 * size</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The input vector is multiplied by a weight matrix,
which is in interleaved format and obtained from <code>riscv_nn_fc_s8_wt_converter</code>.</p>
</li>
<li>
<p>The function shifts the outputs in two stages before storing them. For example:</p>
<div class="listingblock">
<div class="content">
<pre>out = ((out &gt;&gt; pre_rshift) * out_scale) &gt;&gt; post_rshift</pre>
</div>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_wt_converter">riscv_nn_fc_s8_wt_converter</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_fc_s8_wt_converter (const q7_t * wt_mat, const uint32_t size, const uint32_t wt_row_num, q7_t * wt_mat_out)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This is a weight converter for fully-connected layer functions that
use signed 8-bit weight data and have a <code>_fast</code> suffix in their names.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] wt_mat_out</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix stored in a specific order</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s16_wt_converter">riscv_nn_fc_s16_wt_converter</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_fc_s16_wt_converter (const q15_t * wt_mat, const uint32_t size, const uint32_t wt_row_num, q15_t * wt_mat_out)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This is a weight converter for fully-connected layer functions that
use signed 16-bit weight data and have a <code>_fast</code> suffix in their names.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] wt_mat_out</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix stored in a specific order</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_mat_vec_s8_wt_converter">riscv_nn_fc_mat_vec_s8_wt_converter</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_fc_mat_vec_s8_wt_converter (const q7_t * wt_mat, const uint32_t size, const uint32_t wt_row_num, q7_t * wt_mat_out)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This is a weight converter for <code>riscv_nn_fc_mat_vec_s16_s16_s8_sft_bias_fast</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] wt_mat_out</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix stored in a specific order</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s8_s8_asym_bias">riscv_nn_fc_s8_s8_s8_asym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s8_s8_asym_bias (const int8_t * in_vec, const int8_t * wt_mat, const uint16_t in_vec_col, const uint16_t wt_mat_row, const uint16_t in_vec_batch, const int32_t in_offset, const int32_t wt_offset, const int32_t out_scale, const int32_t out_shift, const int32_t out_offset, const int32_t * bias,   int8_t * out_vec, const int32_t act_min, const int32_t act_max, q15_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on signed 8-bit integer inputs,
incorporating bias inputs and applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec_col</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of columns in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat_row</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size of the input vector batches</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value to be added to the input tensor. It should be in in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value to be added to the weight. It should be in in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value to be added to the output tensor. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s8_s8_s8_asym_bias_get_buffer_size">riscv_nn_fc_s8_s8_s8_asym_bias_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s8_s8_s8_asym_bias_get_buffer_size (const uint16_t in_vec_col)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_fc_s8_s8_s8_asym_bias</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec_col</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of columns in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s16_s16_s8_asym_bias">riscv_nn_fc_s16_s16_s8_asym_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s16_s16_s8_asym_bias (const int16_t * in_vec, const int8_t * wt_mat, const int32_t in_vec_col, const int32_t wt_mat_row, const int32_t in_vec_batch, const int32_t in_offset, const int32_t wt_offset, const int32_t out_scale, const int32_t out_shift, const int32_t out_offset, const int64_t * bias, int16_t * out_vec, const int32_t act_min, const int32_t act_max, int16_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on signed 16-bit integer inputs,
incorporating bias inputs and applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec_col</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of columns in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat_row</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size of input vector batches</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_s16_s16_s8_asym_bias_get_buffer_size">riscv_nn_fc_s16_s16_s8_asym_bias_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_s16_s16_s8_asym_bias_get_buffer_size (const uint16_t in_vec_col)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_fc_s16_s16_s8_asym_bias</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec_col</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of columns in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_fc_f16_f16_f16_bias">riscv_nn_fc_f16_f16_f16_bias</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_fc_f16_f16_f16_bias(const float16_t * in_vec, const float16_t * wt_mat, const uint16_t size, const uint16_t wt_row_num, const float16_t * bias, float16_t * out_vec, float16_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculation on half-precision floating-point inputs and outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_mat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_row_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the weight matrix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="section:function_pooling">Pooling Functions</h2>
<div class="sectionbody">
<div class="paragraph">
<p>These functions downsample input data and include both max and average pooling methods.</p>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_avepool_HWC_s8">riscv_nn_avepool_HWC_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_avepool_HWC_s8 (q7_t * in_tensor, const uint16_t in_tensor_batch, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t out_tensor_dim, q7_t * in_tmp_buf, q7_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This is an average pooling function for signed 8-bit integer inputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">#define IN_DIM    32
#define IN_CH     32
#define KER_DIM   3
#define PAD       0
#define STRIDE    2
#define OUT_DIM   15

q7_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};
q7_t out_data[IN_CH * OUT_DIM * OUT_DIM] = {...};
q7_t * in_tmp_buf = NULL;

riscv_nn_avepool_HWC_s8 (in_data, IN_DIM, IN_CH, KER_DIM, PAD, STRIDE,
OUT_DIM, in_tmp_buf, out_data);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_avepool_HWC_s8_any">riscv_nn_avepool_HWC_s8_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_avepool_HWC_s8_any (q7_t * in_tensor, const uint16_t in_tensor_batch, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q7_t * in_tmp_buf, q7_t * out_tensor, const uint16_t out_lshift)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function processes signed 8-bit integer inputs across any X and Y dimensions.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied to the output</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">#define IN_X         15
#define IN_Y         15
#define IN_CH        10
#define KER_DIM_X    2
#define KER_DIM_Y    2
#define PAD_X        0
#define PAD_Y        0
#define STRIDE_X     2
#define STRIDE_Y     2
#define OUT_LSHIFT   3
#define OUT_X        7
#define OUT_Y        7

q7_t in_data[IN_CH * IN_X * IN_Y] = {...};
q7_t out_data[IN_CH * OUT_X * OUT_Y] = {...};
q7_t * in_tmp_buf = NULL;

riscv_nn_avepool_HWC_s8_any (in_data, IN_X, IN_Y, IN_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X, STRIDE_Y, OUT_X, OUT_Y, in_tmp_buf, out_data, OUT_LSHIFT);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_avepool_HWC_s8_any_act">riscv_nn_avepool_HWC_s8_any_act</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_avepool_HWC_s8_any_act (const int in_tensor_batch, const int in_tensor_dim_y, const int in_tensor_dim_x, const int out_tensor_dim_y, const int out_tensor_dim_x, const int stride_y, const int stride_x, const int ker_dim_y, const int ker_dim_x, const int pad_y, const int pad_x, const int act_min, const int act_max, const int in_tensor_ch, int8_t * in_tensor, int16_t * in_tmp_buf, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function processes signed 8-bit integer inputs across any X and Y dimensions and applies activation parameters to limit the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                          The required size can be obtained by calling <code>riscv_nn_avepool_HWC_s8_any_act_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_avepool_HWC_s8_any_act_get_buffer_size">riscv_nn_avepool_HWC_s8_any_act_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_avepool_HWC_s8_any_act_get_buffer_size (const int out_tensor_dim_x, const int in_tensor_ch)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_avepool_HWC_s8_any_act</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_avepool_HWC_s16_any_act">riscv_nn_avepool_HWC_s16_any_act</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_avepool_HWC_s16_any_act (const int in_tensor_batch, const int in_tensor_dim_y, const int in_tensor_dim_x, const int out_tensor_dim_y, const int out_tensor_dim_x, const int stride_y, const int stride_x, const int ker_dim_y, const int ker_dim_x, const int pad_y, const int pad_x, const int act_min, const int act_max, const int in_tensor_ch, int16_t * in_tensor, int16_t * in_tmp_buf, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function processes signed 16-bit integer inputs across any X and Y dimensions and applies activation parameters to limit the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor.<br>
                          The required size can be obtained by calling <code>riscv_nn_avepool_HWC_s16_any_act_get_buffer_size</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_avepool_HWC_s16_any_act_get_buffer_size">riscv_nn_avepool_HWC_s16_any_act_get_buffer_size</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_avepool_HWC_s16_any_act_get_buffer_size (const int out_tensor_dim_x, const int in_tensor_ch)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the required temporary buffer size (in bytes) for
<code>riscv_nn_avepool_HWC_s16_any_act</code>.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>The required temporary buffer size</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_avepool_HWC_s8_asym">riscv_nn_avepool_HWC_s8_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_avepool_HWC_s8_asym (const int8_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, int8_t * out_tensor, const int32_t out_shift, const int32_t out_scale, const int32_t out_round_pos, const int32_t out_round_neg, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function processes signed 8-bit integer inputs across any X and Y dimensions and applying asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_round_pos</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rounding value for nonnegative outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_round_neg</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rounding value for negative outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value to be added to the outputs. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value to be added to the inputs. It should be in in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in in the range [-128, 127].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_avepool_HWC_s16_asym">riscv_nn_avepool_HWC_s16_asym</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_avepool_HWC_s16_asym (const int16_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, int16_t * out_tensor, const int32_t out_shift, const int32_t out_scale, const int32_t out_round_pos, const int32_t out_round_neg, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function processes signed 16-bit integer inputs across any X and Y dimensions and applies asymmetric quantization to the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_round_pos</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rounding value for nonnegative outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_round_neg</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rounding value for negative outputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value to be added to the outputs.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value to be added to the inputs.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in in the range [-32768, 32767].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_avepool_HWC_f16_any">riscv_nn_avepool_HWC_f16_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_avepool_HWC_f16_any (float16_t * in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, float16_t * in_tmp_buf, float16_t * out_tensor);</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function processes half-precision floating-point inputs across any X and Y dimensions.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_maxpool_HWC_s8">riscv_nn_maxpool_HWC_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_maxpool_HWC_s8 (q7_t * in_tensor, const uint16_t in_tensor_batch, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t out_tensor_dim, q7_t * in_tmp_buf, q7_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This is a max pooling function for signed 8-bit integer inputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">#define IN_DIM     32
#define IN_CH      32
#define KER_DIM    3
#define PAD        0
#define STRIDE     2
#define OUT_DIM    15

q7_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};
q7_t out_data[IN_CH * OUT_DIM * OUT_DIM] = {...};

riscv_nn_maxpool_HWC_s8 (in_data, IN_DIM, IN_CH, KER_DIM, PAD, STRIDE, OUT_DIM, NULL, out_data);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_maxpool_HWC_s8_any_act">riscv_nn_maxpool_HWC_s8_any_act</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_maxpool_HWC_s8_any_act (const uint16_t in_tensor_batch, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_dim_x, const uint16_t out_tensor_dim_y, const uint16_t out_tensor_dim_x, const uint16_t stride_y, const uint16_t stride_x, const uint16_t ker_dim_y, const uint16_t ker_dim_x, const uint16_t pad_y, const uint16_t pad_x, const int8_t act_min, const int8_t act_max, const uint16_t in_tensor_ch, int8_t * in_tensor, int16_t * tmp_buffer, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function processes signed 8-bit integer inputs across any X and Y dimensions and applies activation parameters to limit the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buffer</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_maxpool_HWC_s16_any_act">riscv_nn_maxpool_HWC_s16_any_act</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_maxpool_HWC_s16_any_act (const int32_t in_tensor_batch, const int32_t in_tensor_dim_y, const int32_t in_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t out_tensor_dim_x, const int32_t stride_y, const int32_t stride_x, const int32_t ker_dim_y, const int32_t ker_dim_x, const int32_t pad_y, const int32_t pad_x, const int32_t act_min, const int32_t act_max, const int32_t in_tensor_ch, int16_t * in_tensor, int16_t * tmp_buffer, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function processes signed 16-bit integer inputs across any X and Y dimensions and applies activation parameters to limit the outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buffer</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_maxpool_HWC_f16_any">riscv_nn_maxpool_HWC_f16_any</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_maxpool_HWC_f16_any (const uint16_t in_tensor_dim_y, const uint16_t in_tensor_dim_x, const uint16_t out_tensor_dim_y, const uint16_t out_tensor_dim_x, const uint16_t stride_y, const uint16_t stride_x, const uint16_t ker_dim_y, const uint16_t ker_dim_x, const uint16_t pad_y, const uint16_t pad_x, const uint16_t in_tensor_ch, float16_t * in_tensor, float16_t * tmp_buffer, float16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function processes half-precision floating-point inputs across any X and Y dimensions.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] stride_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stride of the pooling window in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the pooling window</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] pad_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Padding size in the X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buffer</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="section:function_softmax">Softmax Functions</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Softmax functions are mathematical functions that calculate probability distributions for one-dimensional (1D) or two-dimensional (2D) inputs.</p>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_softmax_s8_fast">riscv_nn_softmax_s8_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_softmax_s8_fast (const q7_t * in_vec, const uint16_t size, q7_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs softmax calculations on signed 8-bit integer input vectors.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Outputs from inputs with very small values may become zero, which can cause the sum of the dequantized outputs to deviate from 1.</p>
</li>
<li>
<p>This is a 2-based softmax function.</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">#define LENGTH    10
q7_t in_data[LENGTH] = {...};
q7_t out_data[LENGTH];

riscv_nn_softmax_s8_fast (in_data, LENGTH, out_data);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_softmax_s16_fast">riscv_nn_softmax_s16_fast</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_softmax_s16_fast (const q15_t * in_vec, const uint16_t size, q15_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs softmax calculations on signed 16-bit integer input vectors.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Outputs from inputs with very small values may become zero, which can cause the sum of the dequantized outputs to deviate from 1.</p>
</li>
<li>
<p>This is a 2-based softmax function.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_softmax_s8_hp">riscv_nn_softmax_s8_hp</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_softmax_s8_hp (const int8_t * in_tensor, const int32_t in_tensor_row, const int32_t in_tensor_col, const int32_t scale, const int32_t lshift, const int32_t diff_min, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs softmax calculations on signed 8-bit integer input and output tensors using a high-precision algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_row</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_col</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of columns in the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] diff_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum threshold to perform the quantized exponential operation.
                          The difference can be obtained by subtracting the input from the maximum in row.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_softmax_s8_s16_hp">riscv_nn_softmax_s8_s16_hp</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_softmax_s8_s16_hp (const int8_t * in_tensor, const int32_t in_tensor_row, const int32_t in_tensor_col, const int32_t scale, const int32_t lshift, const int32_t diff_min, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs softmax calculations on signed 8-bit integer input tensors and signed 16-bit integer output tensors using a high-precision algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_row</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_col</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of columns in the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] diff_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum threshold to perform the quantized exponential operation.
                          The difference can be obtained by subtracting the input from the maximum in row.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_softmax_u8_hp">riscv_nn_softmax_u8_hp</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_softmax_u8_hp (const uint8_t * in_tensor, const int32_t in_tensor_row, const int32_t in_tensor_col, const int32_t scale, const int32_t lshift, const int32_t diff_min, uint8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs softmax calculations on unsigned 8-bit integer input tensors using a high-precision algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_row</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_col</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of columns in the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lshift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] diff_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum threshold to perform the quantized exponential operation.
                          The difference can be obtained by subtracting the input from the maximum in row.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_softmax_s16_hp">riscv_nn_softmax_s16_hp</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int riscv_nn_softmax_s16_hp (const int16_t * in_tensor, const int32_t in_tensor_row, const int32_t in_tensor_col, const int32_t scale, const int32_t shift, const int16_t * exp_lut, const int16_t * one_by_one_lut, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs softmax calculations on signed 16-bit integer input and output tensors using a high-precision algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_row</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_col</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of columns in the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-shift amount applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] exp_lut</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the look-up table for <code>exp(x)</code>, where x is uniformly distributed in <code>[-10, 0]</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] one_by_one_lut</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the look-up table for <code>(1/(1+x))</code>, where x is uniformly distributed in <code>[0, 1]</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>exp_lut</code> is expected to be a lookup table with 513 uniformly distributed samples within the range [-10, 0].</p>
</li>
<li>
<p><code>one_by_one_lut</code> is expected to be a lookup table with 513 uniformly distributed samples within the range [0, 1].</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_softmax_f16">riscv_nn_softmax_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_softmax_f16 (const float16_t * in_vec, const uint32_t size, float16_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs softmax calculations on half-precision floating-point input vectors.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The calculations are described as follows:</p>
<div class="stemblock">
<div class="content">
\[
\mathtt{softmax}(x_{\scriptscriptstyle{i}}) = \mathtt{e}^{(x_{\scriptscriptstyle{i}} - \mathtt{max}(x))} * \frac{1}{\sum \mathtt{e}^{(x_{\scriptscriptstyle{i}} - \mathtt{max}(x))}}
\]
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_softmax_f32">riscv_nn_softmax_f32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_softmax_f32 (const float32_t * in_vec, const uint32_t size, float32_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs softmax calculations on single-precision floating-point input vectors.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The calculations are described as follows:</p>
<div class="stemblock">
<div class="content">
\[
\mathtt{softmax}(x_{\scriptscriptstyle{i}}) = \mathtt{e}^{(x_{\scriptscriptstyle{i}} - \mathtt{max}(x))} * \frac{1}{\sum \mathtt{e}^{(x_{\scriptscriptstyle{i}} - \mathtt{max}(x))}}
\]
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_softmax_f32_2pass">riscv_nn_softmax_f32_2pass</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_softmax_f32_2pass (const float32_t * in_vec, const uint32_t size, float32_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs softmax calculations on single-precision floating-point input vectors using a two-pass algorithm.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The calculations are described as follows:</p>
<div class="stemblock">
<div class="content">
\[
\mathtt{softmax}(x_{\scriptscriptstyle{i}}) = \mathtt{e}^{(x_{\scriptscriptstyle{i}} - \mathtt{max}(x))} * \frac{1}{\sum \mathtt{e}^{(x_{\scriptscriptstyle{i}} - \mathtt{max}(x))}}
\]
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_softmax2d_f16">riscv_nn_softmax2d_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_softmax2d_f16 (const float16_t * in_buf, uint32_t row, uint32_t col, float16_t * out_buf, float16_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculations on each row of a two-dimensional half-precision floating-point buffer.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input buffer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] row</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the two-dimensional buffer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] col</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of columns in the two-dimensional buffer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for calculations.<br>
                          Required when <code>-mext-vector</code> is enabled.<br>
                          The required size must be the same as the input buffer.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The calculations for each row are described as follows:</p>
<div class="stemblock">
<div class="content">
\[
\mathtt{softmax}(x_{\scriptscriptstyle{i}}) = \mathtt{e}^{(x_{\scriptscriptstyle{i}} - \mathtt{max}(x))} * \frac{1}{\sum \mathtt{e}^{(x_{\scriptscriptstyle{i}} - \mathtt{max}(x))}}
\]
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_softmax2d_f32">riscv_nn_softmax2d_f32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_softmax2d_f32 (const float32_t * in_buf, uint32_t row, uint32_t col, float32_t * out_buf, float32_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs calculations on each row of a two-dimensional single-precision floating-point buffer.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input buffer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] row</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of rows in the two-dimensional buffer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] col</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of columns in the two-dimensional buffer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for calculations.<br>
                          Required when <code>-mext-vector</code> is enabled.<br>
                          The required size must be the same as the input buffer.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The calculations for each row are described as follows:</p>
<div class="stemblock">
<div class="content">
\[
\mathtt{softmax}(x_{\scriptscriptstyle{i}}) = \mathtt{e}^{(x_{\scriptscriptstyle{i}} - \mathtt{max}(x))} * \frac{1}{\sum \mathtt{e}^{(x_{\scriptscriptstyle{i}} - \mathtt{max}(x))}}
\]
</div>
</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="section:function_utils">Utils Functions</h2>
<div class="sectionbody">
<div class="paragraph">
<p>These functions serve as miscellaneous auxiliary tools.</p>
</div>
<div class="sect2">
<h3 id="section:get_version_libnn">get_version_libnn</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">char * get_version_libnn (void)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function retrieves the version information of the library.</p>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>A string that includes the version information of the library.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_argmax_f32">riscv_nn_argmax_f32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_argmax_f32 (const float32_t * in_tensor, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_dim_x, const uint8_t axis, uint32_t * out_idx)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function finds the indices of the maximum values along the specified axis
for single-precision floating-point inputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] axis</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis along which to find the maximum values<br>
                          (0: X-axis, 1: Y-axis)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_idx</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Indices of the maximum values</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if <code>axis</code> is invalid</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_channel_shuffle_CHW_s8">riscv_nn_channel_shuffle_CHW_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_channel_shuffle_CHW_s8 (int8_t * in_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const uint32_t in_tensor_batch, const uint32_t group, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs channel shuffling on signed 8-bit integer input and output tensors using the NCHW layout.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] group</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of group for channel shuffle</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, <code>-1</code> if <code>in_tensor_ch</code> is not a multiple of <code>group</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The input and output tensors are assumed to use the NCHW data layout.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_channel_shuffle_HWC_s8">riscv_nn_channel_shuffle_HWC_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_channel_shuffle_HWC_s8 (int8_t * in_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const uint32_t in_tensor_batch, const uint32_t group, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs channel shuffling on signed 8-bit integer input and output tensors using the NHWC layout.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] group</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of group for channel shuffle</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, <code>-1</code> if <code>in_tensor_ch</code> is not a multiple of <code>group</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The input and output tensors are assumed to use the NHWC data layout.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_dequantize_s8_f16">riscv_nn_dequantize_s8_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_dequantize_s8_f16 (const int8_t * in_vec, const uint32_t size, const float32_t in_scale, const int32_t in_zero_point, float16_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function dequantizes signed 8-bit integer inputs into half-precision
floating-point outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for dequantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_zero_point</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Zero point for input dequantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_dequantize_s8_f32">riscv_nn_dequantize_s8_f32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_dequantize_s8_f32 (const int8_t * in_vec, const uint32_t size, const float32_t in_scale, const int32_t in_zero_point, float32_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function dequantizes signed 8-bit integer inputs into single-precision
floating-point outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for dequantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_zero_point</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Zero point for input dequantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_dequantize_s16_f32">riscv_nn_dequantize_s16_f32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_dequantize_s16_f32 (const int16_t * in_vec, const uint32_t size, const float32_t in_scale, const int32_t in_zero_point, float32_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function dequantizes signed 16-bit integer inputs into single-precision
floating-point outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor for dequantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_zero_point</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Zero point for input dequantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_exp_f16">riscv_nn_exp_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_exp_f16 (const float16_t * in_vec, const uint32_t size, float16_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the base-e exponential values for half-precision
floating-point inputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_exp_f32">riscv_nn_exp_f32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_exp_f32 (const float32_t * in_vec, uint32_t size, float32_t * out_vec)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function calculates the base-e exponential values for single-precision
floating-point inputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_gather_HWC_s8">riscv_nn_gather_HWC_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_gather_HWC_s8 (int8_t * in_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const uint32_t in_tensor_batch, const uint32_t gather_idx, const uint32_t axis, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function extracts a specific portion of data from a signed 8-bit integer tensor.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] gather_idx</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Starting index for the gather operation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] axis</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis along which the data is gathered<br>
                          (0: N-axis, 1: H-axis, 2: W-axis, 3: C-axis)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if <code>axis</code> is invalid</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_gather_HWC_s16">riscv_nn_gather_HWC_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_gather_HWC_s16 (const int16_t * in_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const uint32_t in_tensor_batch, const uint32_t gather_idx, const uint32_t axis, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function extracts a specific portion of data from a signed 16-bit integer tensor.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] gather_idx</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Starting index for the gather operation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] axis</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis along which the data is gathered<br>
                          (0: N-axis, 1: H-axis, 2: W-axis, 3: C-axis)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if <code>axis</code> is invalid</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_layer_norm_f16">riscv_nn_layer_norm_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_layer_norm_f16 (const float16_t * in_tensor, const float16_t epsilon, const float16_t * beta, const float16_t * gamma, const uint32_t sentence_len, const uint32_t feature_len, float16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs layer normalization on half-precision floating-point inputs.</p>
<div class="paragraph">
<p><a href="#figure:input_tensor_layer_norm">Input Tensor of Layer Normalization</a> illustrates the input tensor,
where cells colored in gray represent the elements calculated at a time using the following:</p>
</div>
<div class="stemblock">
<div class="content">
\[
\mathtt{y = \frac{x - E[x]}{\sqrt{\mathtt{Var}[x] + \epsilon}} * \gamma + \beta}
\]
</div>
</div>
</dd>
</dl>
</div>
<div id="figure:input_tensor_layer_norm" class="imageblock text-center">
<div class="content">
<img src="images/input_tensor_layer_norm.png" alt="input tensor layer norm">
</div>
<div class="title">Figure 7. Input Tensor of Layer Normalization</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] epsilon</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant to be added to mini-batch variances</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] beta</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the offset vector for each feature</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] gamma</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for each feature</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] sentence_len</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length of input sentences</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] feature_len</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length of features</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The assumed batch size is 1.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_layer_norm_f32">riscv_nn_layer_norm_f32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_layer_norm_f32 (const float32_t * in_tensor, const float32_t epsilon, const float32_t * beta, const float32_t * gamma, const uint32_t sentence_len, const uint32_t feature_len, float32_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs layer normalization on single-precision floating-point inputs.</p>
<div class="paragraph">
<p><a href="#figure:input_tensor_layer_norm">Input Tensor of Layer Normalization</a> illustrates the input tensor,
where cells colored in gray represent the elements calculated at a time using the following:</p>
</div>
<div class="stemblock">
<div class="content">
\[
\mathtt{y = \frac{x - E[x]}{\sqrt{\mathtt{Var}[x] + \epsilon}} * \gamma + \beta}
\]
</div>
</div>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] epsilon</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant to be added to mini-batch variances</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] beta</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the offset vector for each feature</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] gamma</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for each feature</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] sentence_len</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length of input sentences</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] feature_len</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length of features</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The assumed batch size is 1.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_lstm_unidirectional_s16_s8">riscv_nn_lstm_unidirectional_s16_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_lstm_unidirectional_s16_s8 (riscv_nn_lstm_context * scratch_buffers, const int8_t * input_data, const riscv_nn_lstm_dims * lstm_dims, const int8_t * in_to_in_weights, const int8_t * in_to_forget_weights, const int8_t * in_to_cell_weights, const int8_t * in_to_out_weights, const int8_t * recurrent_to_in_weights, const int8_t * recurrent_to_forget_weights, const int8_t * recurrent_to_cell_weights, const int8_t * recurrent_to_out_weights, const int16_t * cell_to_in_weights, const int16_t * cell_to_forget_weights, const int16_t * cell_to_out_weights, const int8_t * projection_weights, const riscv_nn_lstm_params * lstm, int8_t * output_state, int16_t * cell_state, int8_t * output_data)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs a unidirectional long short-term memory (LSTM) operation with
signed 8-bit inputs and outputs, and a signed 16-bit gate output.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scratch_buffers</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Structure containing the scratch buffers.
                                     Each buffer is expected to have a size of
                                     <code>lstm_dims-&gt;num_batches * lstm_dims-&gt;num_outputs</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] input_data</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input data</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lstm_dims</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dimension of the LSTM&#8217;s inputs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_to_in_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_to_forget_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Forget weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_to_cell_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cell weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_to_out_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] recurrent_to_in_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Recurrent of the input weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] recurrent_to_forget_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Recurrent of the forget weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] recurrent_to_cell_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Recurrent of the cell weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] recurrent_to_out_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Recurrent of the output weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] cell_to_in_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] cell_to_forget_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] cell_to_out_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] projection_weights</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] lstm</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">LSTM parameters</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] output_state</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output state</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] cell_state</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the cell state</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] output_data</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input data</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_pixel_shuffle_HWC_s8">riscv_nn_pixel_shuffle_HWC_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_pixel_shuffle_HWC_s8 (const int8_t * in_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const uint32_t in_tensor_batch, const uint32_t up_factor, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs pixel shuffle on signed 8-bit integer tensors for both
input and output.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] up_factor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplier for upscaling the spatial dimensions</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, <code>-1</code> if <code>in_tensor_ch</code> is not a multiple of <code>up_factor</code>\(^\texttt{2}\)</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_quantize_f16_s8">riscv_nn_quantize_f16_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_quantize_f16_s8 (const float16_t * in_vec, const uint32_t size, int8_t * out_vec, const float32_t out_scale, const int32_t out_zero_point, const int32_t act_min, const int32_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function quantizes half-precision floating-point inputs into signed 8-bit
integer outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling value for the quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_zero_point</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Zero point for output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_quantize_f32_s8">riscv_nn_quantize_f32_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_quantize_f32_s8 (const float32_t * in_vec, const uint32_t size, int8_t * out_vec, const float32_t out_scale, const int32_t out_zero_point, const int32_t act_min, const int32_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function quantizes single-precision floating-point inputs into signed 8-bit
integer outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling value for the quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_zero_point</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Zero point for output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_quantize_f32_s16">riscv_nn_quantize_f32_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_quantize_f32_s16 (const float32_t * in_vec, const uint32_t size, int16_t * out_vec, const float32_t out_scale, const int32_t out_zero_point, const int32_t act_min, const int32_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function quantizes single-precision floating-point inputs into signed
16-bit integer outputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling value for the quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_zero_point</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Zero point for output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_reduce_sum_s8">riscv_nn_reduce_sum_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_reduce_sum_s8 (const int8_t * in_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const uint32_t in_tensor_batch, const uint8_t axis, const int32_t in_offset, const int32_t out_shift, const int32_t out_scale, const int32_t out_offset, const int32_t act_min, const int32_t act_max, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function computes the reduction sum of a signed 8-bit input tensor along
the specified axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] axis</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis along which to perform the reduction<br>
                          (0: N-axis, 1: H-axis, 2: W-axis, 3: C-axis)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if <code>axis</code> is invalid</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_reduce_sum_s16">riscv_nn_reduce_sum_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_reduce_sum_s16 (const int16_t * in_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const uint32_t in_tensor_batch, const uint8_t axis, const int32_t in_offset, const int32_t out_shift, const int32_t out_scale, const int32_t out_offset, const int32_t act_min, const int32_t act_max, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function computes the reduction sum of a signed 16-bit input tensor along
the specified axis.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] axis</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis along which to perform the reduction<br>
                          (0: N-axis, 1: H-axis, 2: W-axis, 3: C-axis)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if <code>axis</code> is invalid</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_requantize_s8_s8">riscv_nn_requantize_s8_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_requantize_s8_s8 (const int8_t * in_vec, int8_t * out_vec, const uint32_t size, const int32_t out_scale, const int32_t out_shift, const int32_t in_offset, const int32_t out_offset, const int32_t act_min, const int32_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs re-quantization from one signed 8-bit integer format to another.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value to be added to the input vector. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value to be added to the output vector. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output vector is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output vector is limited to. It should be in the range [-128, 127].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_requantize_s16_s8">riscv_nn_requantize_s16_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_requantize_s16_s8 (const int16_t * in_vec, int8_t * out_vec, const uint32_t size, const int32_t out_scale, const int32_t out_shift, const int32_t out_offset, const int32_t act_min, const int32_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs re-quantization from signed 16-bit integers to signed
8-bit integers.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value to be added to the output vector. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output vector is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output vector is limited to. It should be in the range [-128, 127].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_requantize_s16_s16">riscv_nn_requantize_s16_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_requantize_s16_s16 (const int16_t * in_vec, int16_t * out_vec, const uint32_t size, const int32_t out_scale, const int32_t out_shift, const int32_t act_min, const int32_t act_max)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs re-quantization from one signed 16-bit integer format to
another.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output vector is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output vector is limited to. It should be in the range [-32768, 32767].</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>During the quantization process, a positive <code>out_shift</code> value
left-shifts the calculation results, while a negative value right-shifts them.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_reshape_s8">riscv_nn_reshape_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_reshape_s8 (const int8_t * in_tensor, int8_t * out_tensor, const uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function reshapes a 8-bit tensor to a new shape with identical data.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size, in bytes, of total input tensors</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
<dt class="hdlist1">Example</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">#define SIZE   1024
int8_t in_tensor[SIZE] = {...};
int8_t out_tensor[SIZE];

riscv_nn_reshape_s8 (in_tensor, out_tensor, SIZE);</code></pre>
</div>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_reshape_f16">riscv_nn_reshape_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">void riscv_nn_reshape_f16 (const float16_t * in_tensor, float16_t * out_tensor, const uint32_t size)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function reshapes a half-precision floating-point tensor to a new shape
with identical data.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size, in bytes, of total input tensors</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p>None</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_reverseV2_s8">riscv_nn_reverseV2_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_reverseV2_s8 (const int8_t * in_tensor, const uint32_t in_tensor_dim_w, const uint32_t in_tensor_dim_z, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_dim_x, const uint32_t axis, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function reverses a specified dimension of a signed 8-bit integer input
tensor.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] axis</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis along which to reverse the elements<br>
                          (0: W-axis, 1: Z-axis, 2: Y-axis, 3: X-axis)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if <code>axis</code> is invalid</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_reverseV2_s16">riscv_nn_reverseV2_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_reverseV2_s16 (const int16_t * in_tensor, const uint32_t in_tensor_dim_w, const uint32_t in_tensor_dim_z, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_dim_x, const uint32_t axis, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function reverses a specified dimension of a signed 16-bit integer input
tensor.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] axis</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis along which to reverse the elements<br>
                          (0: W-axis, 1: Z-axis, 2: Y-axis, 3: X-axis)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if <code>axis</code> is invalid</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_rms_norm_f16">riscv_nn_rms_norm_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_rms_norm_f16 (const float16_t * in_tensor, const float16_t epsilon, const float16_t * gamma, const uint32_t sentence_len, const uint32_t feature_len, float16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs Root Mean Square Layer Normalization on half-precision
floating-point inputs.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] epsilon</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Small constant added for numerical stability</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] gamma</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the scaling vector for each input sentence</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] sentence_len</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length of input sentences</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] feature_len</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Length of features</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_scatter_nd_s8">riscv_nn_scatter_nd_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_scatter_nd_s8 (int8_t * out_tensor, const int32_t * out_tensor_shape, const int32_t out_tensor_dim, const int32_t init_val, const int32_t * idx_tensor, const int32_t * idx_tensor_shape, const int32_t  idx_tensor_dim, const int8_t * update_tensor, const int32_t * update_tensor_shape, const int32_t update_tensor_dim, int32_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function scatters signed 8-bit data from the updating tensor into the
output tensor based on the index tensor.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_shape</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to a vector specifying the size of each dimension in the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of dimensions in the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] init_val</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Initial value used to fill the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] idx_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the index tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] idx_tensor_shape</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to a vector specifying the size of each dimension in the index tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] idx_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of dimensions in the index tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] update_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the updating tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] update_tensor_shape</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to a vector specifying the size of each dimension in the updating tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] update_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of dimensions in the updating tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for calculations; its size must match the last dimension of <code>idx_tensor_shape</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, <code>-1</code> if the number of updates specified by <code>idx_tensor</code> exceeds the size of <code>update_tensor</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>In vectors storing tensor dimensions, the dimensions are ordered from outermost to innermost, with outer dimensions at lower indices.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_scatter_nd_s16">riscv_nn_scatter_nd_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_scatter_nd_s16 (int16_t * out_tensor, const int32_t * out_tensor_shape, const int32_t out_tensor_dim, const int32_t * idx_tensor, const int32_t * idx_tensor_shape, const int32_t idx_tensor_dim, const int16_t * update_tensor, const int32_t * update_tensor_shape, const int32_t update_tensor_dim, int32_t * tmp_buf)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function scatters signed 16-bit data from the updating tensor into the
output tensor based on the index tensor.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_shape</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to a vector specifying the size of each dimension in the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of dimensions in the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] init_val</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Initial value used to fill the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] idx_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the index tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] idx_tensor_shape</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to a vector specifying the size of each dimension in the index tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] idx_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of dimensions in the index tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] update_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the updating tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] update_tensor_shape</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to a vector specifying the size of each dimension in the updating tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] update_tensor_dim</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of dimensions in the updating tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for calculations; its size must match the last dimension of <code>idx_tensor_shape</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, <code>-1</code> if the number of updates specified by <code>idx_tensor</code> exceeds the size of <code>update_tensor</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>In vectors storing tensor dimensions, the dimensions are ordered from outermost to innermost, with outer dimensions at lower indices.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_subspectral_norm_f32">riscv_nn_subspectral_norm_f32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_subspectral_norm_f32 (float32_t * in_tensor, const uint32_t in_dim_batch, const uint32_t in_dim_freq, const uint32_t in_dim_time, const uint32_t in_dim_ch, const float32_t epsilon, const float32_t * beta, const float32_t * gamma, const float32_t * means, const float32_t * vars, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint32_t spec_groups_num, float32_t * out_tensor, float32_t * out_tensor_tmp_buff, float32_t * ker_weight_tmp_buff, float32_t * bias_tmp_buff)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs subspectral normalization on a single-precision
floating-point tensor.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch size of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_freq</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size of the frequency dimension in the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_time</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size of the time dimension in the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] epsilon</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Small constant added for numerical stability</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] beta</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the beta vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] gamma</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the gamma vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] means</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the means vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] vars</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the variance vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] spec_groups_num</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of group for subspectral</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_tensor_tmp_buff</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dummy</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] ker_weight_tmp_buff</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the kernel weights; its size must be equal to <code>spec_groups_num</code> * <code>in_dim_ch</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias_tmp_buff</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the bias; its size must be equal to <code>spec_groups_num</code> * <code>in_dim_ch</code>.</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if <code>in_dim_freq</code> is not a multiple of <code>spec_groups_num</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_svdf_s8">riscv_nn_svdf_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_svdf_s8 (q31_t * tmp_buf, q31_t * tmp_buf2, const int32_t rank,  const int32_t in_offset, const int32_t out_offset, const int32_t in_act_min, const int32_t in_act_max, const int32_t out_act_min, const int32_t out_act_max, const int32_t in_scale, const int32_t in_shift, const int32_t out_scale, const int32_t out_shift, const int32_t in_batch, const int32_t in_height, const q7_t * in_tensor, q15_t * state_tensor, const int32_t wt_feature_batch, const q7_t * wt_feature_tensor, const int32_t wt_time_height, const q15_t * wt_time_tensor, const q31_t * bias, q7_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs singular value decomposition (SVD) filtering for
signed 8-bit integer inputs and a signed 16-bit integer state tensor.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rank</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of the largest elements to be kept</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the input tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the input tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size of input tensor batches</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_height</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Height of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] state_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the state tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_feature_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size of the feature weight tensor batches</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_feature_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the feature weight tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_time_height</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Height of the time weight tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_time_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the time weight tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the following constraints:
<code>in_height</code> is nonnegative and less than <code>0x7FFFFFF0</code>, and <code>wt_time_height</code> is also nonnegative.</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, positive <code>in_shift</code> and <code>out_shift</code> values
left-shift the calculation results, while negative values right-shift them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_svdf_s8_state_s8">riscv_nn_svdf_s8_state_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int riscv_nn_svdf_s8_state_s8 (q31_t * tmp_buf, q31_t * tmp_buf2, const int32_t rank, const int32_t in_offset, const int32_t out_offset, const int32_t in_act_min, const int32_t in_act_max, const int32_t out_act_min, const int32_t out_act_max, const int32_t in_scale, const int32_t in_shift, const int32_t out_scale, const int32_t out_shift, const int32_t in_batch, const int32_t in_height, const q7_t * in_tensor, q7_t * state_tensor, const int32_t wt_feature_batch, const q7_t * wt_feature_tensor, const int32_t wt_time_height, const q7_t * wt_time_tensor, const q31_t * bias, q7_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs singular value decomposition (SVD) filtering for
signed 8-bit integer inputs and a signed 8-bit integer state tensor.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tmp_buf2</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporary buffer for the output tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] rank</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of the largest elements to be kept</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the input tensor. It should be in the range [-127, 128].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Offset value for the output tensor. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the input tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the input tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_act_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_act_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum value that the output tensor is limited to. It should be in the range [-128, 127].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during input quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_scale</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling factor applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] out_shift</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift amount applied during output quantization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size of input tensor batches</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_height</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Height of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] state_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the state tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_feature_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size of the feature weight tensor batches</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_feature_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the feature weight tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_time_height</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Height of the time weight tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] wt_time_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the time weight tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] bias</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the bias vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code> if successful; otherwise, returns <code>-1</code> if the inputs fail to meet the following constraints:
<code>in_height</code> is nonnegative and less than <code>0x7FFFFFF0</code>, and <code>wt_time_height</code> is also nonnegative.</p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><code>bias</code> can be a null pointer as the bias vector is optional for this function.</p>
</li>
<li>
<p>During the quantization process, positive <code>in_shift</code> and <code>out_shift</code> values
left-shift the calculation results, while negative values right-shift them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_top_k_s8">riscv_nn_top_k_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_top_k_s8 (q7_t * in_vec, uint32_t size, uint32_t k, q7_t * val, uint32_t * idx)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function identifies the <code>k</code> largest values and their indices in a signed 8-bit integer input vector.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] k</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of the largest values to be searched</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] val</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The <code>k</code> largest values in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] idx</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Indices of the <code>k</code> largest values in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The <code>k</code> largest values are sorted from largest to smallest and stored in the <code>val</code> output vector.
If multiple elements share the same value, those with smaller indices are given higher priority in the selection.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_top_k_f16">riscv_nn_top_k_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_top_k_f16 (float16_t * in_vec, uint32_t size, uint32_t k, float16_t * val, uint32_t * idx)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function identifies the <code>k</code> largest values and their indices in a half-precision floating-point input vector.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_vec</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of elements in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] k</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of the largest values to be searched</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] val</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The <code>k</code> largest values in the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] idx</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Indices of the <code>k</code> largest values in the input vector</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>The <code>k</code> largest values are sorted from largest to smallest and stored in the <code>val</code> output vector.
If multiple elements share the same value, those with smaller indices are given higher priority in the selection.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_transpose_4d_s8">riscv_nn_transpose_4d_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_transpose_4d_s8 (const int8_t * in_tensor, const uint32_t in_dim_w, const uint32_t in_dim_z, const uint32_t in_dim_y, const uint32_t in_dim_x, const riscv_nn_transpose_format tran_fmt, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function transposes a signed 8-bit integer tensor from one layout to
another.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tran_fmt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enum specifying the source and destination data layouts for transposition</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_transpose_4d_s16">riscv_nn_transpose_4d_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_transpose_4d_s16 (const int16_t * in_tensor, const uint32_t in_dim_w, const uint32_t in_dim_z, const uint32_t in_dim_y, const uint32_t in_dim_x, const riscv_nn_transpose_format tran_fmt, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function transposes a signed 16-bit integer tensor from one layout to
another.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tran_fmt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enum specifying the source and destination data layouts for transposition</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_transpose_4d_s32">riscv_nn_transpose_4d_s32</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_transpose_4d_s32 (const int32_t * in_tensor, const uint32_t in_dim_w, const uint32_t in_dim_z, const uint32_t in_dim_y, const uint32_t in_dim_x, const riscv_nn_transpose_format tran_fmt, int32_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function transposes a signed 32-bit integer tensor from one layout to
another.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_w</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">W dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_z</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Z dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] tran_fmt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enum specifying the source and destination data layouts for transposition</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_upsampling2d_HWC_s8">riscv_nn_upsampling2d_HWC_s8</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_upsampling2d_HWC_s8 (const int8_t * in_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const uint32_t scale_factor_x, const uint32_t scale_factor_y, const riscv_nn_upsample_method upsample_method, int8_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs upsampling on two-dimensional tensors containing signed
8-bit integer data.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale_factor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Factor to be scaled up for X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale_factor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Factor to be scaled up for Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] upsample_method</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Algorithm used for upsampling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Only the <code>NN_UPSAMPLE_NEAREST</code> algorithm supports <code>upsample_method</code>.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_upsampling2d_HWC_s16">riscv_nn_upsampling2d_HWC_s16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_upsampling2d_HWC_s16 (const int16_t * in_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const uint32_t scale_factor_x, const uint32_t scale_factor_y, const riscv_nn_upsample_method upsample_method, int16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs upsampling on two-dimensional tensors containing signed
16-bit integer data.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale_factor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Factor to be scaled up for X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale_factor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Factor to be scaled up for Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] upsample_method</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Algorithm used for upsampling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Only the <code>NN_UPSAMPLE_NEAREST</code> algorithm supports <code>upsample_method</code>.</p>
</dd>
</dl>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="section:riscv_nn_upsampling2d_HWC_f16">riscv_nn_upsampling2d_HWC_f16</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Declaration</dt>
<dd>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">int32_t riscv_nn_upsampling2d_HWC_f16 (const float16_t * in_tensor, const uint32_t in_tensor_dim_x, const uint32_t in_tensor_dim_y, const uint32_t in_tensor_ch, const uint32_t scale_factor_x, const uint32_t scale_factor_y, const riscv_nn_upsample_method upsample_method, float16_t * out_tensor)</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Description</dt>
<dd>
<p>This function performs upsampling on two-dimensional tensors containing
half-precision floating-point data.</p>
</dd>
<dt class="hdlist1">Parameters</dt>
<dd>
<p>Parameters are described as follows:</p>
<table class="tableblock frame-topbot grid-rows" style="width: 95%;">
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the input vector</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">X dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_dim_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Y dimension of the input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] in_tensor_ch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of input tensor channels</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale_factor_x</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Factor to be scaled up for X dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] scale_factor_y</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Factor to be scaled up for Y dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[in] upsample_method</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Algorithm used for upsampling</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[out] out_tensor</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pointer to the output tensor</p></td>
</tr>
</tbody>
</table>
</dd>
<dt class="hdlist1">Returns</dt>
<dd>
<p><code>0</code></p>
</dd>
<dt class="hdlist1">Note</dt>
<dd>
<p>Only the <code>NN_UPSAMPLE_NEAREST</code> algorithm supports <code>upsample_method</code>.</p>
</dd>
</dl>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Version 3.4.0<br>
Last updated 2025-05-27 09:09:42 +0800
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>